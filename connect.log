2026-01-27 18:23:48,830 - INFO - ============================================================
2026-01-27 18:23:48,830 - INFO - CONNECT Project - Phase 1
2026-01-27 18:23:48,830 - INFO - Problem: inverse
2026-01-27 18:23:48,830 - INFO - ============================================================
2026-01-27 18:23:48,830 - INFO - 
============================================================
2026-01-27 18:23:48,830 - INFO - PHASE 1: TRAINING
2026-01-27 18:23:48,831 - INFO - ============================================================
2026-01-27 18:23:48,831 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 18:23:48,832 - ERROR - Execution failed: Story directory not found: data/collectivistic-stories-all
2026-01-27 18:23:48,832 - ERROR - Check connect.log for details
2026-01-27 18:27:06,299 - INFO - ============================================================
2026-01-27 18:27:06,299 - INFO - CONNECT Project - Phase 1
2026-01-27 18:27:06,299 - INFO - Problem: inverse
2026-01-27 18:27:06,299 - INFO - ============================================================
2026-01-27 18:27:06,300 - INFO - 
============================================================
2026-01-27 18:27:06,300 - INFO - PHASE 1: TRAINING
2026-01-27 18:27:06,300 - INFO - ============================================================
2026-01-27 18:27:06,300 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 18:27:06,300 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 18:27:06,320 - INFO - Successfully loaded 28 stories
2026-01-27 18:27:06,321 - INFO - Loaded 28 training stories
2026-01-27 18:27:06,323 - INFO - Survey results will be saved to: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 18:27:06,339 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 18:27:06,341 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,341 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,342 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,343 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,343 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,343 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,343 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,343 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,345 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 18:27:06,347 - INFO - Processing story: About_a_Hum
2026-01-27 18:27:06,348 - ERROR - Failed to process question 2 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,348 - ERROR - Failed to process question 4 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 6 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 8 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 10 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 12 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 14 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 16 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 18 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 20 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 22 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 24 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 26 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,349 - ERROR - Failed to process question 28 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 30 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 32 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 34 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 36 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 38 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,350 - ERROR - Failed to process question 40 for story About_a_Hum: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,352 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 18:27:06,354 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 18:27:06,355 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,355 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,356 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,357 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,359 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 18:27:06,361 - INFO - Processing story: Back_To_The_Wall
2026-01-27 18:27:06,362 - ERROR - Failed to process question 2 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,362 - ERROR - Failed to process question 4 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 6 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 8 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 10 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 12 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 14 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 16 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 18 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 20 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,363 - ERROR - Failed to process question 22 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 24 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 26 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 28 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 30 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 32 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 34 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 36 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 38 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,364 - ERROR - Failed to process question 40 for story Back_To_The_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,366 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 18:27:06,368 - INFO - Processing story: Community_Time
2026-01-27 18:27:06,370 - ERROR - Failed to process question 2 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 4 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 6 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 8 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 10 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 12 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 14 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 16 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,370 - ERROR - Failed to process question 18 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 20 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 22 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 24 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 26 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 28 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 30 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,371 - ERROR - Failed to process question 32 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,372 - ERROR - Failed to process question 34 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,372 - ERROR - Failed to process question 36 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,372 - ERROR - Failed to process question 38 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,372 - ERROR - Failed to process question 40 for story Community_Time: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,373 - INFO - ✓ Saved: Community_Time.json
2026-01-27 18:27:06,377 - INFO - Processing story: Fleabags
2026-01-27 18:27:06,378 - ERROR - Failed to process question 2 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,378 - ERROR - Failed to process question 4 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 6 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 8 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 10 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 12 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 14 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 16 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 18 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 20 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 22 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 24 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 26 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,379 - ERROR - Failed to process question 28 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 30 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 32 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 34 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 36 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 38 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,380 - ERROR - Failed to process question 40 for story Fleabags: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,382 - INFO - ✓ Saved: Fleabags.json
2026-01-27 18:27:06,384 - INFO - Processing story: Gravity_Reduced
2026-01-27 18:27:06,385 - ERROR - Failed to process question 2 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,385 - ERROR - Failed to process question 4 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 6 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 8 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 10 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 12 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 14 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 16 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 18 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 20 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 22 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,386 - ERROR - Failed to process question 24 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 26 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 28 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 30 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 32 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 34 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 36 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 38 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,387 - ERROR - Failed to process question 40 for story Gravity_Reduced: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,389 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-27 18:27:06,391 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 18:27:06,392 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,392 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,393 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,394 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,396 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-27 18:27:06,398 - INFO - Processing story: Honeybee
2026-01-27 18:27:06,400 - ERROR - Failed to process question 2 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 4 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 6 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 8 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 10 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 12 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 14 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 16 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,400 - ERROR - Failed to process question 18 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 20 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 22 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 24 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 26 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 28 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 30 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 32 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 34 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,401 - ERROR - Failed to process question 36 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,402 - ERROR - Failed to process question 38 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,402 - ERROR - Failed to process question 40 for story Honeybee: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,403 - INFO - ✓ Saved: Honeybee.json
2026-01-27 18:27:06,405 - INFO - Processing story: Last_Long_Night
2026-01-27 18:27:06,407 - ERROR - Failed to process question 2 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 4 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 6 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 8 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 10 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 12 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 14 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 16 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,407 - ERROR - Failed to process question 18 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 20 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 22 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 24 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 26 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 28 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 30 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 32 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 34 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 36 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,408 - ERROR - Failed to process question 38 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,409 - ERROR - Failed to process question 40 for story Last_Long_Night: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,410 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-27 18:27:06,412 - INFO - Processing story: Raindrop_Snowflake
2026-01-27 18:27:06,414 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,414 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,415 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,416 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,416 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,417 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-27 18:27:06,420 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-27 18:27:06,421 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,421 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,421 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,422 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,423 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,423 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,423 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,423 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,423 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,425 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-27 18:27:06,427 - INFO - Processing story: Rice
2026-01-27 18:27:06,428 - ERROR - Failed to process question 2 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,428 - ERROR - Failed to process question 4 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,428 - ERROR - Failed to process question 6 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,428 - ERROR - Failed to process question 8 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,428 - ERROR - Failed to process question 10 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,428 - ERROR - Failed to process question 12 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 14 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 16 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 18 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 20 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 22 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 24 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 26 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 28 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 30 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 32 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 34 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,429 - ERROR - Failed to process question 36 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,430 - ERROR - Failed to process question 38 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,430 - ERROR - Failed to process question 40 for story Rice: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,432 - INFO - ✓ Saved: Rice.json
2026-01-27 18:27:06,434 - INFO - Processing story: Swallowed
2026-01-27 18:27:06,435 - ERROR - Failed to process question 2 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,435 - ERROR - Failed to process question 4 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 6 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 8 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 10 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 12 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 14 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 16 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 18 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 20 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 22 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 24 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 26 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,436 - ERROR - Failed to process question 28 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 30 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 32 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 34 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 36 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 38 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,437 - ERROR - Failed to process question 40 for story Swallowed: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,439 - INFO - ✓ Saved: Swallowed.json
2026-01-27 18:27:06,441 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-27 18:27:06,443 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,443 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,444 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,445 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,445 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,445 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,445 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,446 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-27 18:27:06,449 - INFO - Processing story: The_Christmas_Monks
2026-01-27 18:27:06,450 - ERROR - Failed to process question 2 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,450 - ERROR - Failed to process question 4 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,450 - ERROR - Failed to process question 6 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,450 - ERROR - Failed to process question 8 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 10 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 12 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 14 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 16 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 18 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 20 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 22 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 24 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 26 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 28 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 30 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,451 - ERROR - Failed to process question 32 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,452 - ERROR - Failed to process question 34 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,452 - ERROR - Failed to process question 36 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,452 - ERROR - Failed to process question 38 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,452 - ERROR - Failed to process question 40 for story The_Christmas_Monks: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,454 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-27 18:27:06,456 - INFO - Processing story: The_Circuit
2026-01-27 18:27:06,457 - ERROR - Failed to process question 2 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,457 - ERROR - Failed to process question 4 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 6 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 8 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 10 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 12 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 14 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 16 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,458 - ERROR - Failed to process question 18 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 20 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 22 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 24 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 26 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 28 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 30 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 32 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 34 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 36 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 38 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,459 - ERROR - Failed to process question 40 for story The_Circuit: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,461 - INFO - ✓ Saved: The_Circuit.json
2026-01-27 18:27:06,463 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-27 18:27:06,464 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,465 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,466 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,467 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,468 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-27 18:27:06,471 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-27 18:27:06,472 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,472 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,473 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,474 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,474 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,474 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,474 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,474 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,475 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-27 18:27:06,478 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-27 18:27:06,479 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,479 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,479 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,479 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,480 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,481 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,481 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,481 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,481 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,481 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,483 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-27 18:27:06,485 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-27 18:27:06,487 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,487 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,488 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,488 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,488 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,488 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,489 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,491 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-27 18:27:06,493 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-27 18:27:06,494 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,495 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,496 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,497 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,497 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,497 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,499 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-27 18:27:06,501 - INFO - Processing story: The_Stretcher
2026-01-27 18:27:06,502 - ERROR - Failed to process question 2 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,502 - ERROR - Failed to process question 4 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 6 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 8 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 10 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 12 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 14 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 16 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 18 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 20 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 22 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 24 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,503 - ERROR - Failed to process question 26 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 28 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 30 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 32 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 34 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 36 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 38 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,504 - ERROR - Failed to process question 40 for story The_Stretcher: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,506 - INFO - ✓ Saved: The_Stretcher.json
2026-01-27 18:27:06,508 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-27 18:27:06,510 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,510 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,510 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,510 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,510 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,510 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,511 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,512 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,512 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,513 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-27 18:27:06,518 - INFO - Processing story: War_of_the_Wall
2026-01-27 18:27:06,519 - ERROR - Failed to process question 2 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,519 - ERROR - Failed to process question 4 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 6 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 8 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 10 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 12 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 14 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,520 - ERROR - Failed to process question 16 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 18 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 20 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 22 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 24 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 26 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 28 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 30 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 32 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 34 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 36 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,521 - ERROR - Failed to process question 38 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,522 - ERROR - Failed to process question 40 for story War_of_the_Wall: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,523 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-27 18:27:06,526 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-27 18:27:06,527 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,527 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,528 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,529 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,531 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-27 18:27:06,533 - INFO - Processing story: We_Stand_Up
2026-01-27 18:27:06,534 - ERROR - Failed to process question 2 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 4 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 6 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 8 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 10 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 12 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 14 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 16 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,535 - ERROR - Failed to process question 18 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 20 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 22 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 24 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 26 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 28 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 30 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 32 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 34 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 36 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,536 - ERROR - Failed to process question 38 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,537 - ERROR - Failed to process question 40 for story We_Stand_Up: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,538 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-27 18:27:06,540 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-27 18:27:06,542 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,542 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,543 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,544 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,544 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,544 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,544 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: ANTHROPIC_API_KEY environment variable not set. Set it with: export ANTHROPIC_API_KEY='your-key'
2026-01-27 18:27:06,545 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-27 18:27:06,550 - INFO - 
============================================================
2026-01-27 18:27:06,550 - INFO - Survey complete!
2026-01-27 18:27:06,551 - INFO - Processed: 28/28 stories
2026-01-27 18:27:06,551 - INFO - Failed: 0 stories
2026-01-27 18:27:06,551 - INFO - Total cost: $0.0000
2026-01-27 18:27:06,551 - INFO - Total tokens: 0
2026-01-27 18:27:06,551 - INFO - ============================================================

2026-01-27 18:27:06,551 - INFO - 
============================================================
2026-01-27 18:27:06,551 - INFO - Step 4: Learning PyReason Rules
2026-01-27 18:27:06,552 - INFO - ============================================================
2026-01-27 18:27:06,552 - INFO - ============================================================
2026-01-27 18:27:06,552 - INFO - RULE LEARNING
2026-01-27 18:27:06,552 - INFO - ============================================================
2026-01-27 18:27:06,552 - INFO - Loading survey results from: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 18:27:06,554 - INFO - Found 28 survey result files
2026-01-27 18:27:06,576 - INFO - Successfully loaded 28 survey results
2026-01-27 18:27:06,576 - INFO - Extracting feature scores...
2026-01-27 18:27:06,576 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,576 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,577 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-01-27 18:27:06,578 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-01-27 18:27:06,579 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,580 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,581 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,582 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,583 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-01-27 18:27:06,584 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-01-27 18:27:06,585 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-01-27 18:27:06,586 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-01-27 18:27:06,587 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-01-27 18:27:06,588 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-01-27 18:27:06,589 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,590 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:27:06,591 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-01-27 18:27:06,592 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-01-27 18:27:06,593 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-01-27 18:27:06,594 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,595 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,596 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,596 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,596 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,596 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,596 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,597 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,597 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,597 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,597 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,597 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,598 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,599 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-01-27 18:27:06,600 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-01-27 18:27:06,601 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-01-27 18:27:06,602 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-01-27 18:27:06,603 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,604 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,605 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,606 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-01-27 18:27:06,607 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-01-27 18:27:06,608 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,609 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:27:06,610 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,611 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,612 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,613 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,614 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,615 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,616 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,617 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-01-27 18:27:06,618 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-01-27 18:27:06,619 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,620 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,621 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-01-27 18:27:06,622 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,623 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,624 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-01-27 18:27:06,625 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-01-27 18:27:06,626 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,627 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,628 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,629 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,629 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,629 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:27:06,629 - INFO - Extracted scores for 28 stories and 0 features
2026-01-27 18:27:06,629 - INFO - Learning PyReason rules...
2026-01-27 18:27:06,629 - INFO - Configuration:
2026-01-27 18:27:06,629 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-27 18:27:06,629 - INFO -   - Min confidence: 0.0
2026-01-27 18:27:06,629 - INFO -   - Min support: 0
2026-01-27 18:27:06,629 - INFO - Learning rules for 0 features...
2026-01-27 18:27:06,629 - INFO - Learned 0 rules
2026-01-27 18:27:06,631 - INFO - Saved 0 rules to output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:27:06,631 - INFO - ============================================================
2026-01-27 18:27:06,632 - INFO - RULE LEARNING COMPLETE
2026-01-27 18:27:06,632 - INFO - ============================================================
2026-01-27 18:27:06,632 - INFO - Stories processed: 28
2026-01-27 18:27:06,632 - INFO - Features: 0
2026-01-27 18:27:06,632 - INFO - Rules learned: 0
2026-01-27 18:27:06,632 - INFO - Rules saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:27:06,632 - INFO - ============================================================
2026-01-27 18:27:06,632 - INFO - 
✓ Rules learned and saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:27:06,632 - INFO - 
Phase 1 completed successfully!
2026-01-27 18:27:06,632 - INFO - Output directory: output/phase1
2026-01-27 18:27:06,633 - INFO - ============================================================
2026-01-27 18:27:06,633 - INFO - Execution completed successfully!
2026-01-27 18:27:06,633 - INFO - ============================================================
2026-01-27 18:31:34,484 - INFO - ============================================================
2026-01-27 18:31:34,484 - INFO - CONNECT Project - Phase 1
2026-01-27 18:31:34,484 - INFO - Problem: inverse
2026-01-27 18:31:34,484 - INFO - ============================================================
2026-01-27 18:31:34,485 - INFO - 
============================================================
2026-01-27 18:31:34,485 - INFO - PHASE 1: TRAINING
2026-01-27 18:31:34,485 - INFO - ============================================================
2026-01-27 18:31:34,485 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 18:31:34,486 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 18:31:34,506 - INFO - Successfully loaded 28 stories
2026-01-27 18:31:34,506 - INFO - Loaded 28 training stories
2026-01-27 18:31:34,507 - INFO - Survey results will be saved to: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 18:31:34,513 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 18:31:34,513 - INFO - Story A_Piece_of_Yellow_Soap already processed, skipping
2026-01-27 18:31:34,514 - INFO - Processing story: About_a_Hum
2026-01-27 18:31:34,515 - INFO - Story About_a_Hum already processed, skipping
2026-01-27 18:31:34,516 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 18:31:34,516 - INFO - Story All_Summer_in_a_Day_Ray_Bradbury already processed, skipping
2026-01-27 18:31:34,517 - INFO - Processing story: Back_To_The_Wall
2026-01-27 18:31:34,517 - INFO - Story Back_To_The_Wall already processed, skipping
2026-01-27 18:31:34,518 - INFO - Processing story: Community_Time
2026-01-27 18:31:34,519 - INFO - Story Community_Time already processed, skipping
2026-01-27 18:31:34,519 - INFO - Processing story: Fleabags
2026-01-27 18:31:34,520 - INFO - Story Fleabags already processed, skipping
2026-01-27 18:31:34,521 - INFO - Processing story: Gravity_Reduced
2026-01-27 18:31:34,521 - INFO - Story Gravity_Reduced already processed, skipping
2026-01-27 18:31:34,522 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 18:31:34,522 - INFO - Story Harrison_Bergeron_Kurt_Vonnegut already processed, skipping
2026-01-27 18:31:34,523 - INFO - Processing story: Honeybee
2026-01-27 18:31:34,524 - INFO - Story Honeybee already processed, skipping
2026-01-27 18:31:34,525 - INFO - Processing story: Last_Long_Night
2026-01-27 18:31:34,525 - INFO - Story Last_Long_Night already processed, skipping
2026-01-27 18:31:34,526 - INFO - Processing story: Raindrop_Snowflake
2026-01-27 18:31:34,526 - INFO - Story Raindrop_Snowflake already processed, skipping
2026-01-27 18:31:34,527 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-27 18:31:34,528 - INFO - Story Redemption_of_the_Cursed_Village already processed, skipping
2026-01-27 18:31:34,529 - INFO - Processing story: Rice
2026-01-27 18:31:34,529 - INFO - Story Rice already processed, skipping
2026-01-27 18:31:34,530 - INFO - Processing story: Swallowed
2026-01-27 18:31:34,530 - INFO - Story Swallowed already processed, skipping
2026-01-27 18:31:34,531 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-27 18:31:34,532 - INFO - Story The_Ants_and_The_Locusts already processed, skipping
2026-01-27 18:31:34,533 - INFO - Processing story: The_Christmas_Monks
2026-01-27 18:31:34,533 - INFO - Story The_Christmas_Monks already processed, skipping
2026-01-27 18:31:34,534 - INFO - Processing story: The_Circuit
2026-01-27 18:31:34,534 - INFO - Story The_Circuit already processed, skipping
2026-01-27 18:31:34,536 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-27 18:31:34,536 - INFO - Story The_Fire_That_Fed_the_People already processed, skipping
2026-01-27 18:31:34,537 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-27 18:31:34,537 - INFO - Story The_Gentleman_of_the_Jungle already processed, skipping
2026-01-27 18:31:34,538 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-27 18:31:34,539 - INFO - Story The_Pedestrian_Ray_Bradbury already processed, skipping
2026-01-27 18:31:34,540 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-27 18:31:34,540 - INFO - Story The_People_who_Dug_for_Rain already processed, skipping
2026-01-27 18:31:34,541 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-27 18:31:34,541 - INFO - Story The_Strangers_That_Came_to_Town_Ambrose_Flack already processed, skipping
2026-01-27 18:31:34,542 - INFO - Processing story: The_Stretcher
2026-01-27 18:31:34,543 - INFO - Story The_Stretcher already processed, skipping
2026-01-27 18:31:34,545 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-27 18:31:34,546 - INFO - Story The_village_that_Shared_the_Moonlight already processed, skipping
2026-01-27 18:31:34,547 - INFO - Processing story: War_of_the_Wall
2026-01-27 18:31:34,547 - INFO - Story War_of_the_Wall already processed, skipping
2026-01-27 18:31:34,548 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-27 18:31:34,548 - INFO - Story Warrior_Women_Nicaragua already processed, skipping
2026-01-27 18:31:34,549 - INFO - Processing story: We_Stand_Up
2026-01-27 18:31:34,550 - INFO - Story We_Stand_Up already processed, skipping
2026-01-27 18:31:34,551 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-27 18:31:34,551 - INFO - Story Whose_Voice_We_Wanted_to_Hear already processed, skipping
2026-01-27 18:31:34,555 - INFO - 
============================================================
2026-01-27 18:31:34,555 - INFO - Survey complete!
2026-01-27 18:31:34,555 - INFO - Processed: 28/28 stories
2026-01-27 18:31:34,555 - INFO - Failed: 0 stories
2026-01-27 18:31:34,555 - INFO - Total cost: $0.0000
2026-01-27 18:31:34,555 - INFO - Total tokens: 0
2026-01-27 18:31:34,555 - INFO - ============================================================

2026-01-27 18:31:34,555 - INFO - 
============================================================
2026-01-27 18:31:34,555 - INFO - Step 4: Learning PyReason Rules
2026-01-27 18:31:34,556 - INFO - ============================================================
2026-01-27 18:31:34,556 - INFO - ============================================================
2026-01-27 18:31:34,556 - INFO - RULE LEARNING
2026-01-27 18:31:34,556 - INFO - ============================================================
2026-01-27 18:31:34,556 - INFO - Loading survey results from: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 18:31:34,557 - INFO - Found 28 survey result files
2026-01-27 18:31:34,577 - INFO - Successfully loaded 28 survey results
2026-01-27 18:31:34,577 - INFO - Extracting feature scores...
2026-01-27 18:31:34,577 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,578 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-01-27 18:31:34,579 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,580 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,581 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,582 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,583 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-01-27 18:31:34,584 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-01-27 18:31:34,585 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-01-27 18:31:34,586 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-01-27 18:31:34,587 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-01-27 18:31:34,588 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,589 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,590 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-01-27 18:31:34,591 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-01-27 18:31:34,592 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-01-27 18:31:34,593 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,594 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,595 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,596 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,597 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-01-27 18:31:34,598 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-01-27 18:31:34,599 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-01-27 18:31:34,600 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-01-27 18:31:34,601 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,602 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,603 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,604 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-01-27 18:31:34,605 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-01-27 18:31:34,606 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,607 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,608 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,609 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 18:31:34,610 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,611 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,612 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,613 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,614 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,615 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-01-27 18:31:34,616 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-01-27 18:31:34,617 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,618 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,619 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-01-27 18:31:34,620 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-01-27 18:31:34,621 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,622 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,623 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-01-27 18:31:34,624 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,625 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,626 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 18:31:34,627 - INFO - Extracted scores for 28 stories and 0 features
2026-01-27 18:31:34,627 - INFO - Learning PyReason rules...
2026-01-27 18:31:34,627 - INFO - Configuration:
2026-01-27 18:31:34,627 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-27 18:31:34,627 - INFO -   - Min confidence: 0.0
2026-01-27 18:31:34,627 - INFO -   - Min support: 0
2026-01-27 18:31:34,627 - INFO - Learning rules for 0 features...
2026-01-27 18:31:34,628 - INFO - Learned 0 rules
2026-01-27 18:31:34,629 - INFO - Saved 0 rules to output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:31:34,629 - INFO - ============================================================
2026-01-27 18:31:34,629 - INFO - RULE LEARNING COMPLETE
2026-01-27 18:31:34,629 - INFO - ============================================================
2026-01-27 18:31:34,629 - INFO - Stories processed: 28
2026-01-27 18:31:34,629 - INFO - Features: 0
2026-01-27 18:31:34,629 - INFO - Rules learned: 0
2026-01-27 18:31:34,629 - INFO - Rules saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:31:34,629 - INFO - ============================================================
2026-01-27 18:31:34,630 - INFO - 
✓ Rules learned and saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 18:31:34,630 - INFO - 
Phase 1 completed successfully!
2026-01-27 18:31:34,630 - INFO - Output directory: output/phase1
2026-01-27 18:31:34,630 - INFO - ============================================================
2026-01-27 18:31:34,631 - INFO - Execution completed successfully!
2026-01-27 18:31:34,631 - INFO - ============================================================
2026-01-27 18:38:08,905 - INFO - ============================================================
2026-01-27 18:38:08,905 - INFO - CONNECT Project - Phase 1
2026-01-27 18:38:08,905 - INFO - Problem: inverse
2026-01-27 18:38:08,905 - INFO - ============================================================
2026-01-27 18:38:08,905 - INFO - 
============================================================
2026-01-27 18:38:08,906 - INFO - PHASE 1: TRAINING
2026-01-27 18:38:08,906 - INFO - ============================================================
2026-01-27 18:38:08,906 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 18:38:08,907 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 18:38:08,929 - INFO - Successfully loaded 28 stories
2026-01-27 18:38:08,930 - INFO - Loaded 28 training stories
2026-01-27 18:38:08,932 - INFO - Survey results will be saved to: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 18:38:08,940 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 18:38:08,984 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:17,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:17,726 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:24,335 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:24,337 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:32,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:32,481 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:39,385 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:39,386 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:44,980 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:44,982 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:52,261 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:52,263 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:38:59,500 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:38:59,501 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:07,460 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:07,462 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:13,130 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:13,131 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:20,025 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:20,028 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:29,835 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:29,837 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:38,092 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:38,094 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:45,750 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:45,752 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:39:52,743 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:39:52,745 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:00,027 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:00,029 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:07,439 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:07,441 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:14,395 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:14,397 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:23,592 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:23,594 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:31,341 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:31,343 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:38,406 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:38,412 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 18:40:38,414 - INFO - Processing story: About_a_Hum
2026-01-27 18:40:38,416 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:46,398 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:46,400 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:40:53,470 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:40:53,472 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:00,460 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:00,462 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:08,108 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:08,110 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:15,646 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:15,647 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:23,157 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:23,159 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:31,006 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:31,008 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:37,865 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:37,867 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:44,267 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:44,269 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:51,027 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:51,029 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:41:59,148 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:41:59,150 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:07,295 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:07,296 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:15,025 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:15,026 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:23,060 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:23,062 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:31,430 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:31,432 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:40,428 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:40,430 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:46,867 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:46,869 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:42:54,328 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:42:54,330 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:02,718 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:02,720 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:10,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:10,280 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 18:43:10,282 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 18:43:10,284 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:18,589 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:18,591 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:27,175 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:27,177 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:36,314 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:36,315 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:45,593 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:45,595 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:43:53,664 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:43:53,666 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:00,891 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:00,893 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:07,865 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:07,867 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:16,146 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:16,148 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:23,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:23,332 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:31,504 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:31,506 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:41,054 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:41,056 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:49,365 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:49,367 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:44:58,702 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:44:58,704 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:09,182 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:09,184 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:18,174 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:18,176 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:25,095 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:25,097 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:33,194 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:33,196 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:42,707 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:42,709 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:51,245 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:51,247 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:45:59,431 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:45:59,441 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 18:45:59,443 - INFO - Processing story: Back_To_The_Wall
2026-01-27 18:45:59,448 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:05,952 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:05,954 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:12,787 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:12,789 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:18,212 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:18,214 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:25,538 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:25,540 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:32,674 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:32,676 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:38,910 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:38,912 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:46,169 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:46,171 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:52,505 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:52,506 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:46:59,067 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:46:59,069 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:05,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:05,467 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:12,655 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:12,657 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:19,431 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:19,433 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:26,755 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:26,757 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:33,426 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:33,428 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:40,537 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:40,539 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:47,734 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:47,736 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:47:54,008 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:47:54,011 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:01,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:01,528 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:08,516 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:08,518 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:14,944 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:14,948 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 18:48:14,951 - INFO - Processing story: Community_Time
2026-01-27 18:48:14,953 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:22,384 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:22,386 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:31,763 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:31,765 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:39,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:39,832 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:49,662 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:49,664 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:48:57,849 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:48:57,851 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:05,804 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:05,806 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:14,134 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:14,136 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:21,935 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:21,937 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:29,561 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:29,563 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:41,011 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:41,013 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:50,156 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:50,158 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:49:58,614 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:49:58,616 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:13,103 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:13,105 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:21,357 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:21,359 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:29,856 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:29,858 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:38,521 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:38,523 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:46,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:46,043 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:50:56,575 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:50:56,577 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:06,162 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:06,163 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:14,447 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:14,452 - INFO - ✓ Saved: Community_Time.json
2026-01-27 18:51:14,455 - INFO - Processing story: Fleabags
2026-01-27 18:51:14,457 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:21,066 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:21,068 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:28,205 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:28,207 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:34,190 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:34,193 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:40,515 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:40,517 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:48,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:48,498 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:51:55,768 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:51:55,770 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:02,819 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:02,821 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:09,483 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:09,485 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:17,185 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:17,187 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:24,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:24,042 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:31,088 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:31,089 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:37,845 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:37,846 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:44,897 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:44,898 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:51,018 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:51,020 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:52:59,549 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:52:59,551 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:06,651 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:06,654 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:12,983 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:12,985 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:19,459 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:19,461 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:26,152 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:26,154 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:32,940 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:32,946 - INFO - ✓ Saved: Fleabags.json
2026-01-27 18:53:32,948 - INFO - Processing story: Gravity_Reduced
2026-01-27 18:53:32,951 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:39,336 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:39,338 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:46,092 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:46,094 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:53:54,297 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:53:54,299 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:00,794 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:00,796 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:07,083 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:07,085 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:14,549 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:14,550 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:22,177 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:22,179 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:28,809 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:28,811 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:37,189 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:37,191 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:44,704 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:44,705 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:52,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:52,320 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:54:59,716 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:54:59,718 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:06,455 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:06,457 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:13,198 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:13,200 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:21,914 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:21,916 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:28,978 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:28,980 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:36,909 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:36,911 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:43,581 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:43,583 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:52,276 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:52,277 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:55:59,550 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:55:59,556 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-27 18:55:59,559 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 18:55:59,561 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:07,045 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:07,046 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:15,394 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:15,396 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:23,405 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:23,406 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:31,870 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:31,872 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:40,840 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:40,842 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:56:49,841 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:56:49,843 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:01,405 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:01,407 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:10,932 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:10,935 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:19,363 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:19,365 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:28,450 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:28,452 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:38,316 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:38,318 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:45,833 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:45,835 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:57:53,530 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:57:53,533 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:02,263 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:02,265 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:11,762 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:11,763 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:20,624 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:20,626 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:27,708 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:27,710 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:36,123 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:36,125 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:47,611 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:47,613 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:58:54,784 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:58:54,791 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-27 18:58:54,795 - INFO - Processing story: Honeybee
2026-01-27 18:58:54,798 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:03,509 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:03,511 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:10,799 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:10,801 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:19,436 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:19,438 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:27,896 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:27,898 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:35,855 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:35,857 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:43,958 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:43,960 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:51,709 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:51,711 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 18:59:59,169 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 18:59:59,171 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:06,462 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:06,464 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:13,850 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:13,852 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:21,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:21,043 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:28,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:28,873 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:35,503 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:35,505 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:44,381 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:44,383 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:00:52,731 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:00:52,733 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:00,420 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:00,422 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:08,859 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:08,861 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:16,352 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:16,354 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:23,752 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:23,754 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:31,066 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:31,074 - INFO - ✓ Saved: Honeybee.json
2026-01-27 19:01:31,079 - INFO - Processing story: Last_Long_Night
2026-01-27 19:01:31,081 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:40,046 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:40,049 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:48,350 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:48,352 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:01:56,254 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:01:56,256 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:04,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:04,126 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:11,177 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:11,179 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:19,947 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:19,949 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:27,954 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:27,956 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:36,252 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:36,254 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:44,555 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:44,557 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:02:52,901 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:02:52,903 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:00,484 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:00,486 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:09,552 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:09,554 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:15,811 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:15,813 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:22,448 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:22,450 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:30,014 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:30,016 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:38,115 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:38,117 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:47,167 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:47,169 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:03:54,420 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:03:54,422 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:02,953 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:02,954 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:04,178 - INFO - ============================================================
2026-01-27 19:04:04,178 - INFO - CONNECT Project - Phase 1
2026-01-27 19:04:04,179 - INFO - Problem: inverse
2026-01-27 19:04:04,179 - INFO - ============================================================
2026-01-27 19:04:04,179 - INFO - 
============================================================
2026-01-27 19:04:04,179 - INFO - PHASE 1: TRAINING
2026-01-27 19:04:04,179 - INFO - ============================================================
2026-01-27 19:04:04,179 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:04:04,180 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:04:04,208 - INFO - Successfully loaded 28 stories
2026-01-27 19:04:04,208 - INFO - Loaded 28 training stories
2026-01-27 19:04:04,211 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:04:04,219 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:04:04,242 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,478 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,479 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,480 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,482 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,482 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,484 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,485 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,485 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,487 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,489 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,489 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,490 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,491 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,491 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,492 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,494 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,494 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,495 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,497 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,497 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,498 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,500 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,500 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,501 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,503 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,503 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,504 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,506 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,506 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,507 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,509 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,509 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,510 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,512 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,512 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,513 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,515 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,515 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,516 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,518 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,518 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,519 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,521 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,521 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,522 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,524 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,524 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,525 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,527 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,527 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,528 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,530 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,530 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,531 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,533 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,533 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,534 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,536 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,536 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,539 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 19:04:04,541 - INFO - Processing story: About_a_Hum
2026-01-27 19:04:04,544 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,545 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,546 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,547 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,548 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,548 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,550 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,551 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,551 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,553 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,554 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,554 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,556 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,558 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,558 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,559 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,561 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,561 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,562 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,563 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,564 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,564 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,566 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,566 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,567 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,569 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,569 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,570 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,572 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,572 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,573 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,575 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,575 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,576 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,578 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,578 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,580 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,581 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,581 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,583 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,584 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,584 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,586 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,587 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,587 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,589 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,590 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,590 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,592 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,593 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,593 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,595 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,596 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,597 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,598 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,599 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,600 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,601 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,602 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,603 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,605 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 19:04:04,608 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 19:04:04,610 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,612 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,612 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,613 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,615 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,615 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,617 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,618 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,618 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,620 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,622 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,622 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,624 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,625 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,625 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,627 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,629 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,629 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,630 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,632 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,632 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,633 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,635 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,635 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,636 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,638 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,638 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,639 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,641 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,641 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,643 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,645 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,645 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,647 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,648 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,648 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,650 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,651 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,652 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,653 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,655 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,655 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,656 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,658 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,658 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,660 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,661 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,661 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,663 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,665 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,665 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,666 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,668 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,668 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,669 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,671 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,671 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,672 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,674 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,674 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,677 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 19:04:04,680 - INFO - Processing story: Back_To_The_Wall
2026-01-27 19:04:04,683 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,684 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,684 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,686 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,687 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,687 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,689 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,690 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,690 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,692 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,693 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,693 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,695 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,697 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,697 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,698 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,700 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,700 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,701 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:04,703 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:04,703 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,464 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,467 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,467 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,468 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,470 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,470 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,471 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,473 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,473 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,475 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,476 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,476 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,478 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,479 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,480 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,481 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,482 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,482 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,484 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,485 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,486 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,487 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,488 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,489 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,490 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,492 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,492 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,493 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,495 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,495 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,496 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,497 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,498 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,500 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,502 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,502 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,503 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,505 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,505 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,507 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 19:04:05,510 - INFO - Processing story: Community_Time
2026-01-27 19:04:05,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,514 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,514 - ERROR - Failed to process question 2 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,516 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,517 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,517 - ERROR - Failed to process question 4 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,519 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,520 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,520 - ERROR - Failed to process question 6 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,521 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,523 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,523 - ERROR - Failed to process question 8 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,524 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,526 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,526 - ERROR - Failed to process question 10 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,527 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,529 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,529 - ERROR - Failed to process question 12 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,530 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,532 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,532 - ERROR - Failed to process question 14 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,533 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,535 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,535 - ERROR - Failed to process question 16 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,538 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,538 - ERROR - Failed to process question 18 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,539 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,541 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,541 - ERROR - Failed to process question 20 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,542 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,544 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,544 - ERROR - Failed to process question 22 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,545 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,547 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,547 - ERROR - Failed to process question 24 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,548 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,550 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,550 - ERROR - Failed to process question 26 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,551 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,553 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,553 - ERROR - Failed to process question 28 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,555 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,557 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,557 - ERROR - Failed to process question 30 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,558 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,560 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,560 - ERROR - Failed to process question 32 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,561 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,563 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,563 - ERROR - Failed to process question 34 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,564 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,565 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,566 - ERROR - Failed to process question 36 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,567 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,569 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,569 - ERROR - Failed to process question 38 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,570 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,571 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,572 - ERROR - Failed to process question 40 for story Community_Time: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,574 - INFO - ✓ Saved: Community_Time.json
2026-01-27 19:04:05,578 - INFO - Processing story: Fleabags
2026-01-27 19:04:05,581 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,582 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,582 - ERROR - Failed to process question 2 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,583 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,585 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,585 - ERROR - Failed to process question 4 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,587 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,588 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,588 - ERROR - Failed to process question 6 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,589 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,591 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,591 - ERROR - Failed to process question 8 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,593 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,594 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,594 - ERROR - Failed to process question 10 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,595 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,597 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,597 - ERROR - Failed to process question 12 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,598 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,600 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,600 - ERROR - Failed to process question 14 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,601 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,603 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,603 - ERROR - Failed to process question 16 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,604 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,606 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,606 - ERROR - Failed to process question 18 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,608 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,609 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,609 - ERROR - Failed to process question 20 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,611 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,612 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,612 - ERROR - Failed to process question 22 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,613 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,615 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,615 - ERROR - Failed to process question 24 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,616 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,618 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,618 - ERROR - Failed to process question 26 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,619 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,621 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,621 - ERROR - Failed to process question 28 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,624 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,625 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,625 - ERROR - Failed to process question 30 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,626 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,628 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,628 - ERROR - Failed to process question 32 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,629 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,631 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,631 - ERROR - Failed to process question 34 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,632 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,634 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,634 - ERROR - Failed to process question 36 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,635 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,637 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,637 - ERROR - Failed to process question 38 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,638 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,640 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,640 - ERROR - Failed to process question 40 for story Fleabags: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,643 - INFO - ✓ Saved: Fleabags.json
2026-01-27 19:04:05,647 - INFO - Processing story: Gravity_Reduced
2026-01-27 19:04:05,650 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,652 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,652 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,653 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,655 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,655 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,656 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,657 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,658 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,659 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,661 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,661 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,662 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,664 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,664 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,665 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,667 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,667 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,668 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,669 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,670 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,671 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,672 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,673 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,674 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,675 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,675 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,677 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,678 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,679 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,680 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,681 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,681 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,683 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,685 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,685 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,686 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,688 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,688 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,689 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,691 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,691 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,692 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,693 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,694 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,695 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,696 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,697 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,698 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,699 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,700 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,701 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,702 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,703 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,704 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,706 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,706 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,707 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,710 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,710 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,712 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-27 19:04:05,716 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 19:04:05,718 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,720 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,720 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,722 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,724 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,724 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,725 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,727 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,727 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,728 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,730 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,730 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,731 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,733 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,733 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,734 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,736 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,736 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,738 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,739 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,739 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,741 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,742 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,743 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,744 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,746 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,746 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,747 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,748 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,748 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,750 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,751 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,752 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,753 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,755 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,755 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,756 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,758 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,758 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,759 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,761 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,761 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,763 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,765 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,765 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,766 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,768 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,768 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,769 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,771 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,771 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,773 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,775 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,775 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,776 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,778 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,778 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,780 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,781 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,781 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,784 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-27 19:04:05,789 - INFO - Processing story: Honeybee
2026-01-27 19:04:05,792 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,793 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,794 - ERROR - Failed to process question 2 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,795 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,797 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,798 - ERROR - Failed to process question 4 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,799 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,801 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,801 - ERROR - Failed to process question 6 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,802 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,804 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,804 - ERROR - Failed to process question 8 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,805 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,807 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,807 - ERROR - Failed to process question 10 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,809 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,810 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,810 - ERROR - Failed to process question 12 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,812 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,813 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,813 - ERROR - Failed to process question 14 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,815 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,816 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,817 - ERROR - Failed to process question 16 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,818 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,820 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,820 - ERROR - Failed to process question 18 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,822 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,824 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,824 - ERROR - Failed to process question 20 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,825 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,827 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,827 - ERROR - Failed to process question 22 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,828 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,830 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,830 - ERROR - Failed to process question 24 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,831 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,832 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,832 - ERROR - Failed to process question 26 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,833 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,835 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,835 - ERROR - Failed to process question 28 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,836 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,838 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,838 - ERROR - Failed to process question 30 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,839 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,841 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,841 - ERROR - Failed to process question 32 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,842 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,844 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,844 - ERROR - Failed to process question 34 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,846 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,848 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,848 - ERROR - Failed to process question 36 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,849 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,851 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,851 - ERROR - Failed to process question 38 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,852 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,854 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,854 - ERROR - Failed to process question 40 for story Honeybee: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,856 - INFO - ✓ Saved: Honeybee.json
2026-01-27 19:04:05,859 - INFO - Processing story: Last_Long_Night
2026-01-27 19:04:05,862 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,864 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,864 - ERROR - Failed to process question 2 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,866 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,867 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,867 - ERROR - Failed to process question 4 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,869 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,871 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,871 - ERROR - Failed to process question 6 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,872 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,874 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,874 - ERROR - Failed to process question 8 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,875 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,877 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,877 - ERROR - Failed to process question 10 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,879 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,880 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,880 - ERROR - Failed to process question 12 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,882 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,883 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,883 - ERROR - Failed to process question 14 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,885 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,886 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,886 - ERROR - Failed to process question 16 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,888 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,889 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,889 - ERROR - Failed to process question 18 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,891 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,893 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,893 - ERROR - Failed to process question 20 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,894 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,896 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,896 - ERROR - Failed to process question 22 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,897 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,899 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,899 - ERROR - Failed to process question 24 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,900 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,902 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,902 - ERROR - Failed to process question 26 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,903 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,905 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,905 - ERROR - Failed to process question 28 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,906 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,908 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,908 - ERROR - Failed to process question 30 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,909 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,911 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,911 - ERROR - Failed to process question 32 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,912 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,914 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,914 - ERROR - Failed to process question 34 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,915 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,917 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,917 - ERROR - Failed to process question 36 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,918 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,920 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,920 - ERROR - Failed to process question 38 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,921 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,922 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,922 - ERROR - Failed to process question 40 for story Last_Long_Night: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,925 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-27 19:04:05,928 - INFO - Processing story: Raindrop_Snowflake
2026-01-27 19:04:05,931 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,932 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,932 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,934 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,936 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,936 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,937 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,939 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,939 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,940 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,942 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,942 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,943 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,945 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,945 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,946 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,948 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,948 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,953 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,955 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,955 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,957 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,959 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,959 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,960 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,962 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,962 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,963 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,965 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,965 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,966 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,968 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,968 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,969 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,971 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,971 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,972 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,974 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,974 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,975 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,977 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,977 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,978 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,980 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,980 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,982 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,983 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,983 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,984 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,986 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,986 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,987 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,989 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,989 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,990 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,991 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,991 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,992 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:05,994 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,994 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:05,998 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-27 19:04:06,004 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-27 19:04:06,008 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,010 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,010 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,012 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,014 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,014 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,016 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,018 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,018 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,020 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,022 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,022 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,023 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,025 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,025 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,026 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,028 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,028 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,030 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,032 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,032 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,033 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,035 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,035 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,036 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,038 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,038 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,039 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,041 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,041 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,043 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,044 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,045 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,046 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,047 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,048 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,049 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,050 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,050 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,052 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,053 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,053 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,055 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,056 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,056 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,058 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,059 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,059 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,061 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,062 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,062 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,064 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,065 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,065 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,067 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,069 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,069 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,070 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,072 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,072 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,074 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-27 19:04:06,077 - INFO - Processing story: Rice
2026-01-27 19:04:06,080 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,082 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,082 - ERROR - Failed to process question 2 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,084 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,086 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,086 - ERROR - Failed to process question 4 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,087 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,089 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,089 - ERROR - Failed to process question 6 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,091 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,093 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,093 - ERROR - Failed to process question 8 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,094 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,096 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,096 - ERROR - Failed to process question 10 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,098 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,099 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,099 - ERROR - Failed to process question 12 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,101 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,103 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,103 - ERROR - Failed to process question 14 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,104 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,106 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,106 - ERROR - Failed to process question 16 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,107 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,109 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,109 - ERROR - Failed to process question 18 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,111 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,112 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,113 - ERROR - Failed to process question 20 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,114 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,116 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,116 - ERROR - Failed to process question 22 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,117 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,119 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,119 - ERROR - Failed to process question 24 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,120 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,122 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,123 - ERROR - Failed to process question 26 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,124 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,126 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,126 - ERROR - Failed to process question 28 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,127 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,129 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,129 - ERROR - Failed to process question 30 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,131 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,133 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,133 - ERROR - Failed to process question 32 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,134 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,136 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,136 - ERROR - Failed to process question 34 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,137 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,139 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,139 - ERROR - Failed to process question 36 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,140 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,142 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,142 - ERROR - Failed to process question 38 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,143 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,145 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,145 - ERROR - Failed to process question 40 for story Rice: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,147 - INFO - ✓ Saved: Rice.json
2026-01-27 19:04:06,150 - INFO - Processing story: Swallowed
2026-01-27 19:04:06,153 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,154 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,155 - ERROR - Failed to process question 2 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,156 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,158 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,158 - ERROR - Failed to process question 4 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,159 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,161 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,161 - ERROR - Failed to process question 6 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,162 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,163 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,163 - ERROR - Failed to process question 8 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,165 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,166 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,166 - ERROR - Failed to process question 10 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,168 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,169 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,170 - ERROR - Failed to process question 12 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,171 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,172 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,172 - ERROR - Failed to process question 14 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,174 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,175 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,176 - ERROR - Failed to process question 16 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,177 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,179 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,179 - ERROR - Failed to process question 18 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,180 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,181 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,181 - ERROR - Failed to process question 20 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,183 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,184 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,184 - ERROR - Failed to process question 22 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,186 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,188 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,188 - ERROR - Failed to process question 24 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,189 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,191 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,191 - ERROR - Failed to process question 26 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,192 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,194 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,194 - ERROR - Failed to process question 28 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,195 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,197 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,197 - ERROR - Failed to process question 30 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,198 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,200 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,200 - ERROR - Failed to process question 32 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,201 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,203 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,203 - ERROR - Failed to process question 34 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,204 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,206 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,206 - ERROR - Failed to process question 36 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,208 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,209 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,209 - ERROR - Failed to process question 38 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,211 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,212 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,212 - ERROR - Failed to process question 40 for story Swallowed: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,215 - INFO - ✓ Saved: Swallowed.json
2026-01-27 19:04:06,217 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-27 19:04:06,220 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,221 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,221 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,223 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,224 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,224 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,226 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,227 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,227 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,229 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,231 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,231 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,232 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,234 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,234 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,235 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,236 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,237 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,238 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,239 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,240 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,241 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,242 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,242 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,244 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,245 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,245 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,247 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,248 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,248 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,250 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,251 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,251 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,253 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,255 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,255 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,256 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,258 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,258 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,259 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,260 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,260 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,262 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,263 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,263 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,265 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,266 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,266 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,268 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,269 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,269 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,271 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,272 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,272 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,273 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,275 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,275 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,276 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,278 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,278 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,280 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-27 19:04:06,283 - INFO - Processing story: The_Christmas_Monks
2026-01-27 19:04:06,285 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,287 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,287 - ERROR - Failed to process question 2 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,288 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,290 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,291 - ERROR - Failed to process question 4 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,292 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,294 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,294 - ERROR - Failed to process question 6 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,296 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,298 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,298 - ERROR - Failed to process question 8 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,299 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,301 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,302 - ERROR - Failed to process question 10 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,302 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,305 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,305 - ERROR - Failed to process question 12 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,306 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,308 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,308 - ERROR - Failed to process question 14 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,311 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,311 - ERROR - Failed to process question 16 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,313 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,315 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,315 - ERROR - Failed to process question 18 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,316 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,318 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,318 - ERROR - Failed to process question 20 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,319 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,321 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,321 - ERROR - Failed to process question 22 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,323 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,325 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,325 - ERROR - Failed to process question 24 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,326 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,328 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,328 - ERROR - Failed to process question 26 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,329 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,331 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,331 - ERROR - Failed to process question 28 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,333 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,335 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,335 - ERROR - Failed to process question 30 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,336 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,338 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,338 - ERROR - Failed to process question 32 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,339 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,341 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,341 - ERROR - Failed to process question 34 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,342 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,345 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,345 - ERROR - Failed to process question 36 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,346 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,348 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,348 - ERROR - Failed to process question 38 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,350 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,352 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,352 - ERROR - Failed to process question 40 for story The_Christmas_Monks: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,354 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-27 19:04:06,357 - INFO - Processing story: The_Circuit
2026-01-27 19:04:06,359 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,361 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,361 - ERROR - Failed to process question 2 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,363 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,365 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,365 - ERROR - Failed to process question 4 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,366 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,368 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,368 - ERROR - Failed to process question 6 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,369 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,371 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,371 - ERROR - Failed to process question 8 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,372 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,374 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,374 - ERROR - Failed to process question 10 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,376 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,377 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,378 - ERROR - Failed to process question 12 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,379 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,381 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,381 - ERROR - Failed to process question 14 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,382 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,384 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,384 - ERROR - Failed to process question 16 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,386 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,388 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,388 - ERROR - Failed to process question 18 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,389 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,391 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,391 - ERROR - Failed to process question 20 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,393 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,394 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,394 - ERROR - Failed to process question 22 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,396 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,398 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,398 - ERROR - Failed to process question 24 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,399 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,401 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,401 - ERROR - Failed to process question 26 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,402 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,404 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,404 - ERROR - Failed to process question 28 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,405 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,406 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,407 - ERROR - Failed to process question 30 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,408 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,410 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,410 - ERROR - Failed to process question 32 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,411 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,413 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,413 - ERROR - Failed to process question 34 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,414 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,416 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,416 - ERROR - Failed to process question 36 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,417 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,419 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,419 - ERROR - Failed to process question 38 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,421 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,422 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,422 - ERROR - Failed to process question 40 for story The_Circuit: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,425 - INFO - ✓ Saved: The_Circuit.json
2026-01-27 19:04:06,427 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-27 19:04:06,429 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,431 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,431 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,432 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,434 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,434 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,435 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,437 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,437 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,439 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,440 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,440 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,442 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,443 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,443 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,445 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,446 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,446 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,448 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,450 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,450 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,451 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,452 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,453 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,454 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,455 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,455 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,457 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,458 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,458 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,460 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,461 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,461 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,463 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,464 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,464 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,467 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,469 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,469 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,471 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,472 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,472 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,474 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,475 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,476 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,477 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,478 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,479 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,480 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,481 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,482 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,483 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,485 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,485 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,486 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,488 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,488 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,489 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,491 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,491 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,494 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-27 19:04:06,498 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-27 19:04:06,500 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,502 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,502 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,503 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,505 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,505 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,506 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,508 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,508 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,509 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,511 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,511 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,514 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,514 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,515 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,517 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,517 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,518 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,520 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,520 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,521 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,523 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,523 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,524 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,526 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,526 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,528 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,529 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,530 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,530 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,532 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,532 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,533 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,535 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,535 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,538 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,538 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,539 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,541 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,541 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,542 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,544 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,544 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,546 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,547 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,548 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,549 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,551 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,551 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,552 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,554 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,554 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,555 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,557 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,557 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,558 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,559 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,559 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,562 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-27 19:04:06,565 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-27 19:04:06,567 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,569 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,569 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,571 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,573 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,573 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,575 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,576 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,577 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,577 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,579 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,579 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,581 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,582 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,583 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,584 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,586 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,586 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,587 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,589 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,589 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,591 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,592 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,593 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,594 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,596 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,596 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,597 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,599 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,600 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,601 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,603 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,603 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,604 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,606 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,606 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,607 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,609 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,609 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,610 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,612 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,612 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,613 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,615 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,615 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,616 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,618 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,618 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,620 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,621 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,622 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,623 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,625 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,625 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,626 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,628 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,628 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,629 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,632 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,632 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,635 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-27 19:04:06,638 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-27 19:04:06,641 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,643 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,643 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,644 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,646 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,646 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,647 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,649 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,649 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,651 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,652 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,652 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,654 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,655 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,656 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,657 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,659 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,659 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,660 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,662 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,662 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,663 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,665 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,665 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,666 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,668 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,668 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,669 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,671 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,671 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,672 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,674 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,674 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,675 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,677 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,677 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,678 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,680 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,680 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,681 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,683 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,683 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,684 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,686 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,686 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,687 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,689 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,689 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,690 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,691 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,691 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,693 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,694 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,694 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,696 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,697 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,697 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,699 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,700 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,701 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,703 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-27 19:04:06,706 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-27 19:04:06,709 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,712 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,712 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,714 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,716 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,717 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,718 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,720 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,721 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,722 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,724 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,725 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,726 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,729 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,729 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,730 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,732 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,733 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,734 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,736 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,736 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,738 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,740 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,740 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,742 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,744 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,744 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,747 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,749 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,750 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,751 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,754 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,754 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,755 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,757 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,758 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,759 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,761 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,761 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,762 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,764 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,765 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,766 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,768 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,769 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,770 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,773 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,773 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,774 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,777 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,777 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,778 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,780 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,781 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,782 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,785 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,785 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,786 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,789 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,789 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,792 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-27 19:04:06,796 - INFO - Processing story: The_Stretcher
2026-01-27 19:04:06,799 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,801 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,801 - ERROR - Failed to process question 2 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,803 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,805 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,805 - ERROR - Failed to process question 4 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,806 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,808 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,808 - ERROR - Failed to process question 6 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,810 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,812 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,812 - ERROR - Failed to process question 8 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,813 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,815 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,815 - ERROR - Failed to process question 10 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,816 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,818 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,818 - ERROR - Failed to process question 12 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,819 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,821 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,821 - ERROR - Failed to process question 14 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,822 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,824 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,824 - ERROR - Failed to process question 16 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,825 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,827 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,827 - ERROR - Failed to process question 18 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,828 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,830 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,830 - ERROR - Failed to process question 20 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,831 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,832 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,832 - ERROR - Failed to process question 22 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,834 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,837 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,837 - ERROR - Failed to process question 24 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,838 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,841 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,841 - ERROR - Failed to process question 26 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,842 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,844 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,844 - ERROR - Failed to process question 28 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,845 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,847 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,847 - ERROR - Failed to process question 30 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,848 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,849 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,849 - ERROR - Failed to process question 32 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,850 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,852 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,852 - ERROR - Failed to process question 34 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,853 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,855 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,855 - ERROR - Failed to process question 36 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,857 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,859 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,859 - ERROR - Failed to process question 38 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,860 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,862 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,862 - ERROR - Failed to process question 40 for story The_Stretcher: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,865 - INFO - ✓ Saved: The_Stretcher.json
2026-01-27 19:04:06,870 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-27 19:04:06,873 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,875 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,875 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,877 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,879 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,879 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,880 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,882 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,882 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,883 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,885 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,885 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,886 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,888 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,888 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,890 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,892 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,892 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,895 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,897 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,897 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,898 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,900 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,900 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,901 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,904 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,905 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,907 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,909 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,909 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,910 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,911 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,911 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,913 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,915 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,915 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,916 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,917 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,917 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,918 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,920 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,920 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,921 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,923 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,923 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,925 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,926 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,926 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,928 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,929 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,929 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,931 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,932 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,932 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,934 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,935 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,935 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,936 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,938 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,938 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,940 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-27 19:04:06,946 - INFO - Processing story: War_of_the_Wall
2026-01-27 19:04:06,948 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,951 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,951 - ERROR - Failed to process question 2 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,952 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,954 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,954 - ERROR - Failed to process question 4 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,955 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,957 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,957 - ERROR - Failed to process question 6 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,959 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,961 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,961 - ERROR - Failed to process question 8 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,963 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,965 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,965 - ERROR - Failed to process question 10 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,966 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:06,968 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:06,969 - ERROR - Failed to process question 12 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,322 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,324 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,324 - ERROR - Failed to process question 14 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,326 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,328 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,328 - ERROR - Failed to process question 16 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,329 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,331 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,331 - ERROR - Failed to process question 18 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,332 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,334 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,334 - ERROR - Failed to process question 20 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,336 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,337 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,338 - ERROR - Failed to process question 22 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,338 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,340 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,340 - ERROR - Failed to process question 24 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,342 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,343 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,344 - ERROR - Failed to process question 26 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,345 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,347 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,347 - ERROR - Failed to process question 28 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,348 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,350 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,350 - ERROR - Failed to process question 30 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,351 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,353 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,353 - ERROR - Failed to process question 32 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,355 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,356 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,357 - ERROR - Failed to process question 34 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,358 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,360 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,360 - ERROR - Failed to process question 36 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,361 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,363 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,363 - ERROR - Failed to process question 38 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,365 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,367 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,367 - ERROR - Failed to process question 40 for story War_of_the_Wall: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,369 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-27 19:04:07,372 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-27 19:04:07,374 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,376 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,376 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,377 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,379 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,379 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,380 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,382 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,382 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,383 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,385 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,385 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,386 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,388 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,388 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,389 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,391 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,391 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,393 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,394 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,394 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,395 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,397 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,397 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,399 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,400 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,400 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,402 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,403 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,403 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,405 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,406 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,406 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,408 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,409 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,409 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,411 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,412 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,413 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,414 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,415 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,415 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,417 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,418 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,418 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,420 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,421 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,421 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,423 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,424 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,424 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,426 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,427 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,427 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,429 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,430 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,430 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,432 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,433 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,433 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,436 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-27 19:04:07,439 - INFO - Processing story: We_Stand_Up
2026-01-27 19:04:07,441 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,443 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,443 - ERROR - Failed to process question 2 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,444 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,445 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,446 - ERROR - Failed to process question 4 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,447 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,449 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,449 - ERROR - Failed to process question 6 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,450 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,451 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,452 - ERROR - Failed to process question 8 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,453 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,454 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,455 - ERROR - Failed to process question 10 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,456 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,457 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,458 - ERROR - Failed to process question 12 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,459 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,461 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,461 - ERROR - Failed to process question 14 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,462 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,464 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,464 - ERROR - Failed to process question 16 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,465 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,467 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,467 - ERROR - Failed to process question 18 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,468 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,470 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,470 - ERROR - Failed to process question 20 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,471 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,473 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,473 - ERROR - Failed to process question 22 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,474 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,476 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,476 - ERROR - Failed to process question 24 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,478 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,479 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,479 - ERROR - Failed to process question 26 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,481 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,482 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,482 - ERROR - Failed to process question 28 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,484 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,485 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,485 - ERROR - Failed to process question 30 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,487 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,489 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,489 - ERROR - Failed to process question 32 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,490 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,492 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,492 - ERROR - Failed to process question 34 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,493 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,495 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,495 - ERROR - Failed to process question 36 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,496 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,498 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,498 - ERROR - Failed to process question 38 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,499 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,501 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,501 - ERROR - Failed to process question 40 for story We_Stand_Up: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,504 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-27 19:04:07,506 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-27 19:04:07,508 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,510 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,510 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,511 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,513 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,513 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,515 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,516 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,517 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,518 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,519 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,520 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,521 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,523 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,523 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,524 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,526 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,526 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,527 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,529 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,529 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,530 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,532 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,532 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,533 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,535 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,535 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,538 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,538 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,539 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,541 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,541 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,542 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,543 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,544 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,545 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,547 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,547 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,548 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,550 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,550 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,551 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,553 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,553 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,554 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,556 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,556 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,557 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,559 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,559 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,560 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,562 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,562 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,563 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,566 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,566 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,567 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:04:07,569 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,569 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: litellm.APIConnectionError: No module named 'boto3'
Traceback (most recent call last):
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/main.py", line 3621, in completion
    response = bedrock_converse_chat_completion.completion(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/chat/converse_handler.py", line 310, in completion
    credentials: Credentials = self.get_credentials(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 270, in get_credentials
    credentials, _cache_ttl = self._auth_with_access_key_and_secret_key(
  File "/home/dbavikad/miniconda3/envs/connect/lib/python3.10/site-packages/litellm/llms/bedrock/base_aws_llm.py", line 931, in _auth_with_access_key_and_secret_key
    import boto3
ModuleNotFoundError: No module named 'boto3'

2026-01-27 19:04:07,572 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-27 19:04:07,581 - INFO - 
============================================================
2026-01-27 19:04:07,581 - INFO - Survey complete!
2026-01-27 19:04:07,582 - INFO - Processed: 28/28 stories
2026-01-27 19:04:07,582 - INFO - Failed: 0 stories
2026-01-27 19:04:07,582 - INFO - Total cost: $0.0000
2026-01-27 19:04:07,582 - INFO - Total tokens: 0
2026-01-27 19:04:07,582 - INFO - ============================================================

2026-01-27 19:04:07,582 - INFO - 
============================================================
2026-01-27 19:04:07,582 - INFO - Step 4: Learning PyReason Rules
2026-01-27 19:04:07,582 - INFO - ============================================================
2026-01-27 19:04:07,582 - INFO - ============================================================
2026-01-27 19:04:07,582 - INFO - RULE LEARNING
2026-01-27 19:04:07,582 - INFO - ============================================================
2026-01-27 19:04:07,583 - INFO - Loading survey results from: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:04:07,584 - INFO - Found 28 survey result files
2026-01-27 19:04:07,617 - INFO - Successfully loaded 28 survey results
2026-01-27 19:04:07,617 - INFO - Extracting feature scores...
2026-01-27 19:04:07,617 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,617 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,617 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,617 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,617 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,618 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-01-27 19:04:07,619 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-01-27 19:04:07,620 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-01-27 19:04:07,621 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-01-27 19:04:07,622 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,622 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,622 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,622 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,623 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,624 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,625 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-01-27 19:04:07,626 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-01-27 19:04:07,627 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-01-27 19:04:07,628 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-01-27 19:04:07,629 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-01-27 19:04:07,630 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-01-27 19:04:07,631 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-01-27 19:04:07,632 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,633 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,634 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-01-27 19:04:07,635 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-01-27 19:04:07,636 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-01-27 19:04:07,637 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-01-27 19:04:07,638 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-01-27 19:04:07,639 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,640 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,641 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,642 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,643 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-01-27 19:04:07,644 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-01-27 19:04:07,645 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-01-27 19:04:07,646 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-01-27 19:04:07,647 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,648 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,649 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,650 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,651 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-01-27 19:04:07,652 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-01-27 19:04:07,653 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,654 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,655 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,656 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,657 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,658 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,659 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,660 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,661 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,662 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-01-27 19:04:07,663 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,664 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-01-27 19:04:07,665 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,666 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,667 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-01-27 19:04:07,668 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-01-27 19:04:07,669 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,670 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,671 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,672 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,672 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,672 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,672 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-27 19:04:07,672 - INFO - Extracted scores for 28 stories and 0 features
2026-01-27 19:04:07,672 - INFO - Learning PyReason rules...
2026-01-27 19:04:07,672 - INFO - Configuration:
2026-01-27 19:04:07,672 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-27 19:04:07,672 - INFO -   - Min confidence: 0.0
2026-01-27 19:04:07,672 - INFO -   - Min support: 0
2026-01-27 19:04:07,672 - INFO - Learning rules for 0 features...
2026-01-27 19:04:07,672 - INFO - Learned 0 rules
2026-01-27 19:04:07,676 - INFO - Saved 0 rules to output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:04:07,676 - INFO - ============================================================
2026-01-27 19:04:07,676 - INFO - RULE LEARNING COMPLETE
2026-01-27 19:04:07,677 - INFO - ============================================================
2026-01-27 19:04:07,677 - INFO - Stories processed: 28
2026-01-27 19:04:07,677 - INFO - Features: 0
2026-01-27 19:04:07,677 - INFO - Rules learned: 0
2026-01-27 19:04:07,677 - INFO - Rules saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:04:07,677 - INFO - ============================================================
2026-01-27 19:04:07,677 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:04:07,678 - INFO - 
Phase 1 completed successfully!
2026-01-27 19:04:07,678 - INFO - Output directory: output/phase1
2026-01-27 19:04:07,678 - INFO - ============================================================
2026-01-27 19:04:07,678 - INFO - Execution completed successfully!
2026-01-27 19:04:07,678 - INFO - ============================================================
2026-01-27 19:04:10,953 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:10,958 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-27 19:04:10,962 - INFO - Processing story: Raindrop_Snowflake
2026-01-27 19:04:10,965 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:17,217 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:17,219 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:24,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:24,303 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:31,476 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:31,478 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:37,632 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:37,634 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:43,973 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:43,975 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:50,450 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:50,452 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:04:56,513 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:04:56,515 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:01,589 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:01,591 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:07,814 - INFO - ============================================================
2026-01-27 19:05:07,814 - INFO - CONNECT Project - Phase 1
2026-01-27 19:05:07,814 - INFO - Problem: inverse
2026-01-27 19:05:07,815 - INFO - ============================================================
2026-01-27 19:05:07,815 - INFO - 
============================================================
2026-01-27 19:05:07,815 - INFO - PHASE 1: TRAINING
2026-01-27 19:05:07,815 - INFO - ============================================================
2026-01-27 19:05:07,815 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:05:07,816 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:05:07,837 - INFO - Successfully loaded 28 stories
2026-01-27 19:05:07,837 - INFO - Loaded 28 training stories
2026-01-27 19:05:07,840 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:05:07,846 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:05:07,867 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:08,302 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:08,304 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:09,288 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,288 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,289 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:09,588 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,588 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,589 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:09,888 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,888 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:09,890 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:10,182 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,182 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,184 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:10,471 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,472 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,473 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:10,763 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,763 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:10,765 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:11,016 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,016 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,019 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:11,308 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,308 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,310 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:11,608 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,608 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,610 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:11,904 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,904 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:11,906 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:12,202 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,202 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,203 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:12,495 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,495 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,496 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:12,774 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,775 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:12,776 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:13,082 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,082 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,083 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:13,387 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,387 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,388 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:13,682 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,682 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,686 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:13,980 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,980 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:13,982 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:14,280 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,281 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,282 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:14,581 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,581 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,582 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:14,861 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,862 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:14,864 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 19:05:14,866 - INFO - Processing story: About_a_Hum
2026-01-27 19:05:14,869 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:14,958 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:14,960 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:15,173 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,173 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,174 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:15,466 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,466 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,468 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:15,750 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,750 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:15,752 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:16,040 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,041 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,042 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:16,340 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,341 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,342 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:16,629 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,629 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,631 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:16,875 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,876 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:16,877 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:17,161 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,161 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,162 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:17,454 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,454 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,455 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:17,739 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,740 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:17,741 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:18,027 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,027 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,029 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:18,328 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,329 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,330 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:18,621 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,621 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,622 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:18,929 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,929 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:18,931 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:19,211 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,212 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,213 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:19,511 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,511 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:19,755 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,755 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,756 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:19,987 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,987 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:19,988 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:20,267 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,268 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,269 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:20,512 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,512 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,515 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 19:05:20,517 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 19:05:20,520 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:20,776 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,776 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:20,778 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:21,072 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,072 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,074 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:21,369 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,369 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,371 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:21,659 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,660 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,661 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:21,667 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:21,669 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:21,956 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,956 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:21,958 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:22,255 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,255 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,257 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:22,641 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,641 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,643 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:22,934 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,934 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:22,936 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:23,233 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,233 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,234 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:23,525 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,525 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,527 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:23,812 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,813 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:23,814 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:24,107 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,107 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,108 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:24,393 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,393 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,395 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:24,681 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,681 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:24,683 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:25,007 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,007 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,009 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:25,302 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,302 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,304 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:25,607 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,607 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,609 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:25,901 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,901 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:25,903 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:26,223 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,223 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,225 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:26,522 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,523 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,525 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 19:05:26,528 - INFO - Processing story: Back_To_The_Wall
2026-01-27 19:05:26,530 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:26,820 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,820 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:26,822 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:27,105 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,105 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,107 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:27,343 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,343 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,345 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:27,646 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,646 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:27,648 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:28,344 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,345 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,348 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:28,635 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,635 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,637 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:28,926 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,926 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:28,928 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:29,234 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,235 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,236 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:29,537 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,537 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,540 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:29,833 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,833 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:29,835 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:30,131 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,131 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,133 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:30,136 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:30,137 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:30,443 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,443 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,444 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:30,729 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,729 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:30,730 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:31,082 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,083 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,084 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:31,387 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,387 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,388 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:31,691 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,691 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:31,693 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:32,002 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,002 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,003 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:32,307 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,307 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:32,603 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,603 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,604 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:32,918 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,918 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:32,920 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 19:05:32,923 - INFO - Processing story: Community_Time
2026-01-27 19:05:32,925 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:33,209 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,209 - ERROR - Failed to process question 2 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,210 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:33,515 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,516 - ERROR - Failed to process question 4 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,517 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:33,814 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,814 - ERROR - Failed to process question 6 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:33,816 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:34,117 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,117 - ERROR - Failed to process question 8 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,118 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:34,408 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,408 - ERROR - Failed to process question 10 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,410 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:34,705 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,705 - ERROR - Failed to process question 12 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,706 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:34,992 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,992 - ERROR - Failed to process question 14 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:34,994 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:35,291 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,291 - ERROR - Failed to process question 16 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,292 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:35,588 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,588 - ERROR - Failed to process question 18 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,589 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:35,878 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,878 - ERROR - Failed to process question 20 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:35,879 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:36,084 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:36,086 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:36,176 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,176 - ERROR - Failed to process question 22 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,178 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:36,472 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,472 - ERROR - Failed to process question 24 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,473 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:36,772 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,772 - ERROR - Failed to process question 26 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:36,774 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:37,093 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,093 - ERROR - Failed to process question 28 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,094 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:37,394 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,394 - ERROR - Failed to process question 30 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,395 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:37,612 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,612 - ERROR - Failed to process question 32 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,614 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:37,873 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,873 - ERROR - Failed to process question 34 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:37,875 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:38,169 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,169 - ERROR - Failed to process question 36 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,171 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:38,464 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,464 - ERROR - Failed to process question 38 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,466 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:38,763 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,763 - ERROR - Failed to process question 40 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:38,765 - INFO - ✓ Saved: Community_Time.json
2026-01-27 19:05:38,856 - INFO - Processing story: Fleabags
2026-01-27 19:05:38,860 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:39,147 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,147 - ERROR - Failed to process question 2 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,149 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:39,458 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,458 - ERROR - Failed to process question 4 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,459 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:39,744 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,744 - ERROR - Failed to process question 6 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:39,746 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:40,003 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,003 - ERROR - Failed to process question 8 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,005 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:40,290 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,291 - ERROR - Failed to process question 10 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,292 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:40,583 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,583 - ERROR - Failed to process question 12 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,584 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:40,867 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,868 - ERROR - Failed to process question 14 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:40,869 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:41,164 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,164 - ERROR - Failed to process question 16 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,165 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:41,459 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,460 - ERROR - Failed to process question 18 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,462 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:41,724 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,724 - ERROR - Failed to process question 20 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:41,725 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:42,006 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,006 - ERROR - Failed to process question 22 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,007 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:42,308 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,308 - ERROR - Failed to process question 24 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:42,614 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,614 - ERROR - Failed to process question 26 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,615 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:42,619 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:42,621 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:42,921 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,921 - ERROR - Failed to process question 28 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:42,922 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:43,206 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,206 - ERROR - Failed to process question 30 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,207 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:43,504 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,505 - ERROR - Failed to process question 32 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,506 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:43,849 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,849 - ERROR - Failed to process question 34 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:43,851 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:44,133 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,133 - ERROR - Failed to process question 36 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,134 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:44,425 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,425 - ERROR - Failed to process question 38 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,427 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:44,715 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,715 - ERROR - Failed to process question 40 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:44,717 - INFO - ✓ Saved: Fleabags.json
2026-01-27 19:05:44,719 - INFO - Processing story: Gravity_Reduced
2026-01-27 19:05:44,722 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:45,015 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,015 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,016 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:45,267 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,267 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,269 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:45,502 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,503 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,504 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:45,760 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,760 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:45,761 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:46,041 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,041 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,042 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:46,328 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,328 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,329 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:46,637 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,638 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,639 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:46,850 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,850 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:46,851 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:47,153 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,153 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,154 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:47,451 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,451 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,452 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:47,698 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,698 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:47,699 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:48,082 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,082 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,084 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:48,378 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,378 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,379 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:48,673 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,674 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,675 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:48,951 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,951 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:48,952 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:49,242 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,243 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,244 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:49,533 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,533 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,535 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:49,822 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,822 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:49,823 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:50,114 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,114 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,115 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:50,396 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:50,398 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:50,419 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,419 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,421 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-27 19:05:50,424 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 19:05:50,427 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:50,714 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,715 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:50,716 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:51,000 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,000 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,002 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:51,305 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,306 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,307 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:51,596 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,596 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,598 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:51,878 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,878 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:51,880 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:52,197 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,197 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,198 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:52,501 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,501 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,502 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:52,786 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,786 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:52,787 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:53,075 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,075 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,077 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:53,371 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,371 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,373 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:53,635 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,635 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,636 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:53,942 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,943 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:53,944 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:54,411 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:54,411 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:54,413 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:54,692 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:54,692 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:54,693 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:55,000 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,000 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,002 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:55,308 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,308 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:55,598 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,598 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,599 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:55,915 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,916 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:55,917 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:56,201 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,201 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,202 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:56,495 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,495 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,497 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-27 19:05:56,502 - INFO - Processing story: Honeybee
2026-01-27 19:05:56,505 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:56,788 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,788 - ERROR - Failed to process question 2 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:56,789 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:57,080 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,080 - ERROR - Failed to process question 4 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,081 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:57,387 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,388 - ERROR - Failed to process question 6 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,389 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:57,659 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,659 - ERROR - Failed to process question 8 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,660 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:57,950 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,950 - ERROR - Failed to process question 10 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:57,952 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:58,215 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,215 - ERROR - Failed to process question 12 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,217 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:58,411 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:05:58,413 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:05:58,518 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,518 - ERROR - Failed to process question 14 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,520 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:58,799 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,799 - ERROR - Failed to process question 16 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:58,801 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:59,109 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,110 - ERROR - Failed to process question 18 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,111 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:59,433 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,433 - ERROR - Failed to process question 20 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,434 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:05:59,734 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,734 - ERROR - Failed to process question 22 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:05:59,736 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:06:00,032 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:06:00,033 - ERROR - Failed to process question 24 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:06:00,034 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:06:00,361 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:06:00,362 - ERROR - Failed to process question 26 for story Honeybee: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:06:00,363 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:06:00,639 - WARNING - 
Process interrupted by user
2026-01-27 19:06:05,275 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:05,276 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:11,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:11,482 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:17,679 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:17,681 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:25,115 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:25,121 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-27 19:06:25,124 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-27 19:06:25,126 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:38,354 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:38,356 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:46,732 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:46,735 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:06:55,449 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:06:55,451 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:01,975 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:01,977 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:03,461 - INFO - ============================================================
2026-01-27 19:07:03,461 - INFO - CONNECT Project - Phase 1
2026-01-27 19:07:03,461 - INFO - Problem: inverse
2026-01-27 19:07:03,461 - INFO - ============================================================
2026-01-27 19:07:03,462 - INFO - 
============================================================
2026-01-27 19:07:03,462 - INFO - PHASE 1: TRAINING
2026-01-27 19:07:03,462 - INFO - ============================================================
2026-01-27 19:07:03,462 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:07:03,463 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:07:03,482 - INFO - Successfully loaded 28 stories
2026-01-27 19:07:03,483 - INFO - Loaded 28 training stories
2026-01-27 19:07:03,485 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:07:03,491 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:07:03,514 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:04,464 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,464 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,466 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:04,724 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,724 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,726 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:04,953 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,953 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:04,954 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:05,149 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,149 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,150 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:05,377 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,378 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,379 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:05,588 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,588 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,590 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:05,812 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,812 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:05,813 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:06,041 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,041 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,044 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:06,280 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,280 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,282 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:06,572 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,572 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,573 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:06,806 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,806 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:06,807 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:07,029 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,029 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,031 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:07,259 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,259 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,260 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:07,480 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,480 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,481 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:07,709 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,709 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,710 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:07,938 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,938 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:07,939 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:08,170 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,171 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,172 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:08,405 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,406 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,407 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:08,656 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,656 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,657 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:08,888 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,888 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:08,891 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 19:07:08,894 - INFO - Processing story: About_a_Hum
2026-01-27 19:07:08,898 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:09,141 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,141 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,142 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:09,374 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,375 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,376 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:09,467 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:09,469 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:09,595 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,595 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,597 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:09,830 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,830 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:09,831 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:10,078 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,078 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,080 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:10,270 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,270 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,272 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:10,534 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,534 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:10,734 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,734 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,736 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:10,913 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,913 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:10,914 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:11,126 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,126 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,127 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:11,317 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,317 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,318 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:11,542 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,543 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,544 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:11,773 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,773 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:11,775 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:12,026 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,027 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,028 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:12,250 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,250 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,251 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:12,473 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,473 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,475 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:12,712 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,712 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,713 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:12,962 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,962 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:12,964 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:13,146 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,146 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,148 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:13,341 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,341 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,344 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 19:07:13,346 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 19:07:13,349 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:13,534 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,534 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:13,730 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,730 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,731 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:13,924 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,924 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:13,927 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:14,169 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,169 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,170 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:14,384 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,384 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,386 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:14,613 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,613 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,614 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:14,831 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,831 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:14,833 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:15,099 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,099 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,100 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:15,384 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,384 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,385 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:15,606 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,606 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,607 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:15,838 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,838 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:15,839 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:16,055 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,055 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,056 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:16,274 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,275 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,276 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:16,502 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,502 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,503 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:16,727 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,727 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,728 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:16,778 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:16,780 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:16,948 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,949 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:16,950 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:17,174 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,174 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,175 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:17,395 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,395 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,397 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:17,622 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,622 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,623 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:17,818 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,819 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:17,825 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 19:07:19,444 - INFO - Processing story: Back_To_The_Wall
2026-01-27 19:07:19,448 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:19,671 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:19,671 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:19,673 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:19,894 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:19,894 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:19,895 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:20,134 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,134 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,136 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:20,371 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,372 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,373 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:20,592 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,592 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,594 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:20,813 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,813 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:20,814 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:21,039 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,039 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,040 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:21,279 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,279 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,280 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:21,499 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,500 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,501 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:21,726 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,726 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:21,728 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:22,028 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,028 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,029 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:22,275 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,275 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,277 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:22,509 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,509 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,510 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:22,742 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,742 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,744 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:22,970 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,970 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:22,972 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:23,191 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,191 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,192 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:23,381 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,381 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,383 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:23,573 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,573 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,575 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:23,794 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,794 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:23,795 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:23,937 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:23,939 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:24,031 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,031 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,033 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 19:07:24,036 - INFO - Processing story: Community_Time
2026-01-27 19:07:24,039 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:24,275 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,275 - ERROR - Failed to process question 2 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,276 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:24,470 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,470 - ERROR - Failed to process question 4 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,471 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:24,655 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,655 - ERROR - Failed to process question 6 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,658 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:24,877 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,877 - ERROR - Failed to process question 8 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:24,878 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:25,106 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,107 - ERROR - Failed to process question 10 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,109 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:25,328 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,328 - ERROR - Failed to process question 12 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,329 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:25,575 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,575 - ERROR - Failed to process question 14 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,577 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:25,802 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,802 - ERROR - Failed to process question 16 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:25,803 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:26,021 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,021 - ERROR - Failed to process question 18 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,023 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:26,308 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,308 - ERROR - Failed to process question 20 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,310 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:26,551 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,551 - ERROR - Failed to process question 22 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,552 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:26,748 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,749 - ERROR - Failed to process question 24 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,750 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:26,971 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,971 - ERROR - Failed to process question 26 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:26,972 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:27,169 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,169 - ERROR - Failed to process question 28 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,171 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:27,387 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,387 - ERROR - Failed to process question 30 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,388 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:27,583 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,583 - ERROR - Failed to process question 32 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,584 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:27,818 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,818 - ERROR - Failed to process question 34 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:27,819 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:28,037 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,037 - ERROR - Failed to process question 36 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,038 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:28,261 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,261 - ERROR - Failed to process question 38 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,262 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:28,491 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,491 - ERROR - Failed to process question 40 for story Community_Time: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,494 - INFO - ✓ Saved: Community_Time.json
2026-01-27 19:07:28,496 - INFO - Processing story: Fleabags
2026-01-27 19:07:28,499 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:28,721 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,721 - ERROR - Failed to process question 2 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,723 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:28,970 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,970 - ERROR - Failed to process question 4 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:28,971 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:29,197 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,197 - ERROR - Failed to process question 6 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,199 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:29,425 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,425 - ERROR - Failed to process question 8 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,427 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:29,606 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,606 - ERROR - Failed to process question 10 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,608 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:29,834 - ERROR - Unexpected error calling LLM: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,834 - ERROR - Failed to process question 12 for story Fleabags: litellm.APIConnectionError: BedrockException - {"Message":"User: arn:aws:iam::626747814346:user/connect_finetune is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:626747814346:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"}
2026-01-27 19:07:29,835 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:07:29,891 - WARNING - 
Process interrupted by user
2026-01-27 19:07:29,944 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:29,945 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:37,535 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:37,537 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:44,940 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:44,942 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:07:53,008 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:07:53,010 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:00,452 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:00,454 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:08,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:08,087 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:15,774 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:15,776 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:22,980 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:22,982 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:29,963 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:29,965 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:38,147 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:38,150 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:45,376 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:45,378 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:52,451 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:52,453 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:08:58,982 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:08:58,987 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-27 19:08:58,989 - INFO - Processing story: Rice
2026-01-27 19:08:58,991 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:06,899 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:06,902 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:14,725 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:14,728 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:18,840 - INFO - ============================================================
2026-01-27 19:09:18,840 - INFO - CONNECT Project - Phase 1
2026-01-27 19:09:18,840 - INFO - Problem: inverse
2026-01-27 19:09:18,840 - INFO - ============================================================
2026-01-27 19:09:18,841 - INFO - 
============================================================
2026-01-27 19:09:18,841 - INFO - PHASE 1: TRAINING
2026-01-27 19:09:18,841 - INFO - ============================================================
2026-01-27 19:09:18,841 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:09:18,842 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:09:18,863 - INFO - Successfully loaded 28 stories
2026-01-27 19:09:18,864 - INFO - Loaded 28 training stories
2026-01-27 19:09:18,866 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:09:18,873 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:09:18,898 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:21,278 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:21,283 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:22,687 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:22,689 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:23,576 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:23,578 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:24,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:24,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:26,009 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:26,011 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:27,716 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:27,719 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:29,525 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:29,527 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:31,163 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:31,166 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:31,342 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:31,345 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:32,805 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:32,807 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:34,220 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:34,223 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:35,999 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:36,001 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:37,833 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:37,835 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:38,452 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:38,454 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:39,307 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:39,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:40,872 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:40,874 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:42,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:42,609 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:44,319 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:44,321 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:46,017 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:46,019 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:46,434 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:46,436 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:48,107 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:48,110 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:49,886 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:49,888 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:51,525 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:51,527 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:52,996 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:53,001 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 19:09:53,005 - INFO - Processing story: About_a_Hum
2026-01-27 19:09:53,009 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:54,078 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:54,081 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:09:54,914 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:54,916 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:56,378 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:56,380 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:57,776 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:57,778 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:09:59,614 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:09:59,616 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:00,965 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:00,967 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:01,316 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:01,318 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:02,967 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:02,969 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:04,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:04,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:06,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:06,303 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:07,976 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:07,978 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:09,610 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:09,612 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:09,861 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:09,864 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:11,417 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:11,419 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:12,663 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:12,665 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:10:13,648 - WARNING - 
Process interrupted by user
2026-01-27 19:10:18,013 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:18,015 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:26,184 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:26,186 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:35,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:35,131 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:43,552 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:43,554 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:51,453 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:51,455 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:10:59,385 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:10:59,387 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:07,372 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:07,374 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:15,543 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:15,545 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:23,897 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:23,899 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:31,846 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:31,848 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:40,837 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:40,841 - INFO - ✓ Saved: Rice.json
2026-01-27 19:11:40,844 - INFO - Processing story: Swallowed
2026-01-27 19:11:40,846 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:47,930 - INFO - ============================================================
2026-01-27 19:11:47,930 - INFO - CONNECT Project - Phase 1
2026-01-27 19:11:47,930 - INFO - Problem: inverse
2026-01-27 19:11:47,930 - INFO - ============================================================
2026-01-27 19:11:47,931 - INFO - 
============================================================
2026-01-27 19:11:47,931 - INFO - PHASE 1: TRAINING
2026-01-27 19:11:47,931 - INFO - ============================================================
2026-01-27 19:11:47,931 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:11:47,932 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:11:47,951 - INFO - Successfully loaded 28 stories
2026-01-27 19:11:47,951 - INFO - Loaded 28 training stories
2026-01-27 19:11:47,953 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:11:47,959 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:11:47,983 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:11:49,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:49,320 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:11:50,703 - ERROR - Unexpected error calling LLM: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:50,703 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:50,704 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:11:51,728 - ERROR - Unexpected error calling LLM: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:51,728 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:51,730 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:11:53,756 - ERROR - Unexpected error calling LLM: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:53,756 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:53,758 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:11:55,782 - ERROR - Unexpected error calling LLM: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:55,782 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.AuthenticationError: BedrockException Invalid Authentication - Unable to locate credentials
2026-01-27 19:11:55,784 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:11:56,005 - WARNING - 
Process interrupted by user
2026-01-27 19:11:57,492 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:11:57,494 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:05,179 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:05,181 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:13,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:13,332 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:20,657 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:20,659 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:28,470 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:28,473 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:36,069 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:36,071 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:41,398 - INFO - ============================================================
2026-01-27 19:12:41,398 - INFO - CONNECT Project - Phase 1
2026-01-27 19:12:41,398 - INFO - Problem: inverse
2026-01-27 19:12:41,398 - INFO - ============================================================
2026-01-27 19:12:41,399 - INFO - 
============================================================
2026-01-27 19:12:41,399 - INFO - PHASE 1: TRAINING
2026-01-27 19:12:41,399 - INFO - ============================================================
2026-01-27 19:12:41,399 - INFO - Loading collectivistic stories for inverse problem
2026-01-27 19:12:41,400 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-27 19:12:41,420 - INFO - Successfully loaded 28 stories
2026-01-27 19:12:41,420 - INFO - Loaded 28 training stories
2026-01-27 19:12:41,423 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:12:41,428 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-27 19:12:41,449 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:12:43,673 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:43,675 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:45,683 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:45,688 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:12:48,685 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:48,688 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:12:50,651 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:50,653 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:12:52,133 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:52,135 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:12:56,064 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:56,066 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:12:57,836 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:12:57,838 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:00,050 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:00,052 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:03,524 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:03,526 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:05,055 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:05,057 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:06,344 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:06,347 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:08,939 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:08,941 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:12,700 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:12,703 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:16,673 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:16,675 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:17,354 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:17,357 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:20,396 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:20,398 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:24,232 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:24,234 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:25,569 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:25,571 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:27,735 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:27,737 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:31,396 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:31,398 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:33,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:33,609 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:34,887 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:34,889 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:38,808 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:38,810 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:42,172 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:42,174 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:42,422 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:42,424 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:45,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:45,874 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:48,543 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:48,545 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:50,112 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:50,114 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:51,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:51,130 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-27 19:13:51,133 - INFO - Processing story: About_a_Hum
2026-01-27 19:13:51,135 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:54,439 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:54,442 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:13:57,300 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:57,302 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:13:57,775 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:13:57,777 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:01,342 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:01,345 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:04,954 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:04,956 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:05,065 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:05,067 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:09,156 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:09,158 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:12,528 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:12,529 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:12,837 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:12,839 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:16,686 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:16,688 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:20,147 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:20,153 - INFO - ✓ Saved: Swallowed.json
2026-01-27 19:14:20,432 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:20,434 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:21,232 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-27 19:14:21,235 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:24,279 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:24,282 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:26,894 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:26,896 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:28,439 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:28,441 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:30,231 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:30,233 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:33,144 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:33,146 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:35,817 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:35,819 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:36,767 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:36,769 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:40,191 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:40,193 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:42,945 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:42,947 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:43,784 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:43,786 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:47,620 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:47,622 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:49,684 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:49,686 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:51,283 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:51,285 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:54,777 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:54,779 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:14:55,520 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:55,521 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:14:57,114 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:14:57,116 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:00,818 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:00,823 - INFO - ✓ Saved: About_a_Hum.json
2026-01-27 19:15:00,826 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-27 19:15:00,830 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:02,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:02,131 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:04,941 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:04,943 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:09,225 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:09,228 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:09,886 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:09,888 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:12,970 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:12,972 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:15,863 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:15,865 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:16,820 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:16,822 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:19,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:19,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:23,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:23,873 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:24,502 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:24,504 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:26,740 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:26,742 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:30,466 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:30,468 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:30,711 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:30,713 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:34,362 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:34,364 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:38,400 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:38,401 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:40,214 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:40,216 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:44,776 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:44,778 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:45,863 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:45,865 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:48,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:48,938 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:52,913 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:52,916 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:53,577 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:53,579 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:15:57,382 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:57,384 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:15:59,822 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:15:59,824 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:00,403 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:00,405 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:03,736 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:03,739 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:05,892 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:05,894 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:07,517 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:07,519 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:10,213 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:10,215 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:12,412 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:12,414 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:13,534 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:13,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:17,619 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:17,624 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-27 19:16:17,627 - INFO - Processing story: Back_To_The_Wall
2026-01-27 19:16:17,630 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:19,177 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:19,179 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:21,307 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:21,309 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:25,043 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:25,046 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:26,404 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:26,406 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:28,350 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:28,352 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:32,237 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:32,239 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:33,433 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:33,434 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:36,198 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:36,201 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:39,144 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:39,146 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:39,339 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:39,344 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-27 19:16:39,347 - INFO - Processing story: The_Christmas_Monks
2026-01-27 19:16:39,349 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:42,665 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:42,667 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:46,172 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:46,174 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:49,392 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:49,394 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:49,426 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:49,428 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:16:51,877 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:51,879 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:55,564 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:55,566 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:16:59,140 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:16:59,142 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:01,040 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:01,042 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:02,709 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:02,711 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:06,179 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:06,181 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:08,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:08,832 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:09,952 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:09,954 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:13,773 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:13,775 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:17,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:17,303 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:19,918 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:19,920 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:20,668 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:20,670 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:23,197 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:23,199 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:26,694 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:26,698 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-27 19:17:26,701 - INFO - Processing story: Community_Time
2026-01-27 19:17:26,704 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:30,785 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:30,787 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:32,508 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:32,510 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:35,058 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:35,060 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:38,630 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:38,632 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:42,514 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:42,516 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:43,069 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:43,071 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:45,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:45,680 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:48,822 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:48,824 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:51,846 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:51,848 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:17:52,550 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:52,552 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:17:56,184 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:17:56,187 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:00,309 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:00,311 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:00,501 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:00,503 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:18:03,726 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:03,728 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:08,380 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:08,382 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:12,843 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:12,845 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:13,251 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:13,253 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:18:16,507 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:16,509 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:19,483 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:19,485 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:23,222 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:23,224 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:23,363 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:23,365 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:18:26,839 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:26,841 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:31,057 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:31,059 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:34,808 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:34,810 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:18:36,053 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:36,055 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:38,426 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:38,428 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:41,981 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:41,986 - INFO - ✓ Saved: Community_Time.json
2026-01-27 19:18:41,989 - INFO - Processing story: Fleabags
2026-01-27 19:18:41,991 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:44,724 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:44,726 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:46,975 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:46,977 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:18:48,556 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:48,558 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:52,674 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:52,676 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:56,032 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:56,034 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:58,899 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:58,901 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:18:59,942 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:18:59,943 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:19:03,058 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:03,060 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:05,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:05,681 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:09,458 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:09,460 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:13,120 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:13,122 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:13,707 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:13,709 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:19:16,978 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:16,980 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:20,579 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:20,581 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:24,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:24,133 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:24,701 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:24,703 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:19:27,723 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:27,725 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:31,147 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:31,149 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:34,426 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:34,428 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:35,969 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:35,971 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:19:37,976 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:37,979 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:41,704 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:41,706 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:45,588 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:45,590 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:47,427 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:47,429 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:19:49,128 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:49,130 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:52,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:52,760 - INFO - ✓ Saved: Fleabags.json
2026-01-27 19:19:53,211 - INFO - Processing story: Gravity_Reduced
2026-01-27 19:19:53,222 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:55,668 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:55,670 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:59,186 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:59,188 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:19:59,829 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:19:59,830 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:03,218 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:03,220 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:07,474 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:07,476 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:11,077 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:11,080 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:11,537 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:11,539 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:15,101 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:15,103 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:18,649 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:18,652 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:22,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:22,467 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:25,023 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:25,033 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-27 19:20:26,180 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:26,182 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:26,218 - INFO - Processing story: The_Circuit
2026-01-27 19:20:26,233 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:29,869 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:29,872 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:32,709 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:32,712 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:33,865 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:33,867 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:36,132 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:36,134 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:40,028 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:40,030 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:43,877 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:43,879 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:47,586 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:47,588 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:48,288 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:48,289 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:51,403 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:51,405 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:55,374 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:55,376 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:20:57,097 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:57,099 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:20:59,369 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:20:59,371 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:03,141 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:03,143 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:05,071 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:05,073 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:06,963 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:06,996 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-27 19:21:07,481 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-27 19:21:07,501 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:11,246 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:11,248 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:11,708 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:11,710 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:15,539 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:15,541 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:18,828 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:18,830 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:20,006 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:20,008 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:24,253 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:24,255 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:26,997 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:26,999 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:28,353 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:28,355 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:32,462 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:32,464 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:34,453 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:34,456 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:36,807 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:36,810 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:40,773 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:40,775 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:42,926 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:42,928 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:44,478 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:44,481 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:47,384 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:47,386 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:51,815 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:51,817 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:21:51,862 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:51,864 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:21:55,945 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:21:55,947 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:00,132 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:00,134 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:00,889 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:00,891 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:02,846 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:02,849 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:06,891 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:06,893 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:09,121 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:09,123 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:09,477 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:09,479 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:12,524 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:12,526 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:16,462 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:16,464 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:16,774 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:16,776 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:20,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:20,303 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:23,849 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:23,856 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-27 19:22:23,860 - INFO - Processing story: Honeybee
2026-01-27 19:22:23,863 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:25,004 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:25,006 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:27,612 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:27,615 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:31,719 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:31,722 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:34,383 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:34,384 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:35,902 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:35,904 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:40,492 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:40,495 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:42,500 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:42,502 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:43,883 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:43,885 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:47,665 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:47,668 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:50,578 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:50,580 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:22:51,298 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:51,300 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:54,100 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:54,102 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:58,119 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:58,122 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:22:58,492 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:22:58,494 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:02,047 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:02,050 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:06,104 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:06,106 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:10,063 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:10,066 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:13,851 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:13,853 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:14,075 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:14,078 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:17,893 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:17,895 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:21,847 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:21,852 - INFO - ✓ Saved: The_Circuit.json
2026-01-27 19:23:21,855 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-27 19:23:21,858 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:22,047 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:22,050 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:26,057 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:26,059 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:29,549 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:29,551 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:29,970 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:29,973 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:34,061 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:34,064 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:36,372 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:36,374 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:38,150 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:38,152 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:42,217 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:42,223 - INFO - ✓ Saved: Honeybee.json
2026-01-27 19:23:42,225 - INFO - Processing story: Last_Long_Night
2026-01-27 19:23:42,228 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:43,903 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:43,905 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:45,224 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:45,226 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:49,540 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:49,542 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:51,171 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:51,173 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:23:54,381 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:54,384 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:57,432 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:57,435 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:23:58,312 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:23:58,314 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:00,878 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:00,881 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:04,008 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:04,010 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:05,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:05,832 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:07,160 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:07,163 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:10,499 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:10,501 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:13,637 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:13,639 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:14,468 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:14,471 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:18,906 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:18,908 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:21,195 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:21,197 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:23,154 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:23,156 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:27,321 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:27,323 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:29,702 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:29,704 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:29,928 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:29,930 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:34,059 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:34,061 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:37,356 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:37,357 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:38,300 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:38,302 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:41,517 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:41,519 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:43,391 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:43,393 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:44,207 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:44,209 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:47,966 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:47,968 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:50,079 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:50,081 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:51,065 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:51,068 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:54,984 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:54,991 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-27 19:24:56,053 - INFO - Processing story: Raindrop_Snowflake
2026-01-27 19:24:56,058 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:24:56,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:56,332 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:24:59,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:24:59,926 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:03,060 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:03,062 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:04,038 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:04,040 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:06,862 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:06,865 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:09,228 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:09,230 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:11,751 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:11,753 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:11,919 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:11,921 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:15,481 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:15,483 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:18,634 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:18,636 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:21,030 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:21,032 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:22,339 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:22,341 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:25,682 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:25,684 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:27,333 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:27,335 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:29,350 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:29,352 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:32,515 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:32,517 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:35,620 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:35,622 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:35,693 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:35,695 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:39,483 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:39,485 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:42,020 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:42,021 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:43,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:43,303 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:45,660 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:45,662 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:49,305 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:49,307 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:49,401 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:49,406 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-27 19:25:49,410 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-27 19:25:49,412 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:51,832 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:51,834 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:55,289 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:55,291 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:25:57,505 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:57,506 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:25:58,542 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:25:58,544 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:02,260 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:02,264 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-27 19:26:02,267 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-27 19:26:02,270 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:05,700 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:05,702 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:07,413 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:07,415 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:09,352 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:09,354 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:11,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:11,931 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:15,214 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:15,216 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:15,468 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:15,470 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:19,475 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:19,477 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:22,137 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:22,139 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:23,126 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:23,128 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:26,960 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:26,962 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:30,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:30,573 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:30,617 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:30,619 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:34,804 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:34,806 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:38,030 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:38,032 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:38,382 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:38,384 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:41,222 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:41,224 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:44,710 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:44,712 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:46,439 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:46,441 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:47,162 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:47,165 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:50,699 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:50,701 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:53,211 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:53,213 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:26:54,553 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:54,555 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:26:58,888 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:26:58,890 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:00,803 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:00,806 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:01,238 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:01,240 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:04,901 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:04,903 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:07,238 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:07,240 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:07,339 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:07,341 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:10,091 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:10,096 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-27 19:27:10,099 - INFO - Processing story: Rice
2026-01-27 19:27:10,102 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:14,923 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:14,926 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:15,867 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:15,869 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:19,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:19,681 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:23,751 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:23,754 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:24,800 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:24,801 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:27,003 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:27,006 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:30,854 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:30,857 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:32,533 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:32,535 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:35,210 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:35,212 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:38,378 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:38,380 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:40,234 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:40,236 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:42,369 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:42,371 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:46,592 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:46,594 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:49,251 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:49,252 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:50,635 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:50,637 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:54,914 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:54,917 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:27:58,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:58,276 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:27:59,211 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:27:59,218 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:04,319 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:04,321 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:04,637 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:04,639 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:08,377 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:08,379 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:12,349 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:12,351 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:14,594 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:14,596 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:16,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:16,680 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:21,778 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:21,780 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:22,436 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:22,439 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:26,504 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:26,507 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:29,031 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:29,037 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-27 19:28:29,043 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-27 19:28:29,046 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:30,293 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:30,295 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:33,654 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:33,658 - INFO - ✓ Saved: Rice.json
2026-01-27 19:28:33,661 - INFO - Processing story: Swallowed
2026-01-27 19:28:33,664 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:37,237 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:37,239 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:37,838 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:37,840 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:41,370 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:41,372 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:45,341 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:45,344 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:46,070 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:46,072 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:49,043 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:49,045 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:53,423 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:53,425 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:28:54,903 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:54,905 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:28:57,513 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:28:57,516 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:01,625 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:01,627 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:02,464 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:02,466 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:05,311 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:05,313 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:08,027 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:08,029 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:10,548 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:10,550 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:11,927 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:11,929 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:15,552 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:15,554 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:18,343 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:18,345 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:19,193 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:19,195 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:20,960 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:20,962 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:24,794 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:24,797 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:26,862 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:26,864 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:28,612 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:28,614 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:32,165 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:32,167 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:33,463 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:33,465 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:36,241 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:36,243 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:38,975 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:38,977 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:42,980 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:42,983 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:43,117 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:43,119 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:46,828 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:46,834 - INFO - ✓ Saved: Swallowed.json
2026-01-27 19:29:46,838 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-27 19:29:46,843 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:50,805 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:50,807 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:50,834 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:50,837 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:29:53,534 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:53,536 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:57,202 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:57,204 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:29:59,395 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:29:59,397 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:00,730 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:00,733 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:05,005 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:05,007 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:07,158 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:07,160 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:07,452 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:07,454 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:11,377 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:11,379 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:14,957 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:14,959 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:16,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:16,320 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:18,658 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:18,660 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:21,123 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:21,125 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:24,277 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:24,279 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:24,502 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:24,504 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:27,949 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:27,951 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:31,962 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:31,964 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:32,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:32,333 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:35,392 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:35,395 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:37,782 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:37,784 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:40,887 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:40,889 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:41,400 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:41,402 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:44,651 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:44,653 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:48,144 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:48,146 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:49,071 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:49,073 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:30:50,697 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:50,700 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:54,037 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:54,041 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-27 19:30:54,043 - INFO - Processing story: The_Christmas_Monks
2026-01-27 19:30:54,046 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:57,011 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:57,013 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:30:57,238 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:30:57,240 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:01,248 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:01,251 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:05,988 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:05,990 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:06,114 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:06,115 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:10,590 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:10,593 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:14,320 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:14,322 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:14,351 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:14,355 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-27 19:31:14,359 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-27 19:31:14,361 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:22,084 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:22,086 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:24,138 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:24,140 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:28,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:28,232 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:29,071 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:29,073 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:32,327 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:32,329 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:36,418 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:36,420 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:37,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:37,499 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:41,537 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:41,539 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:43,979 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:43,981 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:45,641 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:45,643 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:49,761 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:49,763 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:50,534 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:50,536 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:31:52,832 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:52,834 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:57,153 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:57,155 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:31:58,144 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:31:58,146 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:00,947 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:00,949 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:05,092 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:05,095 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:05,185 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:05,187 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:07,776 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:07,779 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:11,630 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:11,631 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:11,665 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:11,667 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:15,811 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:15,813 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:19,098 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:19,100 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:19,551 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:19,556 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-27 19:32:19,559 - INFO - Processing story: The_Circuit
2026-01-27 19:32:19,562 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:23,618 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:23,620 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:25,424 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:25,426 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:28,143 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:28,145 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:32,908 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:32,910 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:33,254 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:33,256 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:37,464 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:37,466 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:40,181 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:40,183 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:41,351 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:41,354 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:45,690 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:45,692 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:46,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:46,931 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:49,515 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:49,518 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:53,449 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:53,451 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:32:53,638 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:53,640 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:32:57,521 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:32:57,523 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:00,644 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:00,646 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:01,514 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:01,516 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:05,826 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:05,828 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:07,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:07,931 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:09,541 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:09,543 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:13,829 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:13,831 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:15,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:15,467 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:17,900 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:17,903 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:22,517 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:22,519 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:22,804 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:22,806 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:26,980 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:26,982 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:30,392 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:30,394 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:31,025 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:31,027 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:35,462 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:35,464 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:37,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:37,503 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-27 19:33:38,425 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-27 19:33:38,428 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:39,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:39,931 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:44,004 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:44,009 - INFO - ✓ Saved: The_Circuit.json
2026-01-27 19:33:44,011 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-27 19:33:44,014 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:48,281 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:48,283 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:49,425 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:49,427 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:33:50,597 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:50,599 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:53,376 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:53,378 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:57,643 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:57,645 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:33:59,393 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:33:59,394 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:01,786 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:01,789 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:05,681 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:05,683 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:09,617 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:09,619 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:10,646 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:10,648 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:12,860 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:12,863 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:16,891 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:16,893 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:18,016 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:18,019 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:20,637 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:20,639 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:25,109 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:25,112 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:26,655 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:26,657 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:27,826 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:27,828 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:31,675 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:31,678 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:34,377 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:34,379 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:35,451 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:35,453 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:39,112 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:39,115 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:41,846 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:41,848 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:44,490 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:44,492 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:45,438 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:45,440 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:48,010 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:48,012 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:52,040 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:52,042 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:55,653 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:55,659 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-27 19:34:55,663 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-27 19:34:55,666 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:34:58,026 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:58,028 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:34:59,225 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:34:59,227 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:03,316 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:03,318 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:05,164 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:05,165 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:07,449 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:07,451 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:11,402 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:11,404 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:14,644 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:14,646 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:16,046 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:16,049 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:20,094 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:20,096 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:24,008 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:24,010 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:27,905 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:27,908 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:28,396 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:28,398 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:31,946 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:31,948 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:35,705 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:35,707 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:36,086 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:36,088 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:40,200 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:40,202 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:43,799 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:43,800 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:44,590 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:44,592 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:48,324 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:48,326 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:52,603 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:52,606 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:55,710 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:55,713 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:35:56,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:56,482 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:35:58,990 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:35:58,992 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:03,107 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:03,109 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:05,247 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:05,249 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:36:06,969 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:06,972 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:12,642 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:12,645 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:15,221 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:15,223 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:36:17,243 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:17,249 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-27 19:36:18,210 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-27 19:36:18,213 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:22,544 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:22,546 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:23,555 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:23,557 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:36:26,969 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:26,971 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:31,424 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:31,427 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:34,577 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:34,579 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:36:35,557 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:35,559 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:40,987 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:40,990 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:44,402 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:44,405 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:47,522 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:47,524 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:36:49,039 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:49,041 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:52,914 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:52,916 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:56,976 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:56,979 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:36:57,743 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:36:57,748 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-27 19:36:57,753 - INFO - Processing story: The_Stretcher
2026-01-27 19:36:57,755 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:01,604 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:01,607 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:05,012 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:05,015 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:05,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:05,610 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:10,124 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:10,126 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:12,268 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:12,270 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:13,701 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:13,703 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:16,981 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:16,983 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:18,938 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:18,939 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:21,649 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:21,651 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:24,835 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:24,837 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:26,323 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:26,325 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:28,681 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:28,684 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:32,848 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:32,850 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:33,481 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:33,483 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:36,520 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:36,523 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:40,715 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:40,720 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-27 19:37:40,724 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-27 19:37:40,726 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:40,906 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:40,907 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:44,587 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:44,589 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:48,093 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:48,096 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:49,177 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:49,179 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:51,734 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:51,737 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:55,458 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:55,460 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:37:55,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:55,866 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:37:59,281 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:37:59,284 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:02,570 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:02,572 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:02,950 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:02,952 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:06,554 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:06,557 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:09,167 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:09,170 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:10,455 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:10,457 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:12,829 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:12,831 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:16,415 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:16,417 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:17,671 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:17,673 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:18,825 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:18,828 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:22,671 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:22,673 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:25,831 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:25,832 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:25,978 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:25,981 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:28,842 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:28,844 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:32,320 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:32,323 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:33,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:33,609 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:35,975 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:35,977 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:39,278 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:39,280 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:41,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:41,926 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:42,513 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:42,515 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:46,184 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:46,186 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:48,741 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:48,745 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-27 19:38:50,176 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:50,177 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:50,392 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-27 19:38:50,396 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:54,701 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:54,703 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:38:57,205 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:57,207 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:38:59,509 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:38:59,511 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:03,732 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:03,735 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:05,452 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:05,454 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:08,652 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:08,654 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:12,853 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:12,856 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:13,138 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:13,140 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:16,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:16,499 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:20,542 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:20,545 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:22,212 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:22,214 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:24,653 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:24,656 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:28,971 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:28,974 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:29,818 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:29,824 - INFO - ✓ Saved: The_Stretcher.json
2026-01-27 19:39:29,827 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-27 19:39:29,830 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:32,045 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:32,047 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:36,086 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:36,088 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:38,182 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:38,184 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:40,176 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:40,179 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:44,690 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:44,691 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:44,836 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:44,838 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:48,267 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:48,269 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:52,719 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:52,721 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:53,266 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:53,268 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:39:56,771 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:56,773 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:39:59,852 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:39:59,854 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:01,277 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:01,279 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:05,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:05,512 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:07,397 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:07,399 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:09,991 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:09,993 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:14,177 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:14,182 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-27 19:40:14,186 - INFO - Processing story: The_Stretcher
2026-01-27 19:40:14,189 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:14,645 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:14,646 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:17,819 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:17,821 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:21,053 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:21,055 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:21,241 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:21,243 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:25,965 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:25,967 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:29,371 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:29,373 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:29,420 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:29,422 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:33,390 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:33,392 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:36,848 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:36,850 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:37,295 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:37,297 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:39,958 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:39,960 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:43,594 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:43,597 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:44,081 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:44,083 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:47,241 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:47,244 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:51,216 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:51,219 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:51,716 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:51,718 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:54,677 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:54,682 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:40:58,650 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:58,652 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:40:58,696 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:40:58,698 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:02,874 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:02,876 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:05,252 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:05,254 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:06,473 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:06,475 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:10,045 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:10,047 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:13,098 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:13,100 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:13,836 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:13,838 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:16,901 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:16,903 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:20,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:20,276 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:20,309 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:20,312 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:22,826 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:22,829 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:26,719 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:26,725 - INFO - ✓ Saved: The_Stretcher.json
2026-01-27 19:41:26,728 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-27 19:41:26,732 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:26,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:26,939 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:29,381 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:29,384 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:32,998 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:33,002 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:34,579 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:34,582 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:35,489 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:35,492 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:38,210 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:38,214 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:41,126 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:41,129 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:42,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:42,131 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:45,079 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:45,081 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:48,012 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:48,014 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:49,227 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:49,229 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:53,481 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:53,484 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:41:54,057 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:54,062 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-27 19:41:54,066 - INFO - Processing story: War_of_the_Wall
2026-01-27 19:41:54,069 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:41:56,933 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:41:56,936 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:00,723 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:00,726 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:01,032 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:01,034 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:05,402 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:05,404 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:08,898 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:08,900 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:10,412 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:10,414 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:12,746 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:12,748 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:16,600 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:16,602 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:20,382 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:20,384 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:20,444 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:20,446 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:24,211 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:24,213 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:27,448 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:27,450 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:31,215 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:31,218 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:32,451 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:32,452 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:34,796 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:34,798 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:38,099 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:38,105 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-27 19:42:38,110 - INFO - Processing story: War_of_the_Wall
2026-01-27 19:42:38,113 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:42,138 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:42,140 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:43,059 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:43,060 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:46,136 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:46,138 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:49,978 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:49,981 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:52,589 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:52,591 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:42:53,959 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:53,961 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:42:58,073 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:42:58,075 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:01,233 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:01,234 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:01,786 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:01,788 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:05,660 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:05,662 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:08,836 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:08,838 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:09,022 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:09,024 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:13,162 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:13,164 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:16,902 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:16,905 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:17,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:17,332 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:21,413 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:21,415 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:25,488 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:25,490 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:27,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:27,573 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:29,040 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:29,042 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:32,464 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:32,466 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:35,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:35,926 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:36,744 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:36,746 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:40,660 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:40,662 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:43,618 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:43,620 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:44,541 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:44,543 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:48,688 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:48,691 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:51,078 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:51,080 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:43:52,545 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:52,547 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:55,219 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:55,225 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-27 19:43:55,229 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-27 19:43:55,232 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:58,998 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:59,001 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:43:59,030 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:43:59,032 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:02,496 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:02,498 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:05,928 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:05,930 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:09,690 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:09,692 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:10,440 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:10,441 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:12,997 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:12,999 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:16,600 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:16,602 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:19,156 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:19,158 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:20,187 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:20,189 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:23,528 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:23,530 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:27,133 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:27,135 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:29,171 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:29,173 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:30,736 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:30,738 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:34,432 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:34,434 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:38,239 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:38,240 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:38,293 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:38,295 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:39,763 - ERROR - Unexpected error calling LLM: litellm.Timeout: BedrockException: Timeout Error - {"message":"Model has timed out in processing the request. Try your request again."}
2026-01-27 19:44:39,763 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: litellm.Timeout: BedrockException: Timeout Error - {"message":"Model has timed out in processing the request. Try your request again."}
2026-01-27 19:44:39,764 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:43,600 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:43,602 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:46,566 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:46,568 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:46,988 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:46,990 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:49,456 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:49,458 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:51,960 - ERROR - Unexpected error calling LLM: litellm.Timeout: BedrockException: Timeout Error - {"message":"Model has timed out in processing the request. Try your request again."}
2026-01-27 19:44:51,960 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: litellm.Timeout: BedrockException: Timeout Error - {"message":"Model has timed out in processing the request. Try your request again."}
2026-01-27 19:44:51,961 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:55,342 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:55,344 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:44:55,641 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:55,650 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-27 19:44:55,653 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-27 19:44:55,657 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:44:58,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:44:58,724 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:02,123 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:02,128 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-27 19:45:02,131 - INFO - Processing story: We_Stand_Up
2026-01-27 19:45:02,134 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:02,881 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:02,882 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:05,338 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:05,343 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:08,892 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:08,894 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:09,089 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:09,091 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:12,552 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:12,554 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:14,996 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:14,998 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:16,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:16,926 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:18,690 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:18,693 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:22,321 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:22,323 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:24,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:24,277 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:26,630 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:26,632 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:30,141 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:30,143 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:31,031 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:31,033 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:33,692 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:33,695 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:37,685 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:37,687 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:38,358 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:38,360 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:40,947 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:40,949 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:44,324 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:44,326 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:44,886 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:44,888 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:47,921 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:47,923 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:51,309 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:51,312 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:51,560 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:51,562 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:55,236 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:55,239 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:45:58,562 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:58,564 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:45:58,756 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:45:58,758 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:02,310 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:02,312 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:04,736 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:04,738 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:06,937 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:06,939 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:08,357 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:08,359 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:11,563 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:11,567 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-27 19:46:11,570 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-27 19:46:11,573 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:15,151 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:15,153 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:15,258 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:15,261 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:18,703 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:18,705 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:21,420 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:21,422 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:22,720 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:22,722 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:26,409 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:26,411 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:27,724 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:27,726 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:29,828 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:29,830 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:34,158 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:34,160 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:34,697 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:34,699 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:37,911 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:37,913 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:40,554 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:40,556 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:41,883 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:41,885 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:45,935 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:45,938 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:47,978 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:47,980 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:49,765 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:49,767 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:54,051 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:54,052 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:46:54,095 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:54,097 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:46:57,931 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:46:57,934 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:00,325 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:00,327 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:01,710 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:01,712 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:04,051 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:04,053 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:07,519 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:07,521 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:07,850 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:07,852 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:11,582 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:11,584 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:13,584 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:13,589 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-27 19:47:13,593 - INFO - Processing story: We_Stand_Up
2026-01-27 19:47:13,595 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:15,532 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:15,535 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:19,366 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:19,368 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:19,575 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:19,578 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:23,454 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:23,456 - INFO - 
LiteLLM completion() model= us.meta.llama4-maverick-17b-instruct-v1:0; provider = bedrock
2026-01-27 19:47:25,495 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:25,497 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:27,679 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:27,685 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-27 19:47:27,691 - INFO - 
============================================================
2026-01-27 19:47:27,691 - INFO - Survey complete!
2026-01-27 19:47:27,691 - INFO - Processed: 28/28 stories
2026-01-27 19:47:27,691 - INFO - Failed: 0 stories
2026-01-27 19:47:27,691 - INFO - Total cost: $0.4157
2026-01-27 19:47:27,691 - INFO - Total tokens: 1,234,281
2026-01-27 19:47:27,691 - INFO - ============================================================

2026-01-27 19:47:27,691 - INFO - 
============================================================
2026-01-27 19:47:27,691 - INFO - Step 4: Learning PyReason Rules
2026-01-27 19:47:27,691 - INFO - ============================================================
2026-01-27 19:47:27,691 - INFO - ============================================================
2026-01-27 19:47:27,691 - INFO - RULE LEARNING
2026-01-27 19:47:27,691 - INFO - ============================================================
2026-01-27 19:47:27,692 - INFO - Loading survey results from: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-27 19:47:27,694 - INFO - Found 28 survey result files
2026-01-27 19:47:27,737 - INFO - Successfully loaded 28 survey results
2026-01-27 19:47:27,738 - INFO - Extracting feature scores...
2026-01-27 19:47:27,740 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:47:27,740 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-27 19:47:27,741 - INFO - Extracted scores for 28 stories and 20 features
2026-01-27 19:47:27,741 - INFO - Learning PyReason rules...
2026-01-27 19:47:27,741 - INFO - Configuration:
2026-01-27 19:47:27,741 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-27 19:47:27,741 - INFO -   - Min confidence: 0.0
2026-01-27 19:47:27,741 - INFO -   - Min support: 0
2026-01-27 19:47:27,742 - INFO - Learning rules for 20 features...
2026-01-27 19:47:27,742 - INFO - Learned 100 rules
2026-01-27 19:47:27,745 - INFO - Saved 100 rules to output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:47:27,745 - INFO - ============================================================
2026-01-27 19:47:27,745 - INFO - RULE LEARNING COMPLETE
2026-01-27 19:47:27,745 - INFO - ============================================================
2026-01-27 19:47:27,745 - INFO - Stories processed: 28
2026-01-27 19:47:27,745 - INFO - Features: 20
2026-01-27 19:47:27,745 - INFO - Rules learned: 100
2026-01-27 19:47:27,745 - INFO - Rules saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:47:27,746 - INFO - ============================================================
2026-01-27 19:47:27,746 - INFO - 
Sample rules:
2026-01-27 19:47:27,746 - INFO -   1. corpus(X, behavioral_guidance):[0.21,0.21] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:47:27,746 - INFO -   2. corpus(X, behavioral_guidance):[0.61,0.61] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:47:27,746 - INFO -   3. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:47:27,746 - INFO -   4. corpus(X, behavioral_guidance):[0.11,0.11] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:47:27,746 - INFO -   5. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:47:27,746 - INFO -   ... and 95 more
2026-01-27 19:47:27,747 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:47:27,747 - INFO - 
Phase 1 completed successfully!
2026-01-27 19:47:27,747 - INFO - Output directory: output/phase1
2026-01-27 19:47:27,747 - INFO - ============================================================
2026-01-27 19:47:27,747 - INFO - Execution completed successfully!
2026-01-27 19:47:27,747 - INFO - ============================================================
2026-01-27 19:47:32,858 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:32,860 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:39,098 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:39,101 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:44,849 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:44,851 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:51,106 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:51,108 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:47:57,844 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:47:57,846 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:04,102 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:04,104 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:10,498 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:10,500 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:16,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:16,866 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:23,991 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:23,993 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:31,249 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:31,251 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:38,690 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:38,692 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:45,146 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:45,149 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:52,579 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:52,581 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:48:59,905 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:48:59,907 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:06,419 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:06,421 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:13,119 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:13,121 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:20,493 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:20,495 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:26,878 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:26,883 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-27 19:49:26,886 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-27 19:49:26,888 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:33,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:33,938 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:42,791 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:42,793 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:51,260 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:51,262 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:49:59,548 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:49:59,550 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:07,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:07,043 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:15,858 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:15,859 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:25,079 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:25,081 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:35,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:35,126 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:43,498 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:43,500 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:51,920 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:51,922 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:50:59,795 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:50:59,797 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:08,076 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:08,078 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:17,148 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:17,150 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:26,195 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:26,197 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:33,916 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:33,918 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:42,112 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:42,115 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:49,821 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:49,823 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:51:58,724 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:51:58,725 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:52:06,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:52:06,319 - INFO - 
LiteLLM completion() model= claude-sonnet-4-5; provider = anthropic
2026-01-27 19:52:14,689 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-27 19:52:14,695 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-27 19:52:14,700 - INFO - 
============================================================
2026-01-27 19:52:14,701 - INFO - Survey complete!
2026-01-27 19:52:14,701 - INFO - Processed: 28/28 stories
2026-01-27 19:52:14,701 - INFO - Failed: 0 stories
2026-01-27 19:52:14,701 - INFO - Total cost: $6.7074
2026-01-27 19:52:14,701 - INFO - Total tokens: 1,371,701
2026-01-27 19:52:14,701 - INFO - ============================================================

2026-01-27 19:52:14,701 - INFO - 
============================================================
2026-01-27 19:52:14,702 - INFO - Step 4: Learning PyReason Rules
2026-01-27 19:52:14,702 - INFO - ============================================================
2026-01-27 19:52:14,702 - INFO - ============================================================
2026-01-27 19:52:14,702 - INFO - RULE LEARNING
2026-01-27 19:52:14,702 - INFO - ============================================================
2026-01-27 19:52:14,704 - INFO - Loading survey results from: output/phase1/claude-sonnet-4-5/inverse/survey_results
2026-01-27 19:52:14,706 - INFO - Found 28 survey result files
2026-01-27 19:52:14,750 - INFO - Successfully loaded 28 survey results
2026-01-27 19:52:14,750 - INFO - Extracting feature scores...
2026-01-27 19:52:14,753 - INFO - Extracted scores for 28 stories and 20 features
2026-01-27 19:52:14,753 - INFO - Learning PyReason rules...
2026-01-27 19:52:14,754 - INFO - Configuration:
2026-01-27 19:52:14,754 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-27 19:52:14,754 - INFO -   - Min confidence: 0.0
2026-01-27 19:52:14,754 - INFO -   - Min support: 0
2026-01-27 19:52:14,754 - INFO - Learning rules for 20 features...
2026-01-27 19:52:14,755 - INFO - Learned 100 rules
2026-01-27 19:52:14,757 - INFO - Saved 100 rules to output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:52:14,758 - INFO - ============================================================
2026-01-27 19:52:14,758 - INFO - RULE LEARNING COMPLETE
2026-01-27 19:52:14,758 - INFO - ============================================================
2026-01-27 19:52:14,758 - INFO - Stories processed: 28
2026-01-27 19:52:14,758 - INFO - Features: 20
2026-01-27 19:52:14,758 - INFO - Rules learned: 100
2026-01-27 19:52:14,758 - INFO - Rules saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:52:14,758 - INFO - ============================================================
2026-01-27 19:52:14,758 - INFO - 
Sample rules:
2026-01-27 19:52:14,759 - INFO -   1. corpus(X, behavioral_guidance):[0.36,0.36] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:52:14,759 - INFO -   2. corpus(X, behavioral_guidance):[0.54,0.54] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:52:14,759 - INFO -   3. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:52:14,759 - INFO -   4. corpus(X, behavioral_guidance):[0.11,0.11] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:52:14,759 - INFO -   5. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-27 19:52:14,759 - INFO -   ... and 95 more
2026-01-27 19:52:14,760 - INFO - 
✓ Rules learned and saved to: output/phase1/claude-sonnet-4-5/inverse/learned_rules/pyreason_rules.txt
2026-01-27 19:52:14,760 - INFO - 
Phase 1 completed successfully!
2026-01-27 19:52:14,760 - INFO - Output directory: output/phase1
2026-01-27 19:52:14,762 - INFO - ============================================================
2026-01-27 19:52:14,762 - INFO - Execution completed successfully!
2026-01-27 19:52:14,763 - INFO - ============================================================
2026-01-28 23:30:57,760 - INFO - ============================================================
2026-01-28 23:30:57,761 - INFO - CONNECT Project - Phase 1
2026-01-28 23:30:57,761 - INFO - Problem: inverse
2026-01-28 23:30:57,762 - INFO - ============================================================
2026-01-28 23:30:57,762 - INFO - 
============================================================
2026-01-28 23:30:57,762 - INFO - PHASE 1: TRAINING
2026-01-28 23:30:57,762 - INFO - ============================================================
2026-01-28 23:30:57,762 - INFO - Loading collectivistic stories for inverse problem
2026-01-28 23:30:57,763 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-28 23:30:57,785 - INFO - Successfully loaded 28 stories
2026-01-28 23:30:57,785 - INFO - Loaded 28 training stories
2026-01-28 23:30:57,788 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/survey_results
2026-01-28 23:30:57,792 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-28 23:30:57,813 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:30:58,377 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-28 23:31:00,356 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:00,362 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:02,819 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:02,821 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:04,399 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:04,401 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:06,165 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:06,167 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:08,375 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:08,377 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:10,322 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:10,324 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:12,339 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:12,341 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:14,178 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:14,180 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:15,621 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:15,624 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:18,103 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:18,105 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:20,411 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:20,413 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:22,498 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:22,500 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:24,070 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:24,072 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:26,745 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:26,747 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:29,136 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:29,138 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:31,154 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:31,156 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:33,665 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:33,668 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:35,756 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:35,758 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:37,448 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:37,450 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:39,415 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:39,416 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:31:39,420 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-28 23:31:39,423 - INFO - Processing story: About_a_Hum
2026-01-28 23:31:39,426 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:41,271 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:41,273 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:43,473 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:43,475 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:45,847 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:45,849 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:47,915 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:47,917 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:49,478 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:49,480 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:51,393 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:51,395 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:53,671 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:53,673 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:55,110 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:55,113 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:57,231 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:57,233 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:31:58,765 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:31:58,767 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:32:00,793 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:32:00,796 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:32:02,692 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:32:02,694 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:32:03,949 - WARNING - 
Process interrupted by user
2026-01-28 23:33:03,420 - INFO - ============================================================
2026-01-28 23:33:03,420 - INFO - CONNECT Project - Phase 1
2026-01-28 23:33:03,421 - INFO - Problem: inverse
2026-01-28 23:33:03,421 - INFO - ============================================================
2026-01-28 23:33:03,421 - INFO - 
============================================================
2026-01-28 23:33:03,421 - INFO - PHASE 1: TRAINING
2026-01-28 23:33:03,421 - INFO - ============================================================
2026-01-28 23:33:03,421 - INFO - Loading collectivistic stories for inverse problem
2026-01-28 23:33:03,423 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-28 23:33:03,444 - INFO - Successfully loaded 28 stories
2026-01-28 23:33:03,444 - INFO - Loaded 28 training stories
2026-01-28 23:33:03,447 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/survey_results
2026-01-28 23:33:03,451 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-28 23:33:03,471 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:03,988 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-28 23:33:06,097 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:06,102 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:08,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:08,127 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:10,209 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:10,212 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:11,983 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:11,985 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:13,558 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:13,560 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:14,943 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:14,945 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:23,104 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:23,107 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:25,565 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:25,567 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:27,236 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:27,239 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:29,877 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:29,879 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:31,679 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:31,682 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:33,173 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:33,175 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:34,650 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:34,652 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:36,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:36,832 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:39,138 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:39,140 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:41,141 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:41,143 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:43,248 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:43,250 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:45,463 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:45,465 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:47,490 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:47,492 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:49,768 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:49,769 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:33:49,774 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-28 23:33:49,776 - INFO - Processing story: About_a_Hum
2026-01-28 23:33:49,779 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:52,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:52,276 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:54,174 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:54,176 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:56,640 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:56,642 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:33:59,235 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:33:59,237 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:01,202 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:01,204 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:03,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:03,528 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:05,588 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:05,590 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:07,575 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:07,577 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:09,765 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:09,767 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:11,586 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:11,588 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:13,708 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:13,710 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:15,635 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:15,637 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:17,530 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:17,532 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:19,982 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:19,984 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:22,123 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:22,126 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:24,648 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:24,650 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:26,395 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:26,397 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:28,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:28,482 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:33,896 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:33,898 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:35,826 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:35,827 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:34:35,834 - INFO - ✓ Saved: About_a_Hum.json
2026-01-28 23:34:36,587 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-28 23:34:36,593 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:38,998 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:39,001 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:40,959 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:40,961 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:50,430 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:50,432 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:54,053 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:54,055 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:34:56,840 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:34:56,842 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:01,160 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:01,162 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:09,111 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:09,113 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:10,943 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:10,945 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:20,221 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:20,224 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:22,517 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:22,519 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:24,281 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:24,283 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:26,427 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:26,429 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:28,585 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:28,587 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:31,076 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:31,078 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:38,248 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:38,251 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:40,478 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:40,480 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:42,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:42,938 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:45,241 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:45,243 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:47,106 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:47,109 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:48,894 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:48,895 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:35:48,900 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-28 23:35:49,120 - INFO - Processing story: Back_To_The_Wall
2026-01-28 23:35:49,125 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:55,697 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:55,699 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:57,709 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:57,711 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:35:59,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:35:59,873 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:01,564 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:01,566 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:03,118 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:03,120 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:04,621 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:04,624 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:05,949 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:05,951 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:07,130 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:07,132 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:08,709 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:08,712 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:10,512 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:10,514 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:12,264 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:12,266 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:16,995 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:16,997 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:20,205 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:20,207 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:23,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:23,866 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:25,134 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:25,136 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:26,326 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:26,329 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:31,527 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:31,529 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:35,721 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:35,724 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:37,146 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:37,148 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:39,081 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:39,082 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:36:39,088 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-28 23:36:39,091 - INFO - Processing story: Community_Time
2026-01-28 23:36:39,094 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:41,467 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:41,469 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:45,801 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:45,804 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:48,354 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:48,356 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:50,646 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:50,648 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:52,891 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:52,893 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:54,697 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:54,699 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:56,909 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:56,911 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:36:59,724 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:36:59,726 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:02,233 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:02,235 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:04,574 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:04,576 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:07,498 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:07,501 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:16,579 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:16,582 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:19,150 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:19,153 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:21,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:21,866 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:24,300 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:24,303 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:26,555 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:26,557 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:29,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:29,499 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:31,981 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:31,983 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:34,882 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:34,885 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:37,543 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:37,544 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:37:37,551 - INFO - ✓ Saved: Community_Time.json
2026-01-28 23:37:38,237 - INFO - Processing story: Fleabags
2026-01-28 23:37:38,240 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:39,651 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:39,653 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:41,333 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:41,335 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:43,296 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:43,298 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:45,097 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:45,099 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:46,600 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:46,602 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:48,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:48,964 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:51,127 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:51,129 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:52,506 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:52,508 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:54,087 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:54,089 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:55,752 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:55,755 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:56,742 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:56,745 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:58,043 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:58,045 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:37:59,374 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:37:59,377 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:00,579 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:00,581 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:02,035 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:02,037 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:03,797 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:03,799 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:05,498 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:05,500 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:07,143 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:07,145 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:08,948 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:08,950 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:10,664 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:10,665 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:38:10,670 - INFO - ✓ Saved: Fleabags.json
2026-01-28 23:38:10,674 - INFO - Processing story: Gravity_Reduced
2026-01-28 23:38:10,677 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:12,524 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:12,526 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:14,296 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:14,298 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:16,073 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:16,076 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:17,927 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:17,930 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:19,860 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:19,862 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:22,195 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:22,197 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:24,018 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:24,020 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:25,836 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:25,839 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:30,738 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:30,740 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:32,586 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:32,588 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:34,180 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:34,183 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:36,116 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:36,118 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:39,572 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:39,575 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:41,509 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:41,512 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:43,572 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:43,574 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:45,349 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:45,351 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:47,163 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:47,165 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:49,222 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:49,224 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:51,771 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:51,774 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:53,874 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:53,875 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:38:53,880 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-28 23:38:53,882 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-28 23:38:53,885 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:55,748 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:55,750 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:38:58,307 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:38:58,309 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:00,787 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:00,790 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:03,033 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:03,036 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:05,119 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:05,121 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:08,328 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:08,331 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:09,984 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:09,987 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:12,090 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:12,092 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:14,056 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:14,058 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:15,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:15,867 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:18,327 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:18,330 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:20,172 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:20,175 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:22,742 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:22,744 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:24,851 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:24,854 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:27,574 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:27,577 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:30,040 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:30,044 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:32,442 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:32,444 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:34,608 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:34,611 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:37,237 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:37,240 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:39,669 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:39,670 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:39:39,677 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-28 23:39:41,485 - INFO - Processing story: Honeybee
2026-01-28 23:39:41,489 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:43,002 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:43,004 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:44,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:44,528 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:46,091 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:46,094 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:48,110 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:48,112 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:50,260 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:50,262 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:52,947 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:52,950 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:54,911 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:54,913 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:57,199 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:57,201 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:39:59,117 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:39:59,119 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:01,434 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:01,436 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:03,445 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:03,447 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:05,361 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:05,363 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:07,372 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:07,375 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:08,992 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:08,995 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:11,051 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:11,054 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:12,626 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:12,628 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:14,751 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:14,753 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:17,389 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:17,392 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:19,484 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:19,486 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:21,958 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:21,959 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:40:21,965 - INFO - ✓ Saved: Honeybee.json
2026-01-28 23:40:21,968 - INFO - Processing story: Last_Long_Night
2026-01-28 23:40:21,971 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:24,115 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:24,117 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:26,491 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:26,493 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:28,310 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:28,313 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:30,067 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:30,069 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:31,732 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:31,735 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:33,528 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:33,530 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:35,669 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:35,671 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:37,839 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:37,841 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:39,336 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:39,338 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:41,461 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:41,463 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:42,969 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:42,971 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:45,022 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:45,024 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:47,261 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:47,263 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:49,006 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:49,008 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:51,155 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:51,157 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:53,234 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:53,237 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:40:59,479 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:40:59,481 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:01,163 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:01,167 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:03,735 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:03,739 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:05,776 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:05,777 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:41:05,781 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-28 23:41:05,784 - INFO - Processing story: Raindrop_Snowflake
2026-01-28 23:41:05,786 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:07,309 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:07,311 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:08,789 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:08,791 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:10,375 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:10,377 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:11,523 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:11,526 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:12,720 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:12,722 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:13,758 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:13,761 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:15,165 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:15,167 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:16,717 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:16,720 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:18,274 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:18,276 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:19,712 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:19,714 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:20,890 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:20,893 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:22,600 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:22,602 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:23,801 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:23,804 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:24,842 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:24,845 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:26,940 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:26,942 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:28,695 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:28,697 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:30,109 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:30,112 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:31,314 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:31,317 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:32,623 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:32,625 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:34,230 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:34,232 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:41:34,236 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-28 23:41:34,239 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-28 23:41:34,242 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:36,240 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:36,243 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:37,863 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:37,866 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:39,300 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:39,303 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:41,251 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:41,253 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:43,105 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:43,108 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:44,450 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:44,452 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:46,200 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:46,203 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:47,865 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:47,867 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:49,539 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:49,542 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:50,983 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:50,985 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:52,971 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:52,973 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:54,799 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:54,801 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:56,850 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:56,852 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:41:59,054 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:41:59,056 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:00,566 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:00,568 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:02,543 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:02,545 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:04,234 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:04,236 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:05,879 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:05,881 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:07,509 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:07,512 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:09,456 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:09,457 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:42:09,461 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-28 23:42:09,464 - INFO - Processing story: Rice
2026-01-28 23:42:09,467 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:12,377 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:12,379 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:14,327 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:14,329 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:17,209 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:17,211 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:19,829 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:19,832 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:22,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:22,128 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:25,178 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:25,180 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:27,458 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:27,460 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:28,782 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:28,784 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:30,863 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:30,865 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:33,917 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:33,919 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:35,665 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:35,667 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:37,470 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:37,472 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:39,364 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:39,366 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:41,297 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:41,299 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:43,560 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:43,562 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:45,794 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:45,796 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:48,075 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:48,077 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:50,262 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:50,264 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:52,474 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:52,476 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:56,506 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:56,507 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:42:56,512 - INFO - ✓ Saved: Rice.json
2026-01-28 23:42:56,514 - INFO - Processing story: Swallowed
2026-01-28 23:42:56,517 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:58,160 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:58,163 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:42:59,945 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:42:59,947 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:01,599 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:01,601 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:03,341 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:03,344 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:04,649 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:04,651 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:04,674 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-28 23:43:06,512 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:06,515 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:07,849 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:07,851 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:09,506 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:09,509 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:11,315 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:11,317 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:12,945 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:12,947 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:14,733 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:14,735 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:17,052 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:17,055 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:18,538 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:18,541 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:20,178 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:20,180 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:21,712 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:21,714 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:23,416 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:23,418 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:25,158 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:25,160 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:27,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:27,032 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:28,879 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:28,883 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:31,179 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:31,180 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:43:31,184 - INFO - ✓ Saved: Swallowed.json
2026-01-28 23:43:31,187 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-28 23:43:31,190 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:33,335 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:33,337 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:35,228 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:35,231 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:37,297 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:37,299 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:39,082 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:39,084 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:40,900 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:40,903 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:42,518 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:42,520 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:44,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:44,574 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:45,686 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:45,688 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:47,705 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:47,707 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:49,457 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:49,459 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:51,036 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:51,038 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:52,808 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:52,811 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:55,144 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:55,146 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:56,743 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:56,746 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:43:58,220 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:43:58,222 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:00,000 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:00,002 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:01,980 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:01,983 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:04,133 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:04,135 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:05,742 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:05,744 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:07,803 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:07,804 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:44:07,808 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-28 23:44:07,810 - INFO - Processing story: The_Christmas_Monks
2026-01-28 23:44:07,813 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:10,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:10,332 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:11,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:11,932 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:15,159 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:15,161 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:16,725 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:16,729 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:19,350 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:19,352 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:22,065 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:22,068 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:24,483 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:24,485 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:25,994 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:25,996 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:27,995 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:27,998 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:30,332 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:30,334 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:33,246 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:33,248 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:35,588 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:35,590 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:37,472 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:37,474 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:39,882 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:39,884 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:41,789 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:41,791 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:43,766 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:43,768 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:45,886 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:45,888 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:48,028 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:48,030 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:50,013 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:50,015 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:52,025 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:52,026 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:44:52,030 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-28 23:44:52,033 - INFO - Processing story: The_Circuit
2026-01-28 23:44:52,035 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:57,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:57,031 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:44:59,253 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:44:59,255 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:04,877 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:04,880 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:07,969 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:07,971 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:10,380 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:10,382 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:13,002 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:13,004 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:14,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:14,873 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:16,952 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:16,954 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:19,301 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:19,303 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:21,201 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:21,203 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:23,276 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:23,279 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:25,042 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:25,045 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:27,740 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:27,742 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:29,898 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:29,901 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:33,220 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:33,223 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:35,834 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:35,836 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:38,058 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:38,061 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:40,436 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:40,438 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:42,902 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:42,905 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:45,677 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:45,678 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:45:45,683 - INFO - ✓ Saved: The_Circuit.json
2026-01-28 23:45:45,686 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-28 23:45:45,690 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:47,170 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:47,172 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:53,365 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:53,367 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:55,459 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:55,461 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:57,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:57,231 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:45:58,668 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:45:58,671 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:00,223 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:00,225 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:03,970 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:03,973 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:05,846 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:05,849 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:08,068 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:08,070 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:09,814 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:09,816 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:12,034 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:12,036 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:14,567 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:14,569 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:16,578 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:16,580 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:18,408 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:18,410 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:21,019 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:21,022 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:22,496 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:22,498 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:24,801 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:24,804 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:26,749 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:26,751 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:29,176 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:29,178 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:31,166 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:31,167 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:46:31,171 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-28 23:46:31,174 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-28 23:46:31,178 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:32,907 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:32,909 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:35,090 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:35,093 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:37,141 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:37,144 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:39,308 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:39,311 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:41,217 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:41,220 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:44,139 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:44,142 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:46,551 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:46,554 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:47,853 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:47,856 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:49,958 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:49,960 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:52,286 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:52,288 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:54,120 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:54,122 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:56,659 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:56,661 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:46:58,240 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:46:58,242 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:01,157 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:01,160 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:02,943 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:02,946 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:04,831 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:04,834 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:07,444 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:07,447 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:09,950 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:09,952 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:12,094 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:12,097 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:13,297 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:13,298 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:47:13,303 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-28 23:47:13,306 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-28 23:47:13,309 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:16,005 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:16,007 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:17,433 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:17,435 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:19,609 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:19,611 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:21,403 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:21,405 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:23,151 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:23,154 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:25,215 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:25,217 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:26,911 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:26,913 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:28,135 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:28,137 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:30,146 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:30,148 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:32,125 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:32,127 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:34,658 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:34,660 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:37,576 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:37,579 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:39,624 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:39,626 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:42,438 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:42,440 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:43,927 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:43,929 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:45,754 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:45,756 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:47,516 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:47,518 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:50,162 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:50,164 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:51,585 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:51,588 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:54,576 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:54,577 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:47:54,581 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-28 23:47:54,584 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-28 23:47:54,587 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:56,454 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:56,456 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:47:58,475 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:47:58,478 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:00,143 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:00,145 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:01,204 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:01,207 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:02,925 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:02,928 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:04,574 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:04,576 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:06,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:06,231 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:07,268 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:07,270 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:08,904 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:08,906 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:10,647 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:10,649 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:12,346 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:12,348 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:13,464 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:13,466 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:15,411 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:15,413 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:22,562 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:22,564 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:23,914 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:23,916 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:25,494 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:25,496 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:27,353 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:27,355 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:28,713 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:28,715 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:30,024 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:30,026 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:31,860 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:31,861 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:48:31,866 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-28 23:48:31,900 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-28 23:48:31,904 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:36,167 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:36,170 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:37,500 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:37,502 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:42,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:42,573 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:48,544 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:48,548 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:51,122 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:51,124 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:48:55,987 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:48:55,989 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:03,547 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:03,550 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:08,698 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:08,700 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:12,522 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:12,524 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:15,653 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:15,655 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:18,162 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:18,165 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:21,435 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:21,437 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:25,346 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:25,348 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:29,226 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:29,229 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:33,178 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:33,180 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:40,433 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:40,436 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:43,071 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:43,073 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:45,743 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:45,745 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:53,169 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:53,172 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:49:59,211 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:49:59,212 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:49:59,217 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-28 23:49:59,220 - INFO - Processing story: The_Stretcher
2026-01-28 23:49:59,222 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:00,957 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:00,959 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:02,918 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:02,920 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:04,357 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:04,360 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:05,833 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:05,836 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:07,434 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:07,436 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:09,437 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:09,439 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:10,733 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:10,736 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:12,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:12,573 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:14,250 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:14,252 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:15,828 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:15,830 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:17,302 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:17,304 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:18,695 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:18,697 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:20,283 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:20,286 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:22,090 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:22,092 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:23,878 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:23,880 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:25,999 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:26,002 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:27,403 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:27,405 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:29,420 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:29,422 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:30,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:30,938 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:32,538 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:32,539 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:50:32,543 - INFO - ✓ Saved: The_Stretcher.json
2026-01-28 23:50:32,546 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-28 23:50:32,549 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:42,049 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:42,051 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:46,701 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:46,703 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:48,866 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:48,868 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:54,063 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:54,065 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:55,975 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:55,977 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:57,219 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:57,221 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:50:58,642 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:50:58,644 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:00,026 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:00,028 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:01,946 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:01,949 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:03,509 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:03,511 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:04,867 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:04,870 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:06,212 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:06,214 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:07,504 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:07,506 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:09,257 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:09,260 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:10,682 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:10,685 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:12,385 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:12,387 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:13,820 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:13,822 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:15,393 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:15,395 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:16,943 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:16,945 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:18,763 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:18,764 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:51:18,769 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-28 23:51:18,772 - INFO - Processing story: War_of_the_Wall
2026-01-28 23:51:18,775 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:21,536 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:21,539 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:24,045 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:24,047 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:26,865 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:26,867 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:29,281 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:29,283 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:31,290 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:31,293 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:33,239 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:33,242 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:35,104 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:35,106 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:37,695 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:37,698 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:39,479 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:39,482 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:41,427 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:41,430 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:44,345 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:44,348 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:47,335 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:47,338 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:50,201 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:50,203 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:53,075 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:53,077 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:56,372 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:56,374 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:51:58,649 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:51:58,652 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:00,771 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:00,774 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:03,372 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:03,375 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:06,046 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:06,048 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:08,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:08,723 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:52:08,728 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-28 23:52:08,731 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-28 23:52:08,733 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:10,223 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:10,225 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:11,645 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:11,647 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:12,656 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:12,658 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:14,128 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:14,130 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:15,337 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:15,340 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:16,754 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:16,757 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:18,255 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:18,257 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:19,679 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:19,682 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:22,377 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:22,379 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:23,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:23,681 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:24,959 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:24,962 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:26,173 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:26,176 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:27,566 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:27,569 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:29,170 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:29,173 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:30,373 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:30,376 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:31,767 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:31,769 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:33,507 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:33,509 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:35,235 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:35,237 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:37,113 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:37,115 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:38,523 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:38,524 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:52:38,528 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-28 23:52:38,531 - INFO - Processing story: We_Stand_Up
2026-01-28 23:52:38,534 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:39,908 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:39,911 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:41,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:41,482 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:42,897 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:42,899 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:44,442 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:44,444 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:45,735 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:45,738 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:47,259 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:47,261 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:48,476 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:48,479 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:50,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:50,528 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:51,715 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:51,718 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:53,115 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:53,117 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:54,672 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:54,675 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:55,898 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:55,900 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:57,512 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:57,514 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:52:59,430 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:52:59,432 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:00,849 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:00,851 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:02,117 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:02,120 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:03,623 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:03,625 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:05,714 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:05,717 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:05,740 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-28 23:53:07,220 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:07,222 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:08,781 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:08,782 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:53:08,786 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-28 23:53:08,789 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-28 23:53:08,792 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:11,161 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:11,163 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:13,443 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:13,445 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:14,683 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:14,685 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:17,694 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:17,696 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:19,883 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:19,885 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:22,343 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:22,345 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:23,932 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:23,934 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:25,947 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:25,949 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:28,222 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:28,225 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:29,786 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:29,788 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:32,635 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:32,637 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:34,945 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:34,947 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:37,287 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:37,289 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:39,352 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:39,355 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:41,247 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:41,249 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:43,475 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:43,477 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:45,687 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:45,689 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:47,721 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:47,724 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:49,477 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:49,479 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1:0; provider = bedrock
2026-01-28 23:53:51,688 - INFO - Wrapper: Completed Call, calling success_handler
2026-01-28 23:53:51,690 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1:0, using default
2026-01-28 23:53:51,695 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-28 23:53:51,703 - INFO - 
============================================================
2026-01-28 23:53:51,703 - INFO - Survey complete!
2026-01-28 23:53:51,704 - INFO - Processed: 28/28 stories
2026-01-28 23:53:51,704 - INFO - Failed: 0 stories
2026-01-28 23:53:51,704 - INFO - Total cost: $4.3845
2026-01-28 23:53:51,704 - INFO - Total tokens: 1,238,437
2026-01-28 23:53:51,704 - INFO - ============================================================

2026-01-28 23:53:51,704 - INFO - 
============================================================
2026-01-28 23:53:51,704 - INFO - Step 4: Learning PyReason Rules
2026-01-28 23:53:51,704 - INFO - ============================================================
2026-01-28 23:53:51,704 - INFO - ============================================================
2026-01-28 23:53:51,704 - INFO - RULE LEARNING
2026-01-28 23:53:51,704 - INFO - ============================================================
2026-01-28 23:53:51,705 - INFO - Loading survey results from: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/survey_results
2026-01-28 23:53:51,707 - INFO - Found 28 survey result files
2026-01-28 23:53:51,765 - INFO - Successfully loaded 28 survey results
2026-01-28 23:53:51,766 - INFO - Extracting feature scores...
2026-01-28 23:53:51,768 - INFO - Extracted scores for 28 stories and 20 features
2026-01-28 23:53:51,768 - INFO - Learning PyReason rules...
2026-01-28 23:53:51,768 - INFO - Configuration:
2026-01-28 23:53:51,769 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-28 23:53:51,769 - INFO -   - Min confidence: 0.0
2026-01-28 23:53:51,769 - INFO -   - Min support: 0
2026-01-28 23:53:51,769 - INFO - Learning rules for 20 features...
2026-01-28 23:53:51,770 - INFO - Learned 100 rules
2026-01-28 23:53:51,773 - INFO - Saved 100 rules to output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-28 23:53:51,773 - INFO - ============================================================
2026-01-28 23:53:51,774 - INFO - RULE LEARNING COMPLETE
2026-01-28 23:53:51,774 - INFO - ============================================================
2026-01-28 23:53:51,774 - INFO - Stories processed: 28
2026-01-28 23:53:51,774 - INFO - Features: 20
2026-01-28 23:53:51,774 - INFO - Rules learned: 100
2026-01-28 23:53:51,774 - INFO - Rules saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-28 23:53:51,774 - INFO - ============================================================
2026-01-28 23:53:51,774 - INFO - 
Sample rules:
2026-01-28 23:53:51,774 - INFO -   1. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-28 23:53:51,774 - INFO -   2. corpus(X, behavioral_guidance):[0.86,0.86] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-28 23:53:51,774 - INFO -   3. corpus(X, behavioral_guidance):[0.11,0.11] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-28 23:53:51,774 - INFO -   4. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-28 23:53:51,774 - INFO -   5. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-28 23:53:51,774 - INFO -   ... and 95 more
2026-01-28 23:53:51,775 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-28 23:53:51,775 - INFO - 
Phase 1 completed successfully!
2026-01-28 23:53:51,776 - INFO - Output directory: output/phase1
2026-01-28 23:53:51,777 - INFO - ============================================================
2026-01-28 23:53:51,777 - INFO - Execution completed successfully!
2026-01-28 23:53:51,778 - INFO - ============================================================
2026-01-29 12:33:45,713 - INFO - ============================================================
2026-01-29 12:33:45,713 - INFO - CONNECT Project - Phase 1
2026-01-29 12:33:45,713 - INFO - Problem: inverse
2026-01-29 12:33:45,715 - INFO - ============================================================
2026-01-29 12:33:45,715 - INFO - 
============================================================
2026-01-29 12:33:45,715 - INFO - PHASE 1: TRAINING
2026-01-29 12:33:45,715 - INFO - ============================================================
2026-01-29 12:33:45,715 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 12:33:45,716 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 12:33:45,739 - INFO - Successfully loaded 28 stories
2026-01-29 12:33:45,739 - INFO - Loaded 28 training stories
2026-01-29 12:33:45,743 - INFO - Survey results will be saved to: output/phase1/bedrock-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 12:33:45,747 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 12:33:45,777 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,317 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:46,564 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,564 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,566 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,581 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:46,657 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,657 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,658 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,674 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:46,748 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,749 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,750 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,765 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:46,841 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,841 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,843 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,859 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:46,934 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,934 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:46,935 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:46,953 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,027 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,027 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,028 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,046 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,120 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,121 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,122 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,138 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,212 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,213 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,214 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,230 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,306 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,306 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,308 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,324 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,399 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,399 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,401 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,418 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,493 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,493 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,494 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,510 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,585 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,585 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,586 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,602 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,675 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,676 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,677 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,693 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,767 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,767 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,769 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,785 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,859 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,859 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,860 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,878 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:47,952 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,952 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:47,953 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:47,970 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,045 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,045 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,046 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,064 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,139 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,139 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,140 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,156 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,231 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,232 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,233 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,250 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,329 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,329 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,330 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:48,332 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 12:33:48,334 - INFO - Processing story: About_a_Hum
2026-01-29 12:33:48,336 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,352 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,426 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,427 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,428 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,444 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,519 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,519 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,521 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,538 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,613 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,613 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,614 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,630 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,705 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,705 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,706 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,724 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,798 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,798 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,800 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,816 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,890 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,891 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,892 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,907 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:48,981 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,982 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:48,983 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:48,999 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,073 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,074 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,075 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,091 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,166 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,166 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,168 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,186 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,260 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,260 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,262 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,277 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,353 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,353 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,354 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,370 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,445 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,445 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,446 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,463 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,538 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,538 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,540 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,556 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,630 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,631 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,632 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,651 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,725 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,725 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,727 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,742 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,817 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,817 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,818 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,835 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:49,910 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,910 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:49,911 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:49,928 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,002 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,003 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,004 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,020 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,096 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,096 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,097 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,113 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,188 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,188 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,188 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:50,191 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 12:33:50,194 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 12:33:50,196 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,212 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,287 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,287 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,288 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,305 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,381 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,381 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,382 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,400 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,477 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,477 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,479 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,497 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,572 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,572 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,573 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,591 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,666 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,666 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,667 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,683 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,758 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,758 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,759 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,776 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,851 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,851 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,852 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,869 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:50,944 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,945 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:50,946 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:50,964 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,039 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,039 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,040 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,056 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,131 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,131 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,132 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,149 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,226 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,227 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,228 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,245 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,319 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,319 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,321 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,337 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,412 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,412 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,413 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,432 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,506 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,506 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,507 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,524 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,598 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,599 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,600 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,616 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,691 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,691 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,692 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,708 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,784 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,784 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,785 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,802 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,884 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,885 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,886 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,901 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:51,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,976 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:51,977 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:51,996 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,072 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,072 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,072 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:52,075 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 12:33:52,078 - INFO - Processing story: Back_To_The_Wall
2026-01-29 12:33:52,081 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,098 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,172 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,172 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,173 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,189 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,270 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,271 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,272 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,290 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,365 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,365 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,367 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,384 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,459 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,459 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,460 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,477 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,551 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,551 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,552 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,568 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,642 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,642 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,643 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,660 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,735 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,735 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,736 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,754 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,829 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,829 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,830 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,846 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:52,920 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,921 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:52,922 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:52,939 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,013 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,013 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,014 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,030 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,104 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,104 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,106 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,123 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,197 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,198 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,199 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,218 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,293 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,293 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,294 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,310 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,384 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,385 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,386 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,402 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,476 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,476 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,478 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,494 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,568 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,568 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,570 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,586 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,663 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,663 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,664 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,680 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,754 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,755 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,756 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,772 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,847 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,847 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,848 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,863 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:53,937 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,938 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:53,938 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:53,940 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 12:33:53,943 - INFO - Processing story: Community_Time
2026-01-29 12:33:53,946 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:53,962 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,036 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,036 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,037 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,055 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,130 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,130 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,131 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,148 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,223 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,223 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,224 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,240 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,314 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,314 - ERROR - Failed to process question 8 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,315 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,331 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,405 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,405 - ERROR - Failed to process question 10 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,407 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,423 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,498 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,498 - ERROR - Failed to process question 12 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,500 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,518 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,592 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,593 - ERROR - Failed to process question 14 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,594 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,610 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,683 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,684 - ERROR - Failed to process question 16 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,685 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,700 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,775 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,775 - ERROR - Failed to process question 18 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,776 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,792 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,867 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,867 - ERROR - Failed to process question 20 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,868 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,884 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:54,958 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,958 - ERROR - Failed to process question 22 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:54,960 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:54,979 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,053 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,053 - ERROR - Failed to process question 24 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,055 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,070 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,145 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,145 - ERROR - Failed to process question 26 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,146 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,163 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,238 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,238 - ERROR - Failed to process question 28 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,239 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,256 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,330 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,331 - ERROR - Failed to process question 30 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,332 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,348 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,425 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,426 - ERROR - Failed to process question 32 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,427 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,443 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,517 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,517 - ERROR - Failed to process question 34 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,519 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,535 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,609 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,610 - ERROR - Failed to process question 36 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,611 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,627 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,700 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,701 - ERROR - Failed to process question 38 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,702 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,719 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,793 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,794 - ERROR - Failed to process question 40 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,794 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:55,797 - INFO - ✓ Saved: Community_Time.json
2026-01-29 12:33:55,799 - INFO - Processing story: Fleabags
2026-01-29 12:33:55,802 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,821 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,896 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,896 - ERROR - Failed to process question 2 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,897 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:55,914 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:55,987 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,988 - ERROR - Failed to process question 4 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:55,989 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,006 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,080 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,081 - ERROR - Failed to process question 6 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,082 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,099 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,174 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,174 - ERROR - Failed to process question 8 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,175 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,192 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,266 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,267 - ERROR - Failed to process question 10 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,268 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,286 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,361 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,361 - ERROR - Failed to process question 12 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,362 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,379 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,454 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,454 - ERROR - Failed to process question 14 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,456 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,473 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,547 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,547 - ERROR - Failed to process question 16 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,548 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,564 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,638 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,639 - ERROR - Failed to process question 18 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,640 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,656 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,730 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,731 - ERROR - Failed to process question 20 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,732 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,750 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,825 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,825 - ERROR - Failed to process question 22 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,826 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,842 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:56,916 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,916 - ERROR - Failed to process question 24 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:56,917 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:56,934 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,009 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,009 - ERROR - Failed to process question 26 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,011 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,027 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,101 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,102 - ERROR - Failed to process question 28 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,103 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,121 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,195 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,195 - ERROR - Failed to process question 30 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,196 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,213 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,287 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,287 - ERROR - Failed to process question 32 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,288 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,305 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,378 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,379 - ERROR - Failed to process question 34 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,380 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,396 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,470 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,470 - ERROR - Failed to process question 36 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,472 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,487 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,561 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,561 - ERROR - Failed to process question 38 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,562 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,581 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,655 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,655 - ERROR - Failed to process question 40 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,655 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:57,658 - INFO - ✓ Saved: Fleabags.json
2026-01-29 12:33:57,660 - INFO - Processing story: Gravity_Reduced
2026-01-29 12:33:57,663 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,679 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,753 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,753 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,754 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,772 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,847 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,847 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,848 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,864 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:57,938 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,939 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:57,940 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:57,956 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,031 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,031 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,032 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,338 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,415 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,415 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,416 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,432 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,506 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,506 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,508 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,524 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,598 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,598 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,599 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,615 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,690 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,690 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,691 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,708 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,784 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,784 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,785 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,803 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,877 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,877 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,878 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,896 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:58,970 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,970 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:58,973 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:58,989 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,064 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,064 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,065 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,081 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,155 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,155 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,156 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,172 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,247 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,247 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,250 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,267 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,342 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,342 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,344 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,360 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,434 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,434 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,435 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,452 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,528 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,528 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,529 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,546 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,620 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,620 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,622 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,640 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,715 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,715 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,716 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,732 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,806 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,806 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,807 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:33:59,809 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-29 12:33:59,812 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 12:33:59,815 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,832 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:33:59,907 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,908 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:33:59,909 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:33:59,926 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,001 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,001 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,002 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,020 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,094 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,094 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,095 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,114 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,189 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,189 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,190 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,206 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,282 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,282 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,283 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,300 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,375 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,375 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,376 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,393 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,467 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,467 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,469 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,487 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,562 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,562 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,564 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,582 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,656 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,656 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,658 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,676 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,750 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,750 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,751 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,768 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,842 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,843 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,844 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,860 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:00,935 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,935 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:00,936 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:00,952 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,030 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,030 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,031 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,047 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,122 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,122 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,123 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,140 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,214 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,215 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,216 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,236 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,310 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,311 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,312 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,329 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,404 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,404 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,405 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,424 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,499 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,499 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,500 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,516 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,591 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,591 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,592 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,608 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,682 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,683 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,683 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:34:01,685 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-29 12:34:01,688 - INFO - Processing story: Honeybee
2026-01-29 12:34:01,691 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,708 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,782 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,782 - ERROR - Failed to process question 2 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,784 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,800 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,874 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,875 - ERROR - Failed to process question 4 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,876 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,894 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:01,969 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,969 - ERROR - Failed to process question 6 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:01,970 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:01,987 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,062 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,062 - ERROR - Failed to process question 8 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,063 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,079 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,154 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,154 - ERROR - Failed to process question 10 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,155 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,171 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,246 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,246 - ERROR - Failed to process question 12 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,247 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,263 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,338 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,338 - ERROR - Failed to process question 14 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,339 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,358 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,433 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,433 - ERROR - Failed to process question 16 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,434 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,451 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,525 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,525 - ERROR - Failed to process question 18 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,526 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,542 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,617 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,617 - ERROR - Failed to process question 20 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,618 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,635 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,709 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,709 - ERROR - Failed to process question 22 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,710 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,729 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,802 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,803 - ERROR - Failed to process question 24 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,804 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,819 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,894 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,894 - ERROR - Failed to process question 26 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,896 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:02,912 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:02,986 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,986 - ERROR - Failed to process question 28 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:02,987 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,003 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,078 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,078 - ERROR - Failed to process question 30 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,080 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,095 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,170 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,170 - ERROR - Failed to process question 32 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,171 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,189 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,263 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,264 - ERROR - Failed to process question 34 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,265 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,283 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,358 - ERROR - Failed to process question 36 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,359 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,375 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,450 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,451 - ERROR - Failed to process question 38 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,452 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,468 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,542 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,542 - ERROR - Failed to process question 40 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,543 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:34:03,545 - INFO - ✓ Saved: Honeybee.json
2026-01-29 12:34:03,548 - INFO - Processing story: Last_Long_Night
2026-01-29 12:34:03,550 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,566 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,641 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,641 - ERROR - Failed to process question 2 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,642 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,660 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,735 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,735 - ERROR - Failed to process question 4 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,736 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,752 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,827 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,827 - ERROR - Failed to process question 6 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,828 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,845 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:03,919 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,919 - ERROR - Failed to process question 8 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:03,921 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:03,940 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,014 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,014 - ERROR - Failed to process question 10 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,015 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,031 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,105 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,105 - ERROR - Failed to process question 12 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,109 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,125 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,199 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,200 - ERROR - Failed to process question 14 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,201 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,217 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,292 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,292 - ERROR - Failed to process question 16 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,293 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,309 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,383 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,383 - ERROR - Failed to process question 18 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,384 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,400 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,475 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,475 - ERROR - Failed to process question 20 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,476 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,494 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,568 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,568 - ERROR - Failed to process question 22 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,569 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,585 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,660 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,660 - ERROR - Failed to process question 24 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,661 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,678 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,753 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,753 - ERROR - Failed to process question 26 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,755 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,772 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,848 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,848 - ERROR - Failed to process question 28 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,850 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,867 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:04,941 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,941 - ERROR - Failed to process question 30 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:04,942 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:04,961 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,036 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,036 - ERROR - Failed to process question 32 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,038 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,054 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,128 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,129 - ERROR - Failed to process question 34 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,130 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,146 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,220 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,220 - ERROR - Failed to process question 36 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,222 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,238 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,312 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,312 - ERROR - Failed to process question 38 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,313 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,329 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,404 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,404 - ERROR - Failed to process question 40 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,404 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:34:05,407 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-29 12:34:05,410 - INFO - Processing story: Raindrop_Snowflake
2026-01-29 12:34:05,412 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,431 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,506 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,506 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,507 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,524 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,599 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,599 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,600 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,616 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,691 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,691 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,692 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,708 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,783 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,783 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,784 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,805 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,879 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,880 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,881 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,901 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:05,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,977 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:05,979 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:05,997 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,071 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,071 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,073 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,089 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,164 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,164 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,165 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,181 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,256 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,256 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,257 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,276 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,350 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,350 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,351 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,367 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,441 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,441 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,442 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,459 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,534 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,534 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,535 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,552 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,626 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,626 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,628 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,646 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,721 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,721 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,722 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,741 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,815 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,816 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,817 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,835 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:06,910 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,910 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:06,911 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:06,928 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,003 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,003 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,004 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,020 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,095 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,095 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,097 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,114 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,188 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,188 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,190 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,209 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,283 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,284 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,284 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:34:07,286 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-29 12:34:07,289 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-29 12:34:07,291 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,307 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,382 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,383 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,384 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,400 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,475 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,476 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,477 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,493 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,567 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,567 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,568 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,586 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,662 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,662 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,664 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,680 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,754 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,755 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,756 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,772 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,846 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,846 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,847 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,864 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:07,939 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,939 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:07,940 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:07,956 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,031 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,032 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,033 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,052 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,126 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,126 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,127 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,144 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,218 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,218 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,220 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,236 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,310 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,310 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,311 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,327 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,401 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,402 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,403 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,419 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,493 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,493 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,494 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,512 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,587 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,587 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,588 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,605 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,680 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,680 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,682 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,698 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,772 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,772 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,773 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,789 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,864 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,865 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,866 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,881 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:08,957 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,958 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:34:08,960 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:34:08,978 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-01-29 12:34:09,025 - WARNING - 
Process interrupted by user
2026-01-29 12:40:31,170 - INFO - ============================================================
2026-01-29 12:40:31,170 - INFO - CONNECT Project - Phase 1
2026-01-29 12:40:31,170 - INFO - Problem: inverse
2026-01-29 12:40:31,170 - INFO - ============================================================
2026-01-29 12:40:31,170 - INFO - 
============================================================
2026-01-29 12:40:31,170 - INFO - PHASE 1: TRAINING
2026-01-29 12:40:31,170 - INFO - ============================================================
2026-01-29 12:40:31,170 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 12:40:31,172 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 12:40:31,193 - INFO - Successfully loaded 28 stories
2026-01-29 12:40:31,193 - INFO - Loaded 28 training stories
2026-01-29 12:40:31,196 - INFO - Survey results will be saved to: output/phase1/bedrock-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 12:40:31,200 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 12:40:31,224 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:31,994 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:31,994 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:31,995 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,086 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,086 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,087 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,175 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,176 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,177 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,264 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,264 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,265 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,354 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,354 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,356 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,443 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,443 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,444 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,533 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,533 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,534 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,621 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,621 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,623 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,710 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,710 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,711 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,798 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,798 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,799 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,887 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,887 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,888 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:32,977 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,978 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:32,979 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,067 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,067 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,069 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,157 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,157 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,159 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,247 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,247 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,248 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,337 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,337 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,338 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,428 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,428 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,429 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,517 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,517 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,518 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,609 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,609 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,611 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,699 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,699 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,699 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:33,702 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 12:40:33,705 - INFO - Processing story: About_a_Hum
2026-01-29 12:40:33,708 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,795 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,795 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,797 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,887 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,888 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,889 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:33,977 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,977 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:33,979 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,067 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,067 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,068 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,156 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,156 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,157 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,245 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,245 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,247 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,339 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,339 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,341 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,429 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,429 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,430 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,518 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,518 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,520 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,608 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,608 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,609 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,697 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,698 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,699 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,788 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,789 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,791 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,878 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,878 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,880 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:34,969 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,969 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:34,972 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,061 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,061 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,062 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,150 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,150 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,151 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,241 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,241 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,242 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,330 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,330 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,331 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,419 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,419 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,420 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,509 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,509 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,509 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:35,511 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 12:40:35,514 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 12:40:35,517 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,607 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,607 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,609 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,700 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,700 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,702 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,790 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,790 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,791 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,880 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,880 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,881 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:35,969 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,969 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:35,971 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,059 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,060 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,061 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,151 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,151 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,152 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,240 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,240 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,242 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,329 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,329 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,331 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,419 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,419 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,420 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,507 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,507 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,509 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,597 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,597 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,598 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,690 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,690 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,691 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,779 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,779 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,780 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,869 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,869 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,870 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:36,959 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,959 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:36,960 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,048 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,048 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,049 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,140 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,140 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,141 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,233 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,233 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,234 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,323 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,323 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,323 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:37,326 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 12:40:37,329 - INFO - Processing story: Back_To_The_Wall
2026-01-29 12:40:37,332 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,420 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,421 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,422 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,510 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,510 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,511 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,600 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,601 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,602 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,690 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,690 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,691 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,779 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,780 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,781 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,869 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,869 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,870 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:37,959 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,959 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:37,960 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,050 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,050 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,051 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,139 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,139 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,140 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,228 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,229 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,230 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,318 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,319 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,320 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,414 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,414 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,415 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,525 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,525 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,526 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,614 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,616 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,703 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,704 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,705 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,792 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,792 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,793 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,881 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,881 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,883 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:38,973 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,973 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:38,974 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,077 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,077 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,079 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,167 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,167 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,168 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:39,170 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 12:40:39,173 - INFO - Processing story: Community_Time
2026-01-29 12:40:39,176 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,264 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,265 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,266 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,355 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,355 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,357 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,447 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,447 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,448 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,536 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,536 - ERROR - Failed to process question 8 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,538 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,625 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,625 - ERROR - Failed to process question 10 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,627 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,716 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,716 - ERROR - Failed to process question 12 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,718 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,807 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,807 - ERROR - Failed to process question 14 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,808 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,900 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,900 - ERROR - Failed to process question 16 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,902 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:39,990 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,990 - ERROR - Failed to process question 18 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:39,993 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,081 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,081 - ERROR - Failed to process question 20 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,084 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,174 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,175 - ERROR - Failed to process question 22 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,176 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,266 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,266 - ERROR - Failed to process question 24 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,267 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,358 - ERROR - Failed to process question 26 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,359 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,448 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,448 - ERROR - Failed to process question 28 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,449 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,537 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,538 - ERROR - Failed to process question 30 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,539 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,626 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,626 - ERROR - Failed to process question 32 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,627 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,720 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,720 - ERROR - Failed to process question 34 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,721 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,808 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,809 - ERROR - Failed to process question 36 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,810 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,899 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,900 - ERROR - Failed to process question 38 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,901 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:40,989 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,989 - ERROR - Failed to process question 40 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:40,989 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:40,993 - INFO - ✓ Saved: Community_Time.json
2026-01-29 12:40:41,655 - INFO - Processing story: Fleabags
2026-01-29 12:40:41,658 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:41,745 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,745 - ERROR - Failed to process question 2 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,746 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:41,834 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,834 - ERROR - Failed to process question 4 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,835 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:41,923 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,923 - ERROR - Failed to process question 6 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:41,924 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,016 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,016 - ERROR - Failed to process question 8 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,017 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,104 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,104 - ERROR - Failed to process question 10 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,105 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,203 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,203 - ERROR - Failed to process question 12 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,205 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,292 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,293 - ERROR - Failed to process question 14 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,296 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,384 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,385 - ERROR - Failed to process question 16 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,386 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,476 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,476 - ERROR - Failed to process question 18 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,477 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,565 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,566 - ERROR - Failed to process question 20 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,567 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,654 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,655 - ERROR - Failed to process question 22 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,656 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,744 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,745 - ERROR - Failed to process question 24 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,746 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,835 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,835 - ERROR - Failed to process question 26 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,836 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:42,925 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,925 - ERROR - Failed to process question 28 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:42,926 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,014 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,014 - ERROR - Failed to process question 30 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,016 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,104 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,104 - ERROR - Failed to process question 32 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,105 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,192 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,193 - ERROR - Failed to process question 34 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,194 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,280 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,281 - ERROR - Failed to process question 36 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,282 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,372 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,372 - ERROR - Failed to process question 38 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,374 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,460 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,461 - ERROR - Failed to process question 40 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,461 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:43,463 - INFO - ✓ Saved: Fleabags.json
2026-01-29 12:40:43,466 - INFO - Processing story: Gravity_Reduced
2026-01-29 12:40:43,468 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,557 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,557 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,558 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,647 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,647 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,648 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,736 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,736 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,737 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,827 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,827 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,828 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:43,915 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,915 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:43,916 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,004 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,004 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,005 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,093 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,093 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,094 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,182 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,182 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,183 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,272 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,272 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,273 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,656 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,656 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,658 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,745 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,745 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,746 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,834 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,834 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,835 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:44,923 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,923 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:44,924 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,012 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,012 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,015 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,103 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,103 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,104 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,191 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,192 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,193 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,281 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,281 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,282 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,370 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,370 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,371 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,458 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,458 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,459 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,549 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,549 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,549 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:45,551 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-29 12:40:45,554 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 12:40:45,556 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,644 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,644 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,645 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,732 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,732 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,733 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,820 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,820 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,821 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:45,910 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,910 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:45,911 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,001 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,001 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,002 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,091 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,091 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,092 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,180 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,180 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,181 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,270 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,270 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,271 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,359 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,360 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,449 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,449 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,451 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,538 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,539 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,540 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,627 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,627 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,628 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,716 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,716 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,717 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,805 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,806 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,807 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,897 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,897 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,899 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:46,987 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,987 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:46,988 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,076 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,076 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,077 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,165 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,165 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,167 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,255 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,255 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,256 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,346 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,346 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,346 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:47,348 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-29 12:40:47,351 - INFO - Processing story: Honeybee
2026-01-29 12:40:47,354 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,441 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,442 - ERROR - Failed to process question 2 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,443 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,530 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,531 - ERROR - Failed to process question 4 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,532 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,619 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,619 - ERROR - Failed to process question 6 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,620 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,708 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,708 - ERROR - Failed to process question 8 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,709 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,799 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,799 - ERROR - Failed to process question 10 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,801 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,888 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,888 - ERROR - Failed to process question 12 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,890 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:47,977 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,978 - ERROR - Failed to process question 14 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:47,979 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,067 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,068 - ERROR - Failed to process question 16 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,069 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,156 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,157 - ERROR - Failed to process question 18 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,158 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,247 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,247 - ERROR - Failed to process question 20 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,248 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,337 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,337 - ERROR - Failed to process question 22 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,338 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,427 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,428 - ERROR - Failed to process question 24 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,429 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,517 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,517 - ERROR - Failed to process question 26 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,518 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,606 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,606 - ERROR - Failed to process question 28 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,608 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,698 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,698 - ERROR - Failed to process question 30 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,699 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,788 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,788 - ERROR - Failed to process question 32 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,789 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,877 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,877 - ERROR - Failed to process question 34 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,878 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:48,967 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,967 - ERROR - Failed to process question 36 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:48,968 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,056 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,056 - ERROR - Failed to process question 38 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,057 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,146 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,146 - ERROR - Failed to process question 40 for story Honeybee: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,146 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:49,149 - INFO - ✓ Saved: Honeybee.json
2026-01-29 12:40:49,152 - INFO - Processing story: Last_Long_Night
2026-01-29 12:40:49,154 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,241 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,242 - ERROR - Failed to process question 2 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,244 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,332 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,333 - ERROR - Failed to process question 4 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,334 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,422 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,422 - ERROR - Failed to process question 6 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,423 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,511 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,511 - ERROR - Failed to process question 8 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,512 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,603 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,603 - ERROR - Failed to process question 10 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,605 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,694 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,694 - ERROR - Failed to process question 12 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,695 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,783 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,783 - ERROR - Failed to process question 14 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,784 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,874 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,874 - ERROR - Failed to process question 16 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,875 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:49,964 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,964 - ERROR - Failed to process question 18 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:49,965 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,053 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,053 - ERROR - Failed to process question 20 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,054 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,145 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,145 - ERROR - Failed to process question 22 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,146 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,234 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,234 - ERROR - Failed to process question 24 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,235 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,323 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,323 - ERROR - Failed to process question 26 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,324 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,413 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,413 - ERROR - Failed to process question 28 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,414 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,503 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,504 - ERROR - Failed to process question 30 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,506 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,595 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,595 - ERROR - Failed to process question 32 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,596 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,684 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,684 - ERROR - Failed to process question 34 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,685 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,773 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,773 - ERROR - Failed to process question 36 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,774 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,862 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,862 - ERROR - Failed to process question 38 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,864 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:50,951 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,952 - ERROR - Failed to process question 40 for story Last_Long_Night: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:50,952 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:50,955 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-29 12:40:50,958 - INFO - Processing story: Raindrop_Snowflake
2026-01-29 12:40:50,960 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,050 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,050 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,051 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,138 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,138 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,139 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,227 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,228 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,229 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,317 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,317 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,318 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,406 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,406 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,408 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,497 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,497 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,498 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,585 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,586 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,588 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,676 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,676 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,677 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,764 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,764 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,765 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,853 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,853 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,854 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:51,946 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,946 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:51,947 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,037 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,037 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,038 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,126 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,127 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,128 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,216 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,216 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,217 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,304 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,304 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,305 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,395 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,396 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,397 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,485 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,485 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,486 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,574 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,574 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,575 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,663 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,663 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,664 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,751 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,751 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,751 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:40:52,759 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-29 12:40:52,762 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-29 12:40:52,765 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,854 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,855 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,856 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:52,943 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,943 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:52,944 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:53,032 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:53,033 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:53,034 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:53,121 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:53,121 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:40:53,122 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:40:53,179 - WARNING - 
Process interrupted by user
2026-01-29 12:45:18,307 - INFO - ============================================================
2026-01-29 12:45:18,308 - INFO - CONNECT Project - Phase 1
2026-01-29 12:45:18,308 - INFO - Problem: inverse
2026-01-29 12:45:18,308 - INFO - ============================================================
2026-01-29 12:45:18,308 - INFO - 
============================================================
2026-01-29 12:45:18,308 - INFO - PHASE 1: TRAINING
2026-01-29 12:45:18,308 - INFO - ============================================================
2026-01-29 12:45:18,308 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 12:45:18,310 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 12:45:18,329 - INFO - Successfully loaded 28 stories
2026-01-29 12:45:18,329 - INFO - Loaded 28 training stories
2026-01-29 12:45:18,332 - INFO - Survey results will be saved to: output/phase1/bedrock-invoke-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 12:45:18,336 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 12:45:18,359 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,118 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,118 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,119 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,209 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,209 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,210 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,297 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,297 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,298 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,386 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,386 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,387 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,473 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,473 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,474 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,561 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,561 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,563 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,651 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,651 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,652 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,740 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,740 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,741 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,828 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,828 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,829 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:19,915 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,915 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:19,917 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,003 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,003 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,004 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,093 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,093 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,094 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,180 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,180 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,181 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,268 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,268 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,269 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,357 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,357 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,358 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,445 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,445 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,446 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,535 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,535 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,536 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,623 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,623 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,624 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,712 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,712 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,713 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,802 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,802 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,802 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:45:20,804 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 12:45:20,807 - INFO - Processing story: About_a_Hum
2026-01-29 12:45:20,809 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,897 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,897 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,898 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:20,988 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,988 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:20,989 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,076 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,076 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,078 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,165 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,165 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,166 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,254 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,254 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,255 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,348 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,348 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,349 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,438 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,438 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,440 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,527 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,527 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,528 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,615 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,615 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,618 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,704 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,704 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,706 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,793 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,793 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,794 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,883 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,883 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,885 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:21,972 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,972 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:21,974 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,061 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,061 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,062 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,149 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,149 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,150 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,237 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,237 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,238 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,327 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,327 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,328 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,414 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,414 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,415 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,502 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,502 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,503 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,589 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,590 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,590 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:45:22,592 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 12:45:22,594 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 12:45:22,597 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,685 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,686 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,687 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,775 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,776 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,777 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,864 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,864 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,866 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:22,954 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,954 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:22,955 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,054 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,054 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,056 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,143 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,143 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,146 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,234 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,235 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,236 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,323 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,323 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,324 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,412 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,412 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,413 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,500 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,500 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,501 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,588 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,588 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,589 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,676 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,676 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,677 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,766 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,766 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,767 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,854 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,854 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,855 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:23,943 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,943 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:23,944 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,031 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,031 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,032 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,118 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,118 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,119 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,208 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,208 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,209 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,297 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,297 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,299 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,386 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,387 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,387 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:45:24,389 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 12:45:24,391 - INFO - Processing story: Back_To_The_Wall
2026-01-29 12:45:24,394 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,481 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,481 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,482 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,569 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,569 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,570 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,658 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,658 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,659 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,745 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,746 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,747 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,832 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,833 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,834 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,921 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,921 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:45:24,922 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:45:24,962 - WARNING - 
Process interrupted by user
2026-01-29 12:48:21,900 - INFO - ============================================================
2026-01-29 12:48:21,900 - INFO - CONNECT Project - Phase 1
2026-01-29 12:48:21,900 - INFO - Problem: inverse
2026-01-29 12:48:21,900 - INFO - ============================================================
2026-01-29 12:48:21,900 - INFO - 
============================================================
2026-01-29 12:48:21,900 - INFO - PHASE 1: TRAINING
2026-01-29 12:48:21,900 - INFO - ============================================================
2026-01-29 12:48:21,901 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 12:48:21,902 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 12:48:21,923 - INFO - Successfully loaded 28 stories
2026-01-29 12:48:21,923 - INFO - Loaded 28 training stories
2026-01-29 12:48:21,927 - INFO - Survey results will be saved to: output/phase1/bedrock-invoke-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 12:48:21,932 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 12:48:21,958 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:22,764 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,764 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,767 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:22,854 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,854 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,855 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:22,943 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,943 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:22,945 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,031 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,031 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,032 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,119 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,119 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,121 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,207 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,208 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,209 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,297 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,297 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,298 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,385 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,385 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,386 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,473 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,473 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,474 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,560 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,561 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,562 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,648 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,649 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,650 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,738 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,738 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,739 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,825 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,825 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,826 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:23,913 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,914 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:23,915 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,002 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,002 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,003 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,089 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,089 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,090 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,179 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,179 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,180 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,267 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,267 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,268 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,355 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,355 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,356 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,446 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,446 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,446 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:48:24,449 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 12:48:24,451 - INFO - Processing story: About_a_Hum
2026-01-29 12:48:24,454 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,542 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,542 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,544 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,633 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,634 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,635 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,724 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,724 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,726 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,813 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,813 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,815 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,903 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,903 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,904 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:24,991 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,992 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:24,993 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,088 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,088 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,089 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,181 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,181 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,182 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,269 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,269 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,270 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,359 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,359 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,360 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,447 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,447 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,448 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,537 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,537 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,538 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,625 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,626 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,627 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,720 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,720 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,722 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,810 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,810 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,811 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,899 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,899 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,900 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:25,991 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,991 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:25,992 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,078 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,079 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,080 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,168 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,168 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,169 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,255 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,255 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,255 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:48:26,258 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 12:48:26,261 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 12:48:26,264 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,351 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,351 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,353 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,441 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,441 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,442 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,529 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,529 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,530 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,619 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,619 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,620 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,707 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,707 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,708 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,796 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,796 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,797 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,888 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,888 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,889 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:26,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,976 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:26,978 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,065 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,065 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,066 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,153 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,153 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,154 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,242 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,242 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,245 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,333 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,334 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,336 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,426 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,426 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,427 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,514 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,515 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,516 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,603 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,603 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,604 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,694 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,694 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,695 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,782 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,783 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,784 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,874 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,875 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,876 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:27,971 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,972 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:27,973 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,061 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,062 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,062 - WARNING - No pricing found for model bedrock/invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 12:48:28,064 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 12:48:28,067 - INFO - Processing story: Back_To_The_Wall
2026-01-29 12:48:28,070 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,157 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,157 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,158 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,246 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,246 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,247 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,336 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,336 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,337 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,424 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,424 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,425 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,511 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,511 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,512 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,598 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,599 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,600 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,689 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,689 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,690 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,780 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,780 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,781 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,867 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,868 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,869 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:28,955 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,955 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:28,956 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,043 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,043 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,044 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,130 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,130 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,131 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,220 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,220 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,222 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,309 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,309 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,310 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,397 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,397 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 12:48:29,400 - INFO - 
LiteLLM completion() model= invoke/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 12:48:29,409 - WARNING - 
Process interrupted by user
2026-01-29 12:55:21,728 - INFO - ============================================================
2026-01-29 12:55:21,728 - INFO - CONNECT Project - Phase 1
2026-01-29 12:55:21,728 - INFO - Problem: inverse
2026-01-29 12:55:21,728 - INFO - ============================================================
2026-01-29 12:55:21,728 - INFO - 
============================================================
2026-01-29 12:55:21,729 - INFO - PHASE 1: TRAINING
2026-01-29 12:55:21,729 - INFO - ============================================================
2026-01-29 12:55:21,729 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 12:55:21,730 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 12:55:21,752 - INFO - Successfully loaded 28 stories
2026-01-29 12:55:21,752 - INFO - Loaded 28 training stories
2026-01-29 12:55:21,754 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-29 12:55:21,759 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 12:55:21,759 - INFO - Story A_Piece_of_Yellow_Soap already processed, skipping
2026-01-29 12:55:21,761 - INFO - Processing story: About_a_Hum
2026-01-29 12:55:21,762 - INFO - Story About_a_Hum already processed, skipping
2026-01-29 12:55:21,763 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 12:55:21,764 - INFO - Story All_Summer_in_a_Day_Ray_Bradbury already processed, skipping
2026-01-29 12:55:21,765 - INFO - Processing story: Back_To_The_Wall
2026-01-29 12:55:21,766 - INFO - Story Back_To_The_Wall already processed, skipping
2026-01-29 12:55:21,767 - INFO - Processing story: Community_Time
2026-01-29 12:55:21,768 - INFO - Story Community_Time already processed, skipping
2026-01-29 12:55:21,769 - INFO - Processing story: Fleabags
2026-01-29 12:55:21,770 - INFO - Story Fleabags already processed, skipping
2026-01-29 12:55:21,771 - INFO - Processing story: Gravity_Reduced
2026-01-29 12:55:21,772 - INFO - Story Gravity_Reduced already processed, skipping
2026-01-29 12:55:21,773 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 12:55:21,773 - INFO - Story Harrison_Bergeron_Kurt_Vonnegut already processed, skipping
2026-01-29 12:55:21,775 - INFO - Processing story: Honeybee
2026-01-29 12:55:21,775 - INFO - Story Honeybee already processed, skipping
2026-01-29 12:55:21,777 - INFO - Processing story: Last_Long_Night
2026-01-29 12:55:21,777 - INFO - Story Last_Long_Night already processed, skipping
2026-01-29 12:55:21,779 - INFO - Processing story: Raindrop_Snowflake
2026-01-29 12:55:21,779 - INFO - Story Raindrop_Snowflake already processed, skipping
2026-01-29 12:55:21,781 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-29 12:55:21,781 - INFO - Story Redemption_of_the_Cursed_Village already processed, skipping
2026-01-29 12:55:21,783 - INFO - Processing story: Rice
2026-01-29 12:55:21,783 - INFO - Story Rice already processed, skipping
2026-01-29 12:55:21,785 - INFO - Processing story: Swallowed
2026-01-29 12:55:21,785 - INFO - Story Swallowed already processed, skipping
2026-01-29 12:55:21,787 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-29 12:55:21,787 - INFO - Story The_Ants_and_The_Locusts already processed, skipping
2026-01-29 12:55:21,789 - INFO - Processing story: The_Christmas_Monks
2026-01-29 12:55:21,789 - INFO - Story The_Christmas_Monks already processed, skipping
2026-01-29 12:55:21,791 - INFO - Processing story: The_Circuit
2026-01-29 12:55:21,791 - INFO - Story The_Circuit already processed, skipping
2026-01-29 12:55:21,793 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-29 12:55:21,793 - INFO - Story The_Fire_That_Fed_the_People already processed, skipping
2026-01-29 12:55:21,795 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-29 12:55:21,795 - INFO - Story The_Gentleman_of_the_Jungle already processed, skipping
2026-01-29 12:55:21,796 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-29 12:55:21,797 - INFO - Story The_Pedestrian_Ray_Bradbury already processed, skipping
2026-01-29 12:55:21,798 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-29 12:55:21,799 - INFO - Story The_People_who_Dug_for_Rain already processed, skipping
2026-01-29 12:55:21,800 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-29 12:55:21,801 - INFO - Story The_Strangers_That_Came_to_Town_Ambrose_Flack already processed, skipping
2026-01-29 12:55:21,802 - INFO - Processing story: The_Stretcher
2026-01-29 12:55:21,803 - INFO - Story The_Stretcher already processed, skipping
2026-01-29 12:55:21,804 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-29 12:55:21,805 - INFO - Story The_village_that_Shared_the_Moonlight already processed, skipping
2026-01-29 12:55:21,806 - INFO - Processing story: War_of_the_Wall
2026-01-29 12:55:21,806 - INFO - Story War_of_the_Wall already processed, skipping
2026-01-29 12:55:21,808 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-29 12:55:21,808 - INFO - Story Warrior_Women_Nicaragua already processed, skipping
2026-01-29 12:55:21,810 - INFO - Processing story: We_Stand_Up
2026-01-29 12:55:21,810 - INFO - Story We_Stand_Up already processed, skipping
2026-01-29 12:55:21,812 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-29 12:55:21,812 - INFO - Story Whose_Voice_We_Wanted_to_Hear already processed, skipping
2026-01-29 12:55:21,817 - INFO - 
============================================================
2026-01-29 12:55:21,817 - INFO - Survey complete!
2026-01-29 12:55:21,817 - INFO - Processed: 28/28 stories
2026-01-29 12:55:21,817 - INFO - Failed: 0 stories
2026-01-29 12:55:21,817 - INFO - Total cost: $0.0000
2026-01-29 12:55:21,817 - INFO - Total tokens: 0
2026-01-29 12:55:21,817 - INFO - ============================================================

2026-01-29 12:55:21,818 - INFO - 
============================================================
2026-01-29 12:55:21,818 - INFO - Step 4: Learning PyReason Rules
2026-01-29 12:55:21,818 - INFO - ============================================================
2026-01-29 12:55:21,818 - INFO - ============================================================
2026-01-29 12:55:21,818 - INFO - RULE LEARNING
2026-01-29 12:55:21,818 - INFO - ============================================================
2026-01-29 12:55:21,818 - INFO - Loading survey results from: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-29 12:55:21,819 - INFO - Found 28 survey result files
2026-01-29 12:55:21,855 - INFO - Successfully loaded 28 survey results
2026-01-29 12:55:21,855 - INFO - Extracting feature scores...
2026-01-29 12:55:21,857 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-29 12:55:21,857 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-29 12:55:21,858 - INFO - Extracted scores for 28 stories and 20 features
2026-01-29 12:55:21,858 - INFO - Learning PyReason rules...
2026-01-29 12:55:21,858 - INFO - Configuration:
2026-01-29 12:55:21,858 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-29 12:55:21,858 - INFO -   - Min confidence: 0.0
2026-01-29 12:55:21,858 - INFO -   - Min support: 0
2026-01-29 12:55:21,858 - INFO - Learning rules for 20 features...
2026-01-29 12:55:21,859 - INFO - Learned 100 rules
2026-01-29 12:55:21,862 - INFO - Saved 100 rules to output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 12:55:21,862 - INFO - ============================================================
2026-01-29 12:55:21,862 - INFO - RULE LEARNING COMPLETE
2026-01-29 12:55:21,862 - INFO - ============================================================
2026-01-29 12:55:21,862 - INFO - Stories processed: 28
2026-01-29 12:55:21,862 - INFO - Features: 20
2026-01-29 12:55:21,863 - INFO - Rules learned: 100
2026-01-29 12:55:21,863 - INFO - Rules saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 12:55:21,863 - INFO - ============================================================
2026-01-29 12:55:21,863 - INFO - 
Sample rules:
2026-01-29 12:55:21,863 - INFO -   1. corpus(X, behavioral_guidance):[0.21,0.21] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 12:55:21,863 - INFO -   2. corpus(X, behavioral_guidance):[0.61,0.61] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 12:55:21,863 - INFO -   3. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 12:55:21,863 - INFO -   4. corpus(X, behavioral_guidance):[0.11,0.11] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 12:55:21,863 - INFO -   5. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 12:55:21,863 - INFO -   ... and 95 more
2026-01-29 12:55:21,864 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 12:55:21,864 - INFO - 
Phase 1 completed successfully!
2026-01-29 12:55:21,864 - INFO - Output directory: output/phase1
2026-01-29 12:55:21,865 - INFO - ============================================================
2026-01-29 12:55:21,865 - INFO - Execution completed successfully!
2026-01-29 12:55:21,865 - INFO - ============================================================
2026-01-29 13:02:18,562 - INFO - ============================================================
2026-01-29 13:02:18,562 - INFO - CONNECT Project - Phase 1
2026-01-29 13:02:18,562 - INFO - Problem: inverse
2026-01-29 13:02:18,562 - INFO - ============================================================
2026-01-29 13:02:18,563 - INFO - 
============================================================
2026-01-29 13:02:18,563 - INFO - PHASE 1: TRAINING
2026-01-29 13:02:18,563 - INFO - ============================================================
2026-01-29 13:02:18,563 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 13:02:18,564 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 13:02:18,586 - INFO - Successfully loaded 28 stories
2026-01-29 13:02:18,586 - INFO - Loaded 28 training stories
2026-01-29 13:02:18,589 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/survey_results
2026-01-29 13:02:18,594 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 13:02:18,616 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:19,523 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,523 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,526 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:19,730 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,730 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,731 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:19,966 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,966 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:19,967 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:20,187 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,188 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,189 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:20,402 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,403 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,404 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:20,634 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,634 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,635 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:20,878 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,879 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:20,880 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:21,123 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,123 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,126 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:21,356 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,356 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,358 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:21,575 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,575 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,576 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:21,778 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,778 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:21,780 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:22,005 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,005 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,007 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:22,201 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,201 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,203 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:22,430 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,430 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,431 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:22,660 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,661 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,662 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:22,877 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,877 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:22,878 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:23,092 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,092 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,094 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:23,319 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,319 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,320 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:23,543 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,543 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,544 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:23,763 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,763 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:23,763 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:02:23,767 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 13:02:23,769 - INFO - Processing story: About_a_Hum
2026-01-29 13:02:23,772 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:24,105 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,105 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,107 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:24,334 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,334 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,335 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:24,562 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,562 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,564 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:24,768 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,768 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,770 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:24,975 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,975 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:24,976 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:25,268 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,268 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,270 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:25,517 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,517 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,519 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:25,734 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,734 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:25,735 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:26,048 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,048 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,049 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:26,275 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,275 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,276 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:26,540 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,540 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,542 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:26,759 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,759 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,760 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:26,975 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,975 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:26,976 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:27,188 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,189 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,190 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:27,433 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,433 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,434 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:27,656 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,656 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,658 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:27,881 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,881 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:27,882 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:28,101 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,101 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,102 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:28,314 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,314 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,315 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:28,544 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,544 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,544 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:02:28,547 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 13:02:28,550 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 13:02:28,552 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:28,781 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,781 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:28,782 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:29,019 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:29,020 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:29,021 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:29,225 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:29,225 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:02:29,226 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:02:29,305 - WARNING - 
Process interrupted by user
2026-01-29 13:10:12,872 - INFO - ============================================================
2026-01-29 13:10:12,872 - INFO - CONNECT Project - Phase 1
2026-01-29 13:10:12,873 - INFO - Problem: inverse
2026-01-29 13:10:12,873 - INFO - ============================================================
2026-01-29 13:10:12,873 - INFO - 
============================================================
2026-01-29 13:10:12,873 - INFO - PHASE 1: TRAINING
2026-01-29 13:10:12,873 - INFO - ============================================================
2026-01-29 13:10:12,873 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 13:10:12,875 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 13:10:12,897 - INFO - Successfully loaded 28 stories
2026-01-29 13:10:12,898 - INFO - Loaded 28 training stories
2026-01-29 13:10:12,899 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-29 13:10:12,903 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 13:10:12,903 - INFO - Story A_Piece_of_Yellow_Soap already processed, skipping
2026-01-29 13:10:12,905 - INFO - Processing story: About_a_Hum
2026-01-29 13:10:12,905 - INFO - Story About_a_Hum already processed, skipping
2026-01-29 13:10:12,907 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 13:10:12,907 - INFO - Story All_Summer_in_a_Day_Ray_Bradbury already processed, skipping
2026-01-29 13:10:12,909 - INFO - Processing story: Back_To_The_Wall
2026-01-29 13:10:12,909 - INFO - Story Back_To_The_Wall already processed, skipping
2026-01-29 13:10:12,911 - INFO - Processing story: Community_Time
2026-01-29 13:10:12,911 - INFO - Story Community_Time already processed, skipping
2026-01-29 13:10:12,913 - INFO - Processing story: Fleabags
2026-01-29 13:10:12,913 - INFO - Story Fleabags already processed, skipping
2026-01-29 13:10:12,915 - INFO - Processing story: Gravity_Reduced
2026-01-29 13:10:12,915 - INFO - Story Gravity_Reduced already processed, skipping
2026-01-29 13:10:12,918 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 13:10:12,918 - INFO - Story Harrison_Bergeron_Kurt_Vonnegut already processed, skipping
2026-01-29 13:10:12,920 - INFO - Processing story: Honeybee
2026-01-29 13:10:12,920 - INFO - Story Honeybee already processed, skipping
2026-01-29 13:10:12,922 - INFO - Processing story: Last_Long_Night
2026-01-29 13:10:12,922 - INFO - Story Last_Long_Night already processed, skipping
2026-01-29 13:10:12,924 - INFO - Processing story: Raindrop_Snowflake
2026-01-29 13:10:12,924 - INFO - Story Raindrop_Snowflake already processed, skipping
2026-01-29 13:10:12,926 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-29 13:10:12,926 - INFO - Story Redemption_of_the_Cursed_Village already processed, skipping
2026-01-29 13:10:12,927 - INFO - Processing story: Rice
2026-01-29 13:10:12,928 - INFO - Story Rice already processed, skipping
2026-01-29 13:10:12,929 - INFO - Processing story: Swallowed
2026-01-29 13:10:12,930 - INFO - Story Swallowed already processed, skipping
2026-01-29 13:10:12,931 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-29 13:10:12,932 - INFO - Story The_Ants_and_The_Locusts already processed, skipping
2026-01-29 13:10:12,933 - INFO - Processing story: The_Christmas_Monks
2026-01-29 13:10:12,934 - INFO - Story The_Christmas_Monks already processed, skipping
2026-01-29 13:10:12,935 - INFO - Processing story: The_Circuit
2026-01-29 13:10:12,936 - INFO - Story The_Circuit already processed, skipping
2026-01-29 13:10:12,937 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-29 13:10:12,938 - INFO - Story The_Fire_That_Fed_the_People already processed, skipping
2026-01-29 13:10:12,939 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-29 13:10:12,940 - INFO - Story The_Gentleman_of_the_Jungle already processed, skipping
2026-01-29 13:10:12,941 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-29 13:10:12,942 - INFO - Story The_Pedestrian_Ray_Bradbury already processed, skipping
2026-01-29 13:10:12,943 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-29 13:10:12,944 - INFO - Story The_People_who_Dug_for_Rain already processed, skipping
2026-01-29 13:10:12,945 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-29 13:10:12,946 - INFO - Story The_Strangers_That_Came_to_Town_Ambrose_Flack already processed, skipping
2026-01-29 13:10:12,947 - INFO - Processing story: The_Stretcher
2026-01-29 13:10:12,948 - INFO - Story The_Stretcher already processed, skipping
2026-01-29 13:10:12,949 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-29 13:10:12,950 - INFO - Story The_village_that_Shared_the_Moonlight already processed, skipping
2026-01-29 13:10:12,951 - INFO - Processing story: War_of_the_Wall
2026-01-29 13:10:12,951 - INFO - Story War_of_the_Wall already processed, skipping
2026-01-29 13:10:12,953 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-29 13:10:12,953 - INFO - Story Warrior_Women_Nicaragua already processed, skipping
2026-01-29 13:10:12,955 - INFO - Processing story: We_Stand_Up
2026-01-29 13:10:12,955 - INFO - Story We_Stand_Up already processed, skipping
2026-01-29 13:10:12,957 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-29 13:10:12,957 - INFO - Story Whose_Voice_We_Wanted_to_Hear already processed, skipping
2026-01-29 13:10:12,961 - INFO - 
============================================================
2026-01-29 13:10:12,961 - INFO - Survey complete!
2026-01-29 13:10:12,961 - INFO - Processed: 28/28 stories
2026-01-29 13:10:12,962 - INFO - Failed: 0 stories
2026-01-29 13:10:12,962 - INFO - Total cost: $0.0000
2026-01-29 13:10:12,962 - INFO - Total tokens: 0
2026-01-29 13:10:12,962 - INFO - ============================================================

2026-01-29 13:10:12,962 - INFO - 
============================================================
2026-01-29 13:10:12,962 - INFO - Step 4: Learning PyReason Rules
2026-01-29 13:10:12,962 - INFO - ============================================================
2026-01-29 13:10:12,962 - INFO - ============================================================
2026-01-29 13:10:12,962 - INFO - RULE LEARNING
2026-01-29 13:10:12,962 - INFO - ============================================================
2026-01-29 13:10:12,962 - INFO - Loading survey results from: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/survey_results
2026-01-29 13:10:12,963 - INFO - Found 28 survey result files
2026-01-29 13:10:13,000 - INFO - Successfully loaded 28 survey results
2026-01-29 13:10:13,000 - INFO - Extracting feature scores...
2026-01-29 13:10:13,003 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:10:13,003 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:10:13,003 - INFO - Extracted scores for 28 stories and 20 features
2026-01-29 13:10:13,003 - INFO - Learning PyReason rules...
2026-01-29 13:10:13,003 - INFO - Configuration:
2026-01-29 13:10:13,003 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-29 13:10:13,004 - INFO -   - Min confidence: 0.0
2026-01-29 13:10:13,004 - INFO -   - Min support: 0
2026-01-29 13:10:13,004 - INFO - Learning rules for 20 features...
2026-01-29 13:10:13,005 - INFO - Learned 100 rules
2026-01-29 13:10:13,008 - INFO - Saved 100 rules to output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:10:13,008 - INFO - ============================================================
2026-01-29 13:10:13,008 - INFO - RULE LEARNING COMPLETE
2026-01-29 13:10:13,008 - INFO - ============================================================
2026-01-29 13:10:13,008 - INFO - Stories processed: 28
2026-01-29 13:10:13,008 - INFO - Features: 20
2026-01-29 13:10:13,008 - INFO - Rules learned: 100
2026-01-29 13:10:13,008 - INFO - Rules saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:10:13,008 - INFO - ============================================================
2026-01-29 13:10:13,008 - INFO - 
Sample rules:
2026-01-29 13:10:13,009 - INFO -   1. corpus(X, behavioral_guidance):[0.21,0.21] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 13:10:13,009 - INFO -   2. corpus(X, behavioral_guidance):[0.61,0.61] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 13:10:13,009 - INFO -   3. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 13:10:13,009 - INFO -   4. corpus(X, behavioral_guidance):[0.11,0.11] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 13:10:13,009 - INFO -   5. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-01-29 13:10:13,009 - INFO -   ... and 95 more
2026-01-29 13:10:13,010 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-us.meta.llama4-maverick-17b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:10:13,010 - INFO - 
Phase 1 completed successfully!
2026-01-29 13:10:13,010 - INFO - Output directory: output/phase1
2026-01-29 13:10:13,011 - INFO - ============================================================
2026-01-29 13:10:13,011 - INFO - Execution completed successfully!
2026-01-29 13:10:13,011 - INFO - ============================================================
2026-01-29 13:11:02,715 - INFO - ============================================================
2026-01-29 13:11:02,715 - INFO - CONNECT Project - Phase 1
2026-01-29 13:11:02,715 - INFO - Problem: inverse
2026-01-29 13:11:02,715 - INFO - ============================================================
2026-01-29 13:11:02,716 - INFO - 
============================================================
2026-01-29 13:11:02,716 - INFO - PHASE 1: TRAINING
2026-01-29 13:11:02,716 - INFO - ============================================================
2026-01-29 13:11:02,716 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 13:11:02,717 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 13:11:02,739 - INFO - Successfully loaded 28 stories
2026-01-29 13:11:02,739 - INFO - Loaded 28 training stories
2026-01-29 13:11:02,742 - INFO - Survey results will be saved to: output/phase1/bedrock-us.meta.llama3-2-11b-instruct-v1-0/inverse/survey_results
2026-01-29 13:11:02,746 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 13:11:02,773 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:03,730 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:03,730 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:03,734 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:03,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:03,976 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:03,977 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:04,308 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,309 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,310 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:04,637 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,637 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,638 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:04,885 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,885 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:04,886 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:05,137 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,137 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,139 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:05,359 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,360 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,361 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:05,601 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,602 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,603 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:05,859 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,860 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:05,861 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:06,093 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,093 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,094 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:06,315 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,315 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,316 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:06,542 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,542 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,543 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:06,793 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,793 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:06,794 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:07,016 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,016 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,017 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:07,244 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,244 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,245 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:07,461 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,461 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,462 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:07,785 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,785 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:07,786 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:08,011 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,012 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,013 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:08,226 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,226 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,227 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:08,472 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,472 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,473 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:11:08,475 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 13:11:08,478 - INFO - Processing story: About_a_Hum
2026-01-29 13:11:08,481 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:08,728 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,728 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,729 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:08,945 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,945 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:08,947 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:09,165 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,166 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,167 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:09,374 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,374 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,375 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:09,607 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,607 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,608 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:09,903 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,904 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:09,905 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:10,122 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,122 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,123 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:10,361 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,362 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,363 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:10,620 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,620 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,622 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:10,878 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,879 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:10,880 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:11,124 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,124 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,125 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:11,376 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,376 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,377 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:11,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,614 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,616 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:11,834 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,834 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:11,835 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:12,119 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,119 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,120 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:12,342 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,343 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,344 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:12,578 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,579 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,580 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:12,795 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,795 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:12,796 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:13,019 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,019 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,020 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:13,297 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,297 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,297 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:11:13,299 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 13:11:13,302 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 13:11:13,305 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:13,533 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,533 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,534 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:13,830 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,830 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:13,831 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:14,061 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,061 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,062 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:14,280 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,280 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,281 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:14,519 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,519 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,520 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:14,762 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,763 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,765 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:14,981 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,981 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:14,982 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:15,397 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,397 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,398 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:15,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,614 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,615 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:15,857 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,858 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:15,859 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:16,081 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,082 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,083 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:16,295 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,295 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,297 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:16,490 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,491 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,492 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:16,758 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,758 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,759 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:16,999 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:16,999 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,000 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:17,233 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,234 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,235 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:17,446 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,447 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,448 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:17,719 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,720 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,721 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:17,946 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,946 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:17,947 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:18,184 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,184 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,184 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:11:18,186 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 13:11:18,190 - INFO - Processing story: Back_To_The_Wall
2026-01-29 13:11:18,192 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:18,405 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,405 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,406 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:18,644 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,644 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,646 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:18,879 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,879 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:18,880 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:19,098 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,098 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,099 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:19,329 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,330 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,331 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:19,563 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,563 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,564 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:19,791 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,791 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:19,792 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:20,067 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,067 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,068 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:20,281 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,281 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,282 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:20,504 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,504 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,505 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:20,736 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,736 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,737 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:20,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,976 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:20,977 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:21,189 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,189 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,190 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:21,401 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,401 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,402 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:21,634 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,634 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,635 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:21,847 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,847 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:21,848 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:22,062 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,062 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,063 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:22,261 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,261 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,262 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:22,484 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,484 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,485 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:22,725 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,726 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,726 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:11:22,728 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 13:11:22,731 - INFO - Processing story: Community_Time
2026-01-29 13:11:22,734 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:22,969 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,969 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:22,970 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:23,198 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,198 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,199 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:23,433 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,434 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,435 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:23,710 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,711 - ERROR - Failed to process question 8 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,712 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:23,955 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,955 - ERROR - Failed to process question 10 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:23,956 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:24,193 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,193 - ERROR - Failed to process question 12 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,194 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:24,441 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,441 - ERROR - Failed to process question 14 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,442 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:24,669 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,669 - ERROR - Failed to process question 16 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,671 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:24,907 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,907 - ERROR - Failed to process question 18 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:24,908 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:25,131 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,131 - ERROR - Failed to process question 20 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,132 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:25,339 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,339 - ERROR - Failed to process question 22 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,341 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:25,599 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,599 - ERROR - Failed to process question 24 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,600 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:25,812 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,812 - ERROR - Failed to process question 26 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:25,814 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:26,032 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,033 - ERROR - Failed to process question 28 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,034 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:26,251 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,251 - ERROR - Failed to process question 30 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,252 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:26,489 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,489 - ERROR - Failed to process question 32 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,491 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:26,705 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,706 - ERROR - Failed to process question 34 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,707 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:26,910 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,911 - ERROR - Failed to process question 36 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:26,912 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:27,119 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,119 - ERROR - Failed to process question 38 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,121 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:27,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,359 - ERROR - Failed to process question 40 for story Community_Time: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,359 - WARNING - No pricing found for model bedrock/us.meta.llama3-2-11b-instruct-v1-0, using default
2026-01-29 13:11:27,362 - INFO - ✓ Saved: Community_Time.json
2026-01-29 13:11:27,365 - INFO - Processing story: Fleabags
2026-01-29 13:11:27,367 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:27,612 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,612 - ERROR - Failed to process question 2 for story Fleabags: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,613 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:27,841 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,841 - ERROR - Failed to process question 4 for story Fleabags: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:27,843 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:28,042 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:28,042 - ERROR - Failed to process question 6 for story Fleabags: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:28,043 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:28,255 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:28,255 - ERROR - Failed to process question 8 for story Fleabags: litellm.BadRequestError: BedrockException - {"message":"Custom model inference is no longer supported directly. Create a provisioned throughput or custom model deployment resourceand make requests using that resource instead."}
2026-01-29 13:11:28,257 - INFO - 
LiteLLM completion() model= us.meta.llama3-2-11b-instruct-v1-0; provider = bedrock
2026-01-29 13:11:28,397 - WARNING - 
Process interrupted by user
2026-01-29 13:17:41,385 - INFO - ============================================================
2026-01-29 13:17:41,385 - INFO - CONNECT Project - Phase 1
2026-01-29 13:17:41,386 - INFO - Problem: inverse
2026-01-29 13:17:41,386 - INFO - ============================================================
2026-01-29 13:17:41,386 - INFO - 
============================================================
2026-01-29 13:17:41,386 - INFO - PHASE 1: TRAINING
2026-01-29 13:17:41,386 - INFO - ============================================================
2026-01-29 13:17:41,386 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 13:17:41,388 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 13:17:41,411 - INFO - Successfully loaded 28 stories
2026-01-29 13:17:41,412 - INFO - Loaded 28 training stories
2026-01-29 13:17:41,415 - INFO - Survey results will be saved to: output/phase1/arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 13:17:41,419 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 13:17:41,421 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,421 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,422 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,423 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,425 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 13:17:41,427 - INFO - Processing story: About_a_Hum
2026-01-29 13:17:41,429 - ERROR - Failed to process question 2 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 4 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 6 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 8 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 10 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 12 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 14 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 16 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 18 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 20 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,429 - ERROR - Failed to process question 22 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 24 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 26 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 28 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 30 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 32 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 34 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 36 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 38 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - ERROR - Failed to process question 40 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,430 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,432 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 13:17:41,436 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 13:17:41,438 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,438 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,438 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,438 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,438 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,439 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,440 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,442 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 13:17:41,445 - INFO - Processing story: Back_To_The_Wall
2026-01-29 13:17:41,446 - ERROR - Failed to process question 2 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,446 - ERROR - Failed to process question 4 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 6 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 8 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 10 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 12 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 14 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 16 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 18 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,447 - ERROR - Failed to process question 20 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 22 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 24 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 26 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 28 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 30 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 32 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 34 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,448 - ERROR - Failed to process question 36 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,449 - ERROR - Failed to process question 38 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,449 - ERROR - Failed to process question 40 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,449 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,452 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 13:17:41,455 - INFO - Processing story: Community_Time
2026-01-29 13:17:41,456 - ERROR - Failed to process question 2 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,456 - ERROR - Failed to process question 4 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 6 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 8 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 10 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 12 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 14 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,457 - ERROR - Failed to process question 16 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 18 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 20 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 22 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 24 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 26 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 28 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,458 - ERROR - Failed to process question 30 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - ERROR - Failed to process question 32 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - ERROR - Failed to process question 34 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - ERROR - Failed to process question 36 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - ERROR - Failed to process question 38 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - ERROR - Failed to process question 40 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,459 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,461 - INFO - ✓ Saved: Community_Time.json
2026-01-29 13:17:41,464 - INFO - Processing story: Fleabags
2026-01-29 13:17:41,465 - ERROR - Failed to process question 2 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 4 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 6 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 8 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 10 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 12 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 14 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 16 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 18 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,466 - ERROR - Failed to process question 20 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 22 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 24 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 26 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 28 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 30 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 32 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,467 - ERROR - Failed to process question 34 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,468 - ERROR - Failed to process question 36 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,468 - ERROR - Failed to process question 38 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,468 - ERROR - Failed to process question 40 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,468 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,470 - INFO - ✓ Saved: Fleabags.json
2026-01-29 13:17:41,473 - INFO - Processing story: Gravity_Reduced
2026-01-29 13:17:41,475 - ERROR - Failed to process question 2 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 4 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 6 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 8 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 10 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 12 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 14 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,475 - ERROR - Failed to process question 16 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,476 - ERROR - Failed to process question 18 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,476 - ERROR - Failed to process question 20 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,476 - ERROR - Failed to process question 22 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,476 - ERROR - Failed to process question 24 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,476 - ERROR - Failed to process question 26 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 28 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 30 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 32 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 34 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 36 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 38 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - ERROR - Failed to process question 40 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,477 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,479 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-29 13:17:41,482 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 13:17:41,484 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,484 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,484 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,484 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,484 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,484 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,485 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,486 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,488 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-01-29 13:17:41,490 - INFO - Processing story: Honeybee
2026-01-29 13:17:41,492 - ERROR - Failed to process question 2 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,492 - ERROR - Failed to process question 4 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 6 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 8 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 10 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 12 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 14 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 16 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,493 - ERROR - Failed to process question 18 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,494 - ERROR - Failed to process question 20 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,494 - ERROR - Failed to process question 22 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,494 - ERROR - Failed to process question 24 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,494 - ERROR - Failed to process question 26 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,494 - ERROR - Failed to process question 28 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 30 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 32 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 34 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 36 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 38 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - ERROR - Failed to process question 40 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,495 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,497 - INFO - ✓ Saved: Honeybee.json
2026-01-29 13:17:41,501 - INFO - Processing story: Last_Long_Night
2026-01-29 13:17:41,503 - ERROR - Failed to process question 2 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,503 - ERROR - Failed to process question 4 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,503 - ERROR - Failed to process question 6 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,503 - ERROR - Failed to process question 8 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,503 - ERROR - Failed to process question 10 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,504 - ERROR - Failed to process question 12 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,504 - ERROR - Failed to process question 14 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,504 - ERROR - Failed to process question 16 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,504 - ERROR - Failed to process question 18 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 20 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 22 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 24 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 26 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 28 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,505 - ERROR - Failed to process question 30 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - ERROR - Failed to process question 32 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - ERROR - Failed to process question 34 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - ERROR - Failed to process question 36 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - ERROR - Failed to process question 38 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - ERROR - Failed to process question 40 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,506 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,508 - INFO - ✓ Saved: Last_Long_Night.json
2026-01-29 13:17:41,511 - INFO - Processing story: Raindrop_Snowflake
2026-01-29 13:17:41,513 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,513 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,513 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,513 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,514 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,515 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,518 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-01-29 13:17:41,520 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-01-29 13:17:41,522 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,522 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,522 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,523 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,524 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,526 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-01-29 13:17:41,529 - INFO - Processing story: Rice
2026-01-29 13:17:41,531 - ERROR - Failed to process question 2 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,531 - ERROR - Failed to process question 4 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,531 - ERROR - Failed to process question 6 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,531 - ERROR - Failed to process question 8 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,531 - ERROR - Failed to process question 10 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 12 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 14 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 16 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 18 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 20 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 22 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 24 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 26 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 28 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 30 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 32 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 34 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 36 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 38 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,532 - ERROR - Failed to process question 40 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,533 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,535 - INFO - ✓ Saved: Rice.json
2026-01-29 13:17:41,537 - INFO - Processing story: Swallowed
2026-01-29 13:17:41,539 - ERROR - Failed to process question 2 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,539 - ERROR - Failed to process question 4 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 6 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 8 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 10 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 12 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 14 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 16 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,540 - ERROR - Failed to process question 18 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 20 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 22 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 24 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 26 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 28 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 30 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 32 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,541 - ERROR - Failed to process question 34 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,542 - ERROR - Failed to process question 36 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,542 - ERROR - Failed to process question 38 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,542 - ERROR - Failed to process question 40 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,542 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,543 - INFO - ✓ Saved: Swallowed.json
2026-01-29 13:17:41,546 - INFO - Processing story: The_Ants_and_The_Locusts
2026-01-29 13:17:41,548 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,548 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,549 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,550 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,552 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-01-29 13:17:41,555 - INFO - Processing story: The_Christmas_Monks
2026-01-29 13:17:41,557 - ERROR - Failed to process question 2 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,557 - ERROR - Failed to process question 4 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,557 - ERROR - Failed to process question 6 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 8 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 10 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 12 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 14 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 16 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 18 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 20 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,558 - ERROR - Failed to process question 22 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 24 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 26 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 28 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 30 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 32 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 34 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 36 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,559 - ERROR - Failed to process question 38 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,560 - ERROR - Failed to process question 40 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,560 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,561 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-01-29 13:17:41,564 - INFO - Processing story: The_Circuit
2026-01-29 13:17:41,566 - ERROR - Failed to process question 2 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,566 - ERROR - Failed to process question 4 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 6 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 8 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 10 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 12 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 14 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 16 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 18 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 20 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,567 - ERROR - Failed to process question 22 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,568 - ERROR - Failed to process question 24 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,568 - ERROR - Failed to process question 26 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,568 - ERROR - Failed to process question 28 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,568 - ERROR - Failed to process question 30 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - ERROR - Failed to process question 32 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - ERROR - Failed to process question 34 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - ERROR - Failed to process question 36 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - ERROR - Failed to process question 38 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - ERROR - Failed to process question 40 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,569 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,572 - INFO - ✓ Saved: The_Circuit.json
2026-01-29 13:17:41,576 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-01-29 13:17:41,578 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,578 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,578 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,579 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,580 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,583 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-01-29 13:17:41,587 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-01-29 13:17:41,588 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,588 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,588 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,589 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,590 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,591 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,591 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,591 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,591 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,593 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-01-29 13:17:41,597 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-01-29 13:17:41,598 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,598 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,599 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,600 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,601 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,603 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-01-29 13:17:41,606 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-01-29 13:17:41,607 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,607 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,608 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,609 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,610 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,610 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,610 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,610 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,612 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-01-29 13:17:41,616 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-01-29 13:17:41,617 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,617 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,618 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,618 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,618 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,618 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,619 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,619 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,619 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,619 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,619 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,620 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,620 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,620 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,620 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,620 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,621 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,621 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,621 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,621 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,621 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,623 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-01-29 13:17:41,626 - INFO - Processing story: The_Stretcher
2026-01-29 13:17:41,627 - ERROR - Failed to process question 2 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 4 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 6 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 8 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 10 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 12 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 14 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 16 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,628 - ERROR - Failed to process question 18 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 20 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 22 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 24 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 26 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 28 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 30 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 32 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 34 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,629 - ERROR - Failed to process question 36 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,630 - ERROR - Failed to process question 38 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,630 - ERROR - Failed to process question 40 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,630 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,632 - INFO - ✓ Saved: The_Stretcher.json
2026-01-29 13:17:41,635 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-01-29 13:17:41,636 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,636 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,636 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,636 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,636 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,637 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,638 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,640 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-01-29 13:17:41,643 - INFO - Processing story: War_of_the_Wall
2026-01-29 13:17:41,645 - ERROR - Failed to process question 2 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 4 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 6 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 8 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 10 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 12 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 14 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 16 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,645 - ERROR - Failed to process question 18 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 20 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 22 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 24 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 26 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 28 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 30 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 32 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 34 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,646 - ERROR - Failed to process question 36 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,647 - ERROR - Failed to process question 38 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,647 - ERROR - Failed to process question 40 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,647 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,649 - INFO - ✓ Saved: War_of_the_Wall.json
2026-01-29 13:17:41,651 - INFO - Processing story: Warrior_Women_Nicaragua
2026-01-29 13:17:41,653 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,653 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,654 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,655 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,657 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-01-29 13:17:41,660 - INFO - Processing story: We_Stand_Up
2026-01-29 13:17:41,662 - ERROR - Failed to process question 2 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,662 - ERROR - Failed to process question 4 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,662 - ERROR - Failed to process question 6 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 8 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 10 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 12 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 14 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 16 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 18 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 20 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,663 - ERROR - Failed to process question 22 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 24 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 26 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 28 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 30 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 32 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 34 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 36 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 38 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - ERROR - Failed to process question 40 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,664 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:41,666 - INFO - ✓ Saved: We_Stand_Up.json
2026-01-29 13:17:41,669 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-01-29 13:17:41,670 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,671 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,672 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:41,672 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,245 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,245 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,245 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-01-29 13:17:42,246 - WARNING - No pricing found for model arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:17:42,248 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-01-29 13:17:42,255 - INFO - 
============================================================
2026-01-29 13:17:42,255 - INFO - Survey complete!
2026-01-29 13:17:42,255 - INFO - Processed: 28/28 stories
2026-01-29 13:17:42,255 - INFO - Failed: 0 stories
2026-01-29 13:17:42,255 - INFO - Total cost: $0.0000
2026-01-29 13:17:42,255 - INFO - Total tokens: 0
2026-01-29 13:17:42,255 - INFO - ============================================================

2026-01-29 13:17:42,255 - INFO - 
============================================================
2026-01-29 13:17:42,255 - INFO - Step 4: Learning PyReason Rules
2026-01-29 13:17:42,256 - INFO - ============================================================
2026-01-29 13:17:42,256 - INFO - ============================================================
2026-01-29 13:17:42,256 - INFO - RULE LEARNING
2026-01-29 13:17:42,256 - INFO - ============================================================
2026-01-29 13:17:42,256 - INFO - Loading survey results from: output/phase1/arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 13:17:42,258 - INFO - Found 28 survey result files
2026-01-29 13:17:42,282 - INFO - Successfully loaded 28 survey results
2026-01-29 13:17:42,282 - INFO - Extracting feature scores...
2026-01-29 13:17:42,282 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,283 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-01-29 13:17:42,284 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-01-29 13:17:42,285 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-01-29 13:17:42,286 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,287 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,288 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,289 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-01-29 13:17:42,290 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-01-29 13:17:42,291 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-01-29 13:17:42,292 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-01-29 13:17:42,293 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-01-29 13:17:42,294 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,295 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,296 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,296 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,296 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,296 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,297 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-01-29 13:17:42,298 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-01-29 13:17:42,299 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-01-29 13:17:42,300 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-01-29 13:17:42,301 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,302 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,303 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,304 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,305 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-01-29 13:17:42,306 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-01-29 13:17:42,307 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-01-29 13:17:42,308 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-01-29 13:17:42,309 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,310 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-01-29 13:17:42,311 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,312 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-01-29 13:17:42,313 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-01-29 13:17:42,314 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,315 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,316 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,317 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,318 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,319 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,320 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,321 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,322 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-01-29 13:17:42,323 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-01-29 13:17:42,324 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-01-29 13:17:42,325 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,326 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-01-29 13:17:42,327 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-01-29 13:17:42,328 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-01-29 13:17:42,329 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,330 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,331 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-01-29 13:17:42,332 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-01-29 13:17:42,333 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,334 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,335 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,336 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,336 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,336 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-01-29 13:17:42,336 - INFO - Extracted scores for 28 stories and 0 features
2026-01-29 13:17:42,336 - INFO - Learning PyReason rules...
2026-01-29 13:17:42,336 - INFO - Configuration:
2026-01-29 13:17:42,336 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-01-29 13:17:42,336 - INFO -   - Min confidence: 0.0
2026-01-29 13:17:42,336 - INFO -   - Min support: 0
2026-01-29 13:17:42,336 - INFO - Learning rules for 0 features...
2026-01-29 13:17:42,336 - INFO - Learned 0 rules
2026-01-29 13:17:42,338 - INFO - Saved 0 rules to output/phase1/arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:17:42,338 - INFO - ============================================================
2026-01-29 13:17:42,339 - INFO - RULE LEARNING COMPLETE
2026-01-29 13:17:42,339 - INFO - ============================================================
2026-01-29 13:17:42,339 - INFO - Stories processed: 28
2026-01-29 13:17:42,339 - INFO - Features: 0
2026-01-29 13:17:42,339 - INFO - Rules learned: 0
2026-01-29 13:17:42,339 - INFO - Rules saved to: output/phase1/arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:17:42,339 - INFO - ============================================================
2026-01-29 13:17:42,339 - INFO - 
✓ Rules learned and saved to: output/phase1/arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/learned_rules/pyreason_rules.txt
2026-01-29 13:17:42,340 - INFO - 
Phase 1 completed successfully!
2026-01-29 13:17:42,340 - INFO - Output directory: output/phase1
2026-01-29 13:17:42,340 - INFO - ============================================================
2026-01-29 13:17:42,340 - INFO - Execution completed successfully!
2026-01-29 13:17:42,340 - INFO - ============================================================
2026-01-29 13:35:25,067 - INFO - ============================================================
2026-01-29 13:35:25,068 - INFO - CONNECT Project - Phase 1
2026-01-29 13:35:25,068 - INFO - Problem: inverse
2026-01-29 13:35:25,068 - INFO - ============================================================
2026-01-29 13:35:25,068 - INFO - 
============================================================
2026-01-29 13:35:25,068 - INFO - PHASE 1: TRAINING
2026-01-29 13:35:25,068 - INFO - ============================================================
2026-01-29 13:35:25,068 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 13:35:25,070 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 13:35:25,090 - INFO - Successfully loaded 28 stories
2026-01-29 13:35:25,090 - INFO - Loaded 28 training stories
2026-01-29 13:35:25,092 - INFO - Survey results will be saved to: output/phase1/bedrock-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 13:35:25,097 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 13:35:25,120 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:25,953 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:25,953 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:25,957 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,044 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,044 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,045 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,133 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,133 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,135 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,223 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,223 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,224 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,313 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,313 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,314 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,403 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,403 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,405 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,495 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,495 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,496 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,584 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,584 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,585 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,673 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,673 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,675 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,763 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,763 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,764 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,852 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,852 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,854 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:26,944 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,944 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:26,945 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,033 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,033 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,034 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,122 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,123 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,124 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,213 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,214 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,215 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,303 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,303 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,304 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,393 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,394 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,395 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,482 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,482 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,483 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,571 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,571 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,572 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,659 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,659 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,659 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:27,662 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 13:35:27,664 - INFO - Processing story: About_a_Hum
2026-01-29 13:35:27,667 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,774 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,774 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,775 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,864 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,865 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,866 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:27,960 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,960 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:27,961 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,055 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,055 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,056 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,163 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,164 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,165 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,260 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,260 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,261 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,352 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,352 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,353 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,442 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,442 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,443 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,533 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,533 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,535 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,623 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,623 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,624 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,710 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,711 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,712 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,801 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,801 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,802 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,890 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,890 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,891 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:28,978 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,978 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:28,980 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,068 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,068 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,069 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,158 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,158 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,160 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,250 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,250 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,251 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,339 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,339 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,340 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,429 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,429 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,430 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,518 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,518 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,519 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:29,521 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 13:35:29,524 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 13:35:29,526 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,614 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,615 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,705 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,705 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,706 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,794 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,795 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,796 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,884 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,884 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,886 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:29,974 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,975 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:29,976 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,065 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,065 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,066 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,158 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,158 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,159 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,248 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,248 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,249 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,338 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,338 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,340 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,433 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,433 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,434 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,521 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,522 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,523 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,612 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,612 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,613 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,706 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,706 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,707 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,796 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,796 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,797 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,885 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,885 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,886 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:30,973 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,974 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:30,975 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,064 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,064 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,065 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,156 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,156 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,157 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,246 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,246 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,247 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,334 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,334 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,334 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:31,337 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 13:35:31,339 - INFO - Processing story: Back_To_The_Wall
2026-01-29 13:35:31,342 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,430 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,430 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,431 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,519 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,520 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,521 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,611 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,611 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,612 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,700 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,700 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,701 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,788 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,789 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,790 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,877 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,877 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,878 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:31,965 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,966 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:31,967 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,057 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,057 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,058 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,145 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,146 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,147 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,235 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,235 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,236 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,323 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,323 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,324 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,412 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,412 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,413 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,504 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,504 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,506 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,593 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,594 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,595 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,682 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,682 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,683 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,772 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,772 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,773 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,861 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,861 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,862 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:32,952 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,953 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:32,954 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,042 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,042 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,043 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,130 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,130 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,130 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:33,133 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 13:35:33,136 - INFO - Processing story: Community_Time
2026-01-29 13:35:33,138 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,225 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,226 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,227 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,314 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,314 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,315 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,405 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,405 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,406 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,495 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,495 - ERROR - Failed to process question 8 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,496 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,583 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,583 - ERROR - Failed to process question 10 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,584 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,672 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,672 - ERROR - Failed to process question 12 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,673 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,760 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,761 - ERROR - Failed to process question 14 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,762 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,851 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,851 - ERROR - Failed to process question 16 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,852 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:33,939 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,939 - ERROR - Failed to process question 18 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:33,940 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,027 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,027 - ERROR - Failed to process question 20 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,028 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,116 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,116 - ERROR - Failed to process question 22 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,117 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,204 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,204 - ERROR - Failed to process question 24 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,205 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,296 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,296 - ERROR - Failed to process question 26 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,297 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,385 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,385 - ERROR - Failed to process question 28 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,387 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,475 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,475 - ERROR - Failed to process question 30 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,476 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,564 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,564 - ERROR - Failed to process question 32 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,565 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,654 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,654 - ERROR - Failed to process question 34 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,655 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,745 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,745 - ERROR - Failed to process question 36 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,746 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,837 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,837 - ERROR - Failed to process question 38 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,838 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:34,927 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,927 - ERROR - Failed to process question 40 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:34,927 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:34,930 - INFO - ✓ Saved: Community_Time.json
2026-01-29 13:35:35,107 - INFO - Processing story: Fleabags
2026-01-29 13:35:35,110 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,197 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,197 - ERROR - Failed to process question 2 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,199 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,286 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,286 - ERROR - Failed to process question 4 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,287 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,374 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,374 - ERROR - Failed to process question 6 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,375 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,466 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,466 - ERROR - Failed to process question 8 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,468 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,556 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,556 - ERROR - Failed to process question 10 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,557 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,645 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,645 - ERROR - Failed to process question 12 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,646 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,734 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,734 - ERROR - Failed to process question 14 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,735 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,823 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,823 - ERROR - Failed to process question 16 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,824 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:35,916 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,916 - ERROR - Failed to process question 18 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:35,917 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,005 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,005 - ERROR - Failed to process question 20 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,006 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,094 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,094 - ERROR - Failed to process question 22 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,095 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,182 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,182 - ERROR - Failed to process question 24 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,183 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,270 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,271 - ERROR - Failed to process question 26 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,272 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,361 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,361 - ERROR - Failed to process question 28 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,362 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,450 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,450 - ERROR - Failed to process question 30 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,452 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,541 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,541 - ERROR - Failed to process question 32 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,542 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,630 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,630 - ERROR - Failed to process question 34 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,631 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,719 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,719 - ERROR - Failed to process question 36 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,721 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,811 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,811 - ERROR - Failed to process question 38 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,813 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,901 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,902 - ERROR - Failed to process question 40 for story Fleabags: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,902 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:36,905 - INFO - ✓ Saved: Fleabags.json
2026-01-29 13:35:36,907 - INFO - Processing story: Gravity_Reduced
2026-01-29 13:35:36,910 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:36,998 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,998 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:36,999 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,087 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,087 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,088 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,175 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,176 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,177 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,266 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,267 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,268 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,356 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,357 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,358 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,445 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,445 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,446 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,535 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,535 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,536 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,624 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,624 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,625 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,715 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,716 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,717 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,807 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,807 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,808 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,896 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,896 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,897 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:37,986 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,986 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:37,987 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,075 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,075 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,076 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,167 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,167 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,168 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,256 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,256 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,257 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,346 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,346 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,347 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,435 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,435 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,436 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,525 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,525 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,526 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,616 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,616 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,617 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:38,993 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,993 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:38,993 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 13:35:38,996 - INFO - ✓ Saved: Gravity_Reduced.json
2026-01-29 13:35:38,998 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-01-29 13:35:39,001 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,089 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,090 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,091 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,179 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,179 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,180 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,268 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,269 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,270 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,358 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,359 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,451 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,451 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,452 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,540 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,540 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,541 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,629 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,630 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,631 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,718 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,718 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,719 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,807 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,808 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 13:35:39,809 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 13:35:39,823 - WARNING - 
Process interrupted by user
2026-01-29 15:14:01,428 - INFO - ============================================================
2026-01-29 15:14:01,429 - INFO - CONNECT Project - Phase 1
2026-01-29 15:14:01,429 - INFO - Problem: inverse
2026-01-29 15:14:01,429 - INFO - ============================================================
2026-01-29 15:14:01,429 - INFO - 
============================================================
2026-01-29 15:14:01,430 - INFO - PHASE 1: TRAINING
2026-01-29 15:14:01,430 - INFO - ============================================================
2026-01-29 15:14:01,430 - INFO - Loading collectivistic stories for inverse problem
2026-01-29 15:14:01,431 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-01-29 15:14:01,452 - INFO - Successfully loaded 28 stories
2026-01-29 15:14:01,453 - INFO - Loaded 28 training stories
2026-01-29 15:14:01,455 - INFO - Survey results will be saved to: output/phase1/bedrock-arn-aws-bedrock-us-west-2-626747814346-custom-model-meta.llama3-2-11b-instruct-v1-0-128k-7trp8r8guozt/inverse/survey_results
2026-01-29 15:14:01,460 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-01-29 15:14:01,485 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,279 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,279 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,280 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,371 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,371 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,372 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,461 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,461 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,462 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,551 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,551 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,552 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,644 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,644 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,645 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,734 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,734 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,735 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,826 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,826 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,827 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:02,916 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,916 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:02,917 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,005 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,006 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,007 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,095 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,095 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,096 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,185 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,185 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,186 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,276 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,276 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,278 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,365 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,366 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,367 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,454 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,455 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,456 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,545 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,546 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,547 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,635 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,635 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,637 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,728 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,728 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,729 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,818 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,818 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,819 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:03,916 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,916 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:03,918 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,006 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,006 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,006 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 15:14:04,009 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-01-29 15:14:04,011 - INFO - Processing story: About_a_Hum
2026-01-29 15:14:04,014 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,102 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,103 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,104 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,194 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,195 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,196 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,285 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,285 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,286 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,375 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,375 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,376 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,464 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,464 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,465 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,559 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,559 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,560 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,651 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,651 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,652 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,742 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,742 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,743 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,831 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,832 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,833 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:04,922 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,922 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:04,924 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,014 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,014 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,015 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,105 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,106 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,107 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,196 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,197 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,198 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,287 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,287 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,288 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,377 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,377 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,379 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,468 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,468 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,469 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,560 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,560 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,561 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,650 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,650 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,651 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,740 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,740 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,742 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:05,832 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,832 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:05,832 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 15:14:05,835 - INFO - ✓ Saved: About_a_Hum.json
2026-01-29 15:14:05,953 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-01-29 15:14:05,956 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,047 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,048 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,049 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,140 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,140 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,141 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,230 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,231 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,232 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,322 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,322 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,323 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,412 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,412 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,413 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,503 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,503 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,504 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,597 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,597 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,598 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,687 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,688 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,689 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,779 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,779 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,781 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,880 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,880 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,881 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:06,972 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,972 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:06,974 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,063 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,063 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,065 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,157 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,157 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,159 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,249 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,249 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,250 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,340 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,341 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,342 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,431 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,431 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,432 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,521 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,521 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,522 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,612 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,612 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,613 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,702 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,702 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,704 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,791 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,791 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,792 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 15:14:07,794 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-01-29 15:14:07,797 - INFO - Processing story: Back_To_The_Wall
2026-01-29 15:14:07,800 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,888 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,889 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,890 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:07,978 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,978 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:07,979 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,069 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,069 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,071 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,161 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,161 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,162 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,251 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,251 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,253 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,342 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,343 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,344 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,434 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,434 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,435 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,525 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,525 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,527 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,614 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,616 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,704 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,704 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,705 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,793 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,794 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,795 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,882 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,883 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,884 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:08,975 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,975 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:08,977 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,066 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,066 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,067 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,155 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,156 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,157 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,245 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,245 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,246 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,334 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,334 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,336 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,426 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,426 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,427 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,516 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,517 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,518 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,606 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,607 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,607 - WARNING - No pricing found for model bedrock/arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt, using default
2026-01-29 15:14:09,609 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-01-29 15:14:09,612 - INFO - Processing story: Community_Time
2026-01-29 15:14:09,615 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,704 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,704 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,705 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,793 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,793 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,794 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,885 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,886 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: BedrockException - Error processing={"Output":{"__type":"com.amazon.coral.service#UnknownOperationException"},"Version":"1.0"}, Received error='generation'
2026-01-29 15:14:09,887 - INFO - 
LiteLLM completion() model= arn:aws:bedrock:us-west-2:626747814346:custom-model/meta.llama3-2-11b-instruct-v1:0:128k/7trp8r8guozt; provider = bedrock
2026-01-29 15:14:09,959 - WARNING - 
Process interrupted by user
2026-02-02 20:33:43,854 - INFO - ============================================================
2026-02-02 20:33:43,854 - INFO - CONNECT Project - Phase 1
2026-02-02 20:33:43,854 - INFO - Problem: inverse
2026-02-02 20:33:43,856 - INFO - ============================================================
2026-02-02 20:33:43,856 - INFO - 
============================================================
2026-02-02 20:33:43,856 - INFO - PHASE 1: TRAINING
2026-02-02 20:33:43,856 - INFO - ============================================================
2026-02-02 20:33:43,856 - INFO - Loading collectivistic stories for inverse problem
2026-02-02 20:33:43,856 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-02-02 20:33:43,943 - INFO - Successfully loaded 28 stories
2026-02-02 20:33:43,944 - INFO - Loaded 28 training stories
2026-02-02 20:33:43,947 - INFO - Survey results will be saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:33:43,961 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-02-02 20:33:43,965 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,965 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,965 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,965 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,966 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,967 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,968 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:43,970 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-02-02 20:33:43,972 - INFO - Processing story: About_a_Hum
2026-02-02 20:33:43,973 - ERROR - Failed to process question 2 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,973 - ERROR - Failed to process question 4 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 6 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 8 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 10 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 12 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 14 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 16 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 18 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 20 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 22 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 24 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 26 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,974 - ERROR - Failed to process question 28 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,975 - ERROR - Failed to process question 30 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,975 - ERROR - Failed to process question 32 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,975 - ERROR - Failed to process question 34 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,975 - ERROR - Failed to process question 36 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,975 - ERROR - Failed to process question 38 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,976 - ERROR - Failed to process question 40 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,976 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:43,977 - INFO - ✓ Saved: About_a_Hum.json
2026-02-02 20:33:43,980 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-02-02 20:33:43,981 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,981 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,982 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,983 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,984 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,984 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:43,986 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-02-02 20:33:43,988 - INFO - Processing story: Back_To_The_Wall
2026-02-02 20:33:43,989 - ERROR - Failed to process question 2 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,989 - ERROR - Failed to process question 4 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 6 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 8 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 10 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 12 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 14 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 16 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 18 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 20 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,990 - ERROR - Failed to process question 22 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 24 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 26 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 28 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 30 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 32 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 34 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 36 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,991 - ERROR - Failed to process question 38 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,992 - ERROR - Failed to process question 40 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,992 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:43,994 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-02-02 20:33:43,996 - INFO - Processing story: Community_Time
2026-02-02 20:33:43,997 - ERROR - Failed to process question 2 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,997 - ERROR - Failed to process question 4 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 6 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 8 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 10 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 12 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 14 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 16 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 18 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 20 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 22 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,998 - ERROR - Failed to process question 24 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 26 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 28 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 30 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 32 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 34 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 36 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 38 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - ERROR - Failed to process question 40 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:43,999 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,002 - INFO - ✓ Saved: Community_Time.json
2026-02-02 20:33:44,004 - INFO - Processing story: Fleabags
2026-02-02 20:33:44,005 - ERROR - Failed to process question 2 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,005 - ERROR - Failed to process question 4 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,005 - ERROR - Failed to process question 6 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,005 - ERROR - Failed to process question 8 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,005 - ERROR - Failed to process question 10 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,005 - ERROR - Failed to process question 12 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 14 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 16 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 18 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 20 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 22 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 24 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 26 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 28 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 30 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 32 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 34 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 36 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 38 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - ERROR - Failed to process question 40 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,006 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,008 - INFO - ✓ Saved: Fleabags.json
2026-02-02 20:33:44,010 - INFO - Processing story: Gravity_Reduced
2026-02-02 20:33:44,012 - ERROR - Failed to process question 2 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 4 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 6 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 8 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 10 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 12 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 14 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,012 - ERROR - Failed to process question 16 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 18 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 20 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 22 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 24 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 26 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 28 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 30 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 32 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,013 - ERROR - Failed to process question 34 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,014 - ERROR - Failed to process question 36 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,014 - ERROR - Failed to process question 38 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,014 - ERROR - Failed to process question 40 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,014 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,016 - INFO - ✓ Saved: Gravity_Reduced.json
2026-02-02 20:33:44,018 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-02-02 20:33:44,019 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,019 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,020 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,021 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,022 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,022 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,023 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-02-02 20:33:44,025 - INFO - Processing story: Honeybee
2026-02-02 20:33:44,027 - ERROR - Failed to process question 2 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 4 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 6 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 8 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 10 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 12 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,027 - ERROR - Failed to process question 14 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 16 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 18 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 20 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 22 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 24 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,028 - ERROR - Failed to process question 26 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 28 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 30 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 32 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 34 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 36 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 38 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - ERROR - Failed to process question 40 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,029 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,031 - INFO - ✓ Saved: Honeybee.json
2026-02-02 20:33:44,033 - INFO - Processing story: Last_Long_Night
2026-02-02 20:33:44,035 - ERROR - Failed to process question 2 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 4 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 6 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 8 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 10 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 12 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 14 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,035 - ERROR - Failed to process question 16 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 18 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 20 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 22 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 24 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 26 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 28 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,036 - ERROR - Failed to process question 30 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - ERROR - Failed to process question 32 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - ERROR - Failed to process question 34 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - ERROR - Failed to process question 36 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - ERROR - Failed to process question 38 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - ERROR - Failed to process question 40 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,037 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,039 - INFO - ✓ Saved: Last_Long_Night.json
2026-02-02 20:33:44,041 - INFO - Processing story: Raindrop_Snowflake
2026-02-02 20:33:44,043 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,043 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,043 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,043 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,043 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,043 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,044 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,045 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,047 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-02-02 20:33:44,049 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-02-02 20:33:44,051 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,051 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,051 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,051 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,051 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,052 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,053 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,055 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-02-02 20:33:44,057 - INFO - Processing story: Rice
2026-02-02 20:33:44,059 - ERROR - Failed to process question 2 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 4 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 6 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 8 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 10 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 12 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,059 - ERROR - Failed to process question 14 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,060 - ERROR - Failed to process question 16 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,060 - ERROR - Failed to process question 18 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,060 - ERROR - Failed to process question 20 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,060 - ERROR - Failed to process question 22 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,060 - ERROR - Failed to process question 24 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 26 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 28 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 30 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 32 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 34 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 36 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 38 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,061 - ERROR - Failed to process question 40 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,062 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,063 - INFO - ✓ Saved: Rice.json
2026-02-02 20:33:44,066 - INFO - Processing story: Swallowed
2026-02-02 20:33:44,067 - ERROR - Failed to process question 2 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,067 - ERROR - Failed to process question 4 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,068 - ERROR - Failed to process question 6 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,068 - ERROR - Failed to process question 8 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,068 - ERROR - Failed to process question 10 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,068 - ERROR - Failed to process question 12 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,068 - ERROR - Failed to process question 14 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 16 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 18 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 20 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 22 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 24 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 26 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 28 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 30 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 32 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 34 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 36 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,069 - ERROR - Failed to process question 38 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,070 - ERROR - Failed to process question 40 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,070 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,072 - INFO - ✓ Saved: Swallowed.json
2026-02-02 20:33:44,074 - INFO - Processing story: The_Ants_and_The_Locusts
2026-02-02 20:33:44,075 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,075 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,076 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,077 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,078 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,078 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,078 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,080 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-02-02 20:33:44,082 - INFO - Processing story: The_Christmas_Monks
2026-02-02 20:33:44,083 - ERROR - Failed to process question 2 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,083 - ERROR - Failed to process question 4 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,084 - ERROR - Failed to process question 6 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,084 - ERROR - Failed to process question 8 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,084 - ERROR - Failed to process question 10 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,084 - ERROR - Failed to process question 12 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,084 - ERROR - Failed to process question 14 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 16 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 18 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 20 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 22 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 24 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 26 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 28 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 30 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 32 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 34 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,085 - ERROR - Failed to process question 36 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,086 - ERROR - Failed to process question 38 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,086 - ERROR - Failed to process question 40 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,086 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,088 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-02-02 20:33:44,090 - INFO - Processing story: The_Circuit
2026-02-02 20:33:44,091 - ERROR - Failed to process question 2 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,091 - ERROR - Failed to process question 4 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 6 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 8 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 10 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 12 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 14 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 16 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 18 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 20 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 22 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 24 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 26 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 28 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 30 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 32 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,092 - ERROR - Failed to process question 34 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,093 - ERROR - Failed to process question 36 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,093 - ERROR - Failed to process question 38 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,093 - ERROR - Failed to process question 40 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,093 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,095 - INFO - ✓ Saved: The_Circuit.json
2026-02-02 20:33:44,097 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-02-02 20:33:44,099 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,099 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,099 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,100 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,101 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,102 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,102 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,104 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-02-02 20:33:44,106 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-02-02 20:33:44,108 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,108 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,109 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,111 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-02-02 20:33:44,114 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-02-02 20:33:44,115 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,115 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,115 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,116 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,117 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,118 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,119 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-02-02 20:33:44,122 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-02-02 20:33:44,123 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,123 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,124 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,125 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,127 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-02-02 20:33:44,129 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-02-02 20:33:44,130 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,130 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,131 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,132 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,133 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,133 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,133 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,133 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,135 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-02-02 20:33:44,137 - INFO - Processing story: The_Stretcher
2026-02-02 20:33:44,138 - ERROR - Failed to process question 2 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 4 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 6 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 8 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 10 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 12 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,139 - ERROR - Failed to process question 14 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 16 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 18 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 20 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 22 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 24 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 26 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 28 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 30 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,140 - ERROR - Failed to process question 32 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,141 - ERROR - Failed to process question 34 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,141 - ERROR - Failed to process question 36 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,141 - ERROR - Failed to process question 38 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,141 - ERROR - Failed to process question 40 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,141 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,143 - INFO - ✓ Saved: The_Stretcher.json
2026-02-02 20:33:44,145 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-02-02 20:33:44,146 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,147 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,148 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,149 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,149 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,149 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,149 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,149 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,151 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-02-02 20:33:44,153 - INFO - Processing story: War_of_the_Wall
2026-02-02 20:33:44,154 - ERROR - Failed to process question 2 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 4 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 6 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 8 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 10 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 12 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,155 - ERROR - Failed to process question 14 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 16 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 18 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 20 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 22 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 24 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 26 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 28 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 30 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,156 - ERROR - Failed to process question 32 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,157 - ERROR - Failed to process question 34 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,157 - ERROR - Failed to process question 36 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,157 - ERROR - Failed to process question 38 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,157 - ERROR - Failed to process question 40 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,157 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,159 - INFO - ✓ Saved: War_of_the_Wall.json
2026-02-02 20:33:44,161 - INFO - Processing story: Warrior_Women_Nicaragua
2026-02-02 20:33:44,163 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,163 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,164 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,165 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,167 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-02-02 20:33:44,170 - INFO - Processing story: We_Stand_Up
2026-02-02 20:33:44,171 - ERROR - Failed to process question 2 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,171 - ERROR - Failed to process question 4 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,171 - ERROR - Failed to process question 6 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,171 - ERROR - Failed to process question 8 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 10 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 12 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 14 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 16 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 18 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 20 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 22 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 24 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,172 - ERROR - Failed to process question 26 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 28 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 30 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 32 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 34 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 36 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,173 - ERROR - Failed to process question 38 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,174 - ERROR - Failed to process question 40 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,174 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,175 - INFO - ✓ Saved: We_Stand_Up.json
2026-02-02 20:33:44,179 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-02-02 20:33:44,180 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,181 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,182 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:33:44,183 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:33:44,185 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-02-02 20:33:44,191 - INFO - 
============================================================
2026-02-02 20:33:44,191 - INFO - Survey complete!
2026-02-02 20:33:44,191 - INFO - Processed: 28/28 stories
2026-02-02 20:33:44,191 - INFO - Failed: 0 stories
2026-02-02 20:33:44,191 - INFO - Total cost: $0.0000
2026-02-02 20:33:44,191 - INFO - Total tokens: 0
2026-02-02 20:33:44,191 - INFO - ============================================================

2026-02-02 20:33:44,192 - INFO - 
============================================================
2026-02-02 20:33:44,192 - INFO - Step 4: Learning PyReason Rules
2026-02-02 20:33:44,192 - INFO - ============================================================
2026-02-02 20:33:44,192 - INFO - ============================================================
2026-02-02 20:33:44,192 - INFO - RULE LEARNING
2026-02-02 20:33:44,192 - INFO - ============================================================
2026-02-02 20:33:44,193 - INFO - Loading survey results from: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:33:44,194 - INFO - Found 28 survey result files
2026-02-02 20:33:44,217 - INFO - Successfully loaded 28 survey results
2026-02-02 20:33:44,217 - INFO - Extracting feature scores...
2026-02-02 20:33:44,217 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,217 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,217 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,217 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,218 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-02-02 20:33:44,219 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-02-02 20:33:44,220 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,221 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,222 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:33:44,223 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,223 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,223 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,223 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,223 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,224 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-02-02 20:33:44,225 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-02-02 20:33:44,226 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-02-02 20:33:44,227 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-02-02 20:33:44,228 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-02-02 20:33:44,229 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-02-02 20:33:44,230 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,231 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,232 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,233 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-02-02 20:33:44,234 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-02-02 20:33:44,235 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-02-02 20:33:44,236 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,237 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,238 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,239 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,240 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:33:44,241 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-02-02 20:33:44,242 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-02-02 20:33:44,243 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-02-02 20:33:44,244 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,245 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,246 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,247 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,248 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-02-02 20:33:44,249 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-02-02 20:33:44,250 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,251 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,252 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,253 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,254 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,255 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,256 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,257 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,258 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,259 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-02-02 20:33:44,260 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-02-02 20:33:44,261 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,262 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,263 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:33:44,264 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,265 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,266 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-02-02 20:33:44,267 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,268 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,269 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,270 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,270 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,270 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,270 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:33:44,270 - INFO - Extracted scores for 28 stories and 0 features
2026-02-02 20:33:44,270 - INFO - Learning PyReason rules...
2026-02-02 20:33:44,270 - INFO - Configuration:
2026-02-02 20:33:44,270 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-02-02 20:33:44,270 - INFO -   - Min confidence: 0.0
2026-02-02 20:33:44,270 - INFO -   - Min support: 0
2026-02-02 20:33:44,270 - INFO - Learning rules for 0 features...
2026-02-02 20:33:44,270 - INFO - Learned 0 rules
2026-02-02 20:33:44,272 - INFO - Saved 0 rules to output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:33:44,272 - INFO - ============================================================
2026-02-02 20:33:44,273 - INFO - RULE LEARNING COMPLETE
2026-02-02 20:33:44,273 - INFO - ============================================================
2026-02-02 20:33:44,273 - INFO - Stories processed: 28
2026-02-02 20:33:44,273 - INFO - Features: 0
2026-02-02 20:33:44,273 - INFO - Rules learned: 0
2026-02-02 20:33:44,273 - INFO - Rules saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:33:44,273 - INFO - ============================================================
2026-02-02 20:33:44,273 - INFO - 
✓ Rules learned and saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:33:44,274 - INFO - 
Phase 1 completed successfully!
2026-02-02 20:33:44,274 - INFO - Output directory: output/phase1
2026-02-02 20:33:44,274 - INFO - ============================================================
2026-02-02 20:33:44,274 - INFO - Execution completed successfully!
2026-02-02 20:33:44,274 - INFO - ============================================================
2026-02-02 20:34:53,845 - INFO - ============================================================
2026-02-02 20:34:53,845 - INFO - CONNECT Project - Phase 1
2026-02-02 20:34:53,845 - INFO - Problem: inverse
2026-02-02 20:34:53,845 - INFO - ============================================================
2026-02-02 20:34:53,845 - INFO - 
============================================================
2026-02-02 20:34:53,846 - INFO - PHASE 1: TRAINING
2026-02-02 20:34:53,846 - INFO - ============================================================
2026-02-02 20:34:53,846 - INFO - Loading collectivistic stories for inverse problem
2026-02-02 20:34:53,846 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-02-02 20:34:53,866 - INFO - Successfully loaded 28 stories
2026-02-02 20:34:53,866 - INFO - Loaded 28 training stories
2026-02-02 20:34:53,868 - INFO - Survey results will be saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:34:53,872 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-02-02 20:34:53,874 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,874 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,874 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,874 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,874 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,875 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,876 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,876 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,876 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,876 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,877 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,877 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,878 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-02-02 20:34:53,880 - INFO - Processing story: About_a_Hum
2026-02-02 20:34:53,882 - ERROR - Failed to process question 2 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 4 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 6 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 8 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 10 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 12 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,882 - ERROR - Failed to process question 14 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 16 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 18 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 20 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 22 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 24 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 26 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 28 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 30 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,883 - ERROR - Failed to process question 32 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,884 - ERROR - Failed to process question 34 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,884 - ERROR - Failed to process question 36 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,884 - ERROR - Failed to process question 38 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,884 - ERROR - Failed to process question 40 for story About_a_Hum: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,884 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,886 - INFO - ✓ Saved: About_a_Hum.json
2026-02-02 20:34:53,888 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-02-02 20:34:53,889 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,889 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,890 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,890 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,890 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,890 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,890 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,891 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,892 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,892 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,894 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-02-02 20:34:53,896 - INFO - Processing story: Back_To_The_Wall
2026-02-02 20:34:53,897 - ERROR - Failed to process question 2 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,897 - ERROR - Failed to process question 4 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 6 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 8 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 10 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 12 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 14 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,898 - ERROR - Failed to process question 16 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 18 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 20 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 22 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 24 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 26 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 28 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 30 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 32 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 34 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 36 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 38 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,899 - ERROR - Failed to process question 40 for story Back_To_The_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,900 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,902 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-02-02 20:34:53,904 - INFO - Processing story: Community_Time
2026-02-02 20:34:53,905 - ERROR - Failed to process question 2 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,905 - ERROR - Failed to process question 4 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 6 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 8 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 10 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 12 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 14 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 16 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 18 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 20 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 22 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 24 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,906 - ERROR - Failed to process question 26 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 28 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 30 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 32 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 34 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 36 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 38 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - ERROR - Failed to process question 40 for story Community_Time: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,907 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,909 - INFO - ✓ Saved: Community_Time.json
2026-02-02 20:34:53,912 - INFO - Processing story: Fleabags
2026-02-02 20:34:53,913 - ERROR - Failed to process question 2 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,913 - ERROR - Failed to process question 4 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,913 - ERROR - Failed to process question 6 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,913 - ERROR - Failed to process question 8 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,913 - ERROR - Failed to process question 10 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,913 - ERROR - Failed to process question 12 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 14 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 16 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 18 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 20 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 22 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 24 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 26 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 28 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 30 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 32 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,914 - ERROR - Failed to process question 34 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,915 - ERROR - Failed to process question 36 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,915 - ERROR - Failed to process question 38 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,915 - ERROR - Failed to process question 40 for story Fleabags: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,915 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,917 - INFO - ✓ Saved: Fleabags.json
2026-02-02 20:34:53,919 - INFO - Processing story: Gravity_Reduced
2026-02-02 20:34:53,920 - ERROR - Failed to process question 2 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,920 - ERROR - Failed to process question 4 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,920 - ERROR - Failed to process question 6 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,920 - ERROR - Failed to process question 8 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 10 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 12 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 14 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 16 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 18 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 20 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 22 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 24 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 26 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 28 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 30 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,921 - ERROR - Failed to process question 32 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,922 - ERROR - Failed to process question 34 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,922 - ERROR - Failed to process question 36 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,922 - ERROR - Failed to process question 38 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,922 - ERROR - Failed to process question 40 for story Gravity_Reduced: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,922 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,924 - INFO - ✓ Saved: Gravity_Reduced.json
2026-02-02 20:34:53,926 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-02-02 20:34:53,927 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,928 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,929 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,929 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,930 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,930 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,930 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,930 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,930 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,931 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,931 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,933 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-02-02 20:34:53,936 - INFO - Processing story: Honeybee
2026-02-02 20:34:53,937 - ERROR - Failed to process question 2 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,937 - ERROR - Failed to process question 4 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 6 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 8 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 10 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 12 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 14 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,938 - ERROR - Failed to process question 16 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,939 - ERROR - Failed to process question 18 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,939 - ERROR - Failed to process question 20 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,939 - ERROR - Failed to process question 22 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,939 - ERROR - Failed to process question 24 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,940 - ERROR - Failed to process question 26 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,940 - ERROR - Failed to process question 28 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,940 - ERROR - Failed to process question 30 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,940 - ERROR - Failed to process question 32 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,940 - ERROR - Failed to process question 34 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,941 - ERROR - Failed to process question 36 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,941 - ERROR - Failed to process question 38 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,941 - ERROR - Failed to process question 40 for story Honeybee: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,941 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,943 - INFO - ✓ Saved: Honeybee.json
2026-02-02 20:34:53,946 - INFO - Processing story: Last_Long_Night
2026-02-02 20:34:53,947 - ERROR - Failed to process question 2 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,947 - ERROR - Failed to process question 4 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 6 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 8 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 10 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 12 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 14 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,948 - ERROR - Failed to process question 16 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,949 - ERROR - Failed to process question 18 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,949 - ERROR - Failed to process question 20 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,949 - ERROR - Failed to process question 22 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,949 - ERROR - Failed to process question 24 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,950 - ERROR - Failed to process question 26 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,950 - ERROR - Failed to process question 28 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,950 - ERROR - Failed to process question 30 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,950 - ERROR - Failed to process question 32 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,950 - ERROR - Failed to process question 34 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,951 - ERROR - Failed to process question 36 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,951 - ERROR - Failed to process question 38 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,951 - ERROR - Failed to process question 40 for story Last_Long_Night: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,951 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,953 - INFO - ✓ Saved: Last_Long_Night.json
2026-02-02 20:34:53,955 - INFO - Processing story: Raindrop_Snowflake
2026-02-02 20:34:53,956 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,956 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,957 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,958 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,960 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-02-02 20:34:53,962 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-02-02 20:34:53,964 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,964 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,964 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,964 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,964 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,964 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,965 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,966 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,966 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,966 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,966 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,966 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,968 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-02-02 20:34:53,970 - INFO - Processing story: Rice
2026-02-02 20:34:53,971 - ERROR - Failed to process question 2 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,971 - ERROR - Failed to process question 4 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 6 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 8 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 10 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 12 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 14 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 16 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 18 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 20 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 22 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 24 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 26 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,972 - ERROR - Failed to process question 28 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 30 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 32 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 34 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 36 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 38 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - ERROR - Failed to process question 40 for story Rice: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,973 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,975 - INFO - ✓ Saved: Rice.json
2026-02-02 20:34:53,977 - INFO - Processing story: Swallowed
2026-02-02 20:34:53,978 - ERROR - Failed to process question 2 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 4 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 6 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 8 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 10 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 12 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 14 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 16 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,979 - ERROR - Failed to process question 18 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 20 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 22 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 24 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 26 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 28 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 30 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 32 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 34 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 36 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 38 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,980 - ERROR - Failed to process question 40 for story Swallowed: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,981 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,982 - INFO - ✓ Saved: Swallowed.json
2026-02-02 20:34:53,984 - INFO - Processing story: The_Ants_and_The_Locusts
2026-02-02 20:34:53,986 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,986 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,987 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,988 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,988 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,988 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,988 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,990 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-02-02 20:34:53,992 - INFO - Processing story: The_Christmas_Monks
2026-02-02 20:34:53,993 - ERROR - Failed to process question 2 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,993 - ERROR - Failed to process question 4 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 6 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 8 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 10 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 12 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 14 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 16 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 18 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 20 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 22 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,994 - ERROR - Failed to process question 24 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 26 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 28 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 30 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 32 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 34 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 36 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 38 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - ERROR - Failed to process question 40 for story The_Christmas_Monks: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:53,995 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:53,997 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-02-02 20:34:53,999 - INFO - Processing story: The_Circuit
2026-02-02 20:34:54,001 - ERROR - Failed to process question 2 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 4 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 6 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 8 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 10 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 12 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 14 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 16 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 18 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,001 - ERROR - Failed to process question 20 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 22 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 24 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 26 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 28 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 30 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 32 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 34 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 36 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 38 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - ERROR - Failed to process question 40 for story The_Circuit: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,002 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,004 - INFO - ✓ Saved: The_Circuit.json
2026-02-02 20:34:54,006 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-02-02 20:34:54,007 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,007 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,008 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,009 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,011 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-02-02 20:34:54,013 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-02-02 20:34:54,015 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,015 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,016 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,017 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,017 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,017 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,017 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,018 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-02-02 20:34:54,021 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-02-02 20:34:54,022 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,022 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,022 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,022 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,023 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,024 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,024 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,024 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,024 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,024 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,026 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-02-02 20:34:54,029 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-02-02 20:34:54,030 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,030 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,030 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,030 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,031 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,032 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,032 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,032 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,034 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-02-02 20:34:54,036 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-02-02 20:34:54,037 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,037 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,038 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,039 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,040 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,042 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-02-02 20:34:54,044 - INFO - Processing story: The_Stretcher
2026-02-02 20:34:54,045 - ERROR - Failed to process question 2 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 4 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 6 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 8 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 10 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 12 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 14 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 16 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,046 - ERROR - Failed to process question 18 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 20 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 22 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 24 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 26 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 28 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 30 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 32 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 34 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 36 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 38 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - ERROR - Failed to process question 40 for story The_Stretcher: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,047 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,049 - INFO - ✓ Saved: The_Stretcher.json
2026-02-02 20:34:54,052 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-02-02 20:34:54,053 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,053 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,054 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,055 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,057 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-02-02 20:34:54,060 - INFO - Processing story: War_of_the_Wall
2026-02-02 20:34:54,061 - ERROR - Failed to process question 2 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,061 - ERROR - Failed to process question 4 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 6 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 8 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 10 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 12 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 14 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,062 - ERROR - Failed to process question 16 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 18 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 20 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 22 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 24 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 26 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 28 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 30 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 32 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,063 - ERROR - Failed to process question 34 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,064 - ERROR - Failed to process question 36 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,064 - ERROR - Failed to process question 38 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,064 - ERROR - Failed to process question 40 for story War_of_the_Wall: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,064 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,066 - INFO - ✓ Saved: War_of_the_Wall.json
2026-02-02 20:34:54,069 - INFO - Processing story: Warrior_Women_Nicaragua
2026-02-02 20:34:54,070 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,070 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,070 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,071 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,072 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,073 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,073 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,073 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,075 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-02-02 20:34:54,078 - INFO - Processing story: We_Stand_Up
2026-02-02 20:34:54,079 - ERROR - Failed to process question 2 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,079 - ERROR - Failed to process question 4 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,079 - ERROR - Failed to process question 6 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,079 - ERROR - Failed to process question 8 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 10 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 12 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 14 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 16 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 18 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 20 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 22 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 24 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 26 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,080 - ERROR - Failed to process question 28 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 30 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 32 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 34 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 36 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 38 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,081 - ERROR - Failed to process question 40 for story We_Stand_Up: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,082 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,083 - INFO - ✓ Saved: We_Stand_Up.json
2026-02-02 20:34:54,086 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-02-02 20:34:54,087 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,087 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,088 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,089 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: OPENAI_API_KEY environment variable not set. Set it with: export OPENAI_API_KEY='your-key'
2026-02-02 20:34:54,090 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:34:54,092 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-02-02 20:34:54,098 - INFO - 
============================================================
2026-02-02 20:34:54,098 - INFO - Survey complete!
2026-02-02 20:34:54,099 - INFO - Processed: 28/28 stories
2026-02-02 20:34:54,099 - INFO - Failed: 0 stories
2026-02-02 20:34:54,099 - INFO - Total cost: $0.0000
2026-02-02 20:34:54,099 - INFO - Total tokens: 0
2026-02-02 20:34:54,099 - INFO - ============================================================

2026-02-02 20:34:54,099 - INFO - 
============================================================
2026-02-02 20:34:54,100 - INFO - Step 4: Learning PyReason Rules
2026-02-02 20:34:54,100 - INFO - ============================================================
2026-02-02 20:34:54,100 - INFO - ============================================================
2026-02-02 20:34:54,100 - INFO - RULE LEARNING
2026-02-02 20:34:54,100 - INFO - ============================================================
2026-02-02 20:34:54,100 - INFO - Loading survey results from: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:34:54,102 - INFO - Found 28 survey result files
2026-02-02 20:34:54,125 - INFO - Successfully loaded 28 survey results
2026-02-02 20:34:54,125 - INFO - Extracting feature scores...
2026-02-02 20:34:54,125 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,125 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,126 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-02-02 20:34:54,127 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-02-02 20:34:54,128 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,129 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,130 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,131 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,132 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-02-02 20:34:54,133 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-02-02 20:34:54,134 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-02-02 20:34:54,135 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-02-02 20:34:54,136 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-02-02 20:34:54,137 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-02-02 20:34:54,138 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,139 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,140 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-02-02 20:34:54,141 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-02-02 20:34:54,142 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-02-02 20:34:54,143 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-02-02 20:34:54,144 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,145 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,146 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,147 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,148 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,149 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-02-02 20:34:54,150 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-02-02 20:34:54,151 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-02-02 20:34:54,151 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-02-02 20:34:54,151 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-02-02 20:34:54,151 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-02-02 20:34:54,151 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-02-02 20:34:54,152 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-02-02 20:34:54,153 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-02-02 20:34:54,154 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,155 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,156 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,157 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,158 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-02-02 20:34:54,159 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-02-02 20:34:54,160 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,161 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,162 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,163 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,164 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,165 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,166 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,167 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,168 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,169 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-02-02 20:34:54,170 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-02-02 20:34:54,171 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,172 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,173 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-02-02 20:34:54,174 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-02-02 20:34:54,175 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,176 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-02-02 20:34:54,177 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-02-02 20:34:54,178 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,179 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,180 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,181 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:34:54,181 - INFO - Extracted scores for 28 stories and 0 features
2026-02-02 20:34:54,181 - INFO - Learning PyReason rules...
2026-02-02 20:34:54,181 - INFO - Configuration:
2026-02-02 20:34:54,181 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-02-02 20:34:54,181 - INFO -   - Min confidence: 0.0
2026-02-02 20:34:54,181 - INFO -   - Min support: 0
2026-02-02 20:34:54,181 - INFO - Learning rules for 0 features...
2026-02-02 20:34:54,181 - INFO - Learned 0 rules
2026-02-02 20:34:54,183 - INFO - Saved 0 rules to output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:34:54,183 - INFO - ============================================================
2026-02-02 20:34:54,183 - INFO - RULE LEARNING COMPLETE
2026-02-02 20:34:54,184 - INFO - ============================================================
2026-02-02 20:34:54,184 - INFO - Stories processed: 28
2026-02-02 20:34:54,184 - INFO - Features: 0
2026-02-02 20:34:54,184 - INFO - Rules learned: 0
2026-02-02 20:34:54,184 - INFO - Rules saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:34:54,184 - INFO - ============================================================
2026-02-02 20:34:54,184 - INFO - 
✓ Rules learned and saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:34:54,185 - INFO - 
Phase 1 completed successfully!
2026-02-02 20:34:54,185 - INFO - Output directory: output/phase1
2026-02-02 20:34:54,185 - INFO - ============================================================
2026-02-02 20:34:54,185 - INFO - Execution completed successfully!
2026-02-02 20:34:54,185 - INFO - ============================================================
2026-02-02 20:37:10,784 - INFO - ============================================================
2026-02-02 20:37:10,784 - INFO - CONNECT Project - Phase 1
2026-02-02 20:37:10,784 - INFO - Problem: inverse
2026-02-02 20:37:10,784 - INFO - ============================================================
2026-02-02 20:37:10,785 - INFO - 
============================================================
2026-02-02 20:37:10,785 - INFO - PHASE 1: TRAINING
2026-02-02 20:37:10,785 - INFO - ============================================================
2026-02-02 20:37:10,785 - INFO - Loading collectivistic stories for inverse problem
2026-02-02 20:37:10,786 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-02-02 20:37:10,807 - INFO - Successfully loaded 28 stories
2026-02-02 20:37:10,807 - INFO - Loaded 28 training stories
2026-02-02 20:37:10,811 - INFO - Survey results will be saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:37:10,816 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-02-02 20:37:10,862 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,862 - ERROR - Failed to process question 2 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,863 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,863 - ERROR - Failed to process question 4 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,864 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,865 - ERROR - Failed to process question 6 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,866 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,866 - ERROR - Failed to process question 8 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,868 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,868 - ERROR - Failed to process question 10 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,870 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,870 - ERROR - Failed to process question 12 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,871 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,871 - ERROR - Failed to process question 14 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,872 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,872 - ERROR - Failed to process question 16 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,874 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,874 - ERROR - Failed to process question 18 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,875 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,875 - ERROR - Failed to process question 20 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,876 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,876 - ERROR - Failed to process question 22 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,877 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,878 - ERROR - Failed to process question 24 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,878 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,879 - ERROR - Failed to process question 26 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,880 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,880 - ERROR - Failed to process question 28 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,881 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,881 - ERROR - Failed to process question 30 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,884 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,884 - ERROR - Failed to process question 32 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,885 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,885 - ERROR - Failed to process question 34 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,886 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,886 - ERROR - Failed to process question 36 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,887 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,888 - ERROR - Failed to process question 38 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,889 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,889 - ERROR - Failed to process question 40 for story A_Piece_of_Yellow_Soap: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,889 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:10,891 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-02-02 20:37:10,893 - INFO - Processing story: About_a_Hum
2026-02-02 20:37:10,895 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,896 - ERROR - Failed to process question 2 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,897 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,897 - ERROR - Failed to process question 4 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,898 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,898 - ERROR - Failed to process question 6 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,899 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,899 - ERROR - Failed to process question 8 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,900 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,900 - ERROR - Failed to process question 10 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,901 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,902 - ERROR - Failed to process question 12 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,903 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,903 - ERROR - Failed to process question 14 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,904 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,904 - ERROR - Failed to process question 16 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,905 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,905 - ERROR - Failed to process question 18 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,906 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,906 - ERROR - Failed to process question 20 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,907 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,907 - ERROR - Failed to process question 22 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,908 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,908 - ERROR - Failed to process question 24 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,909 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,910 - ERROR - Failed to process question 26 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,910 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,911 - ERROR - Failed to process question 28 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,911 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,911 - ERROR - Failed to process question 30 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,913 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,913 - ERROR - Failed to process question 32 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,914 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,914 - ERROR - Failed to process question 34 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,915 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,915 - ERROR - Failed to process question 36 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,917 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,917 - ERROR - Failed to process question 38 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,918 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,918 - ERROR - Failed to process question 40 for story About_a_Hum: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,918 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:10,920 - INFO - ✓ Saved: About_a_Hum.json
2026-02-02 20:37:10,923 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-02-02 20:37:10,925 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,925 - ERROR - Failed to process question 2 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,926 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,926 - ERROR - Failed to process question 4 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,927 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,927 - ERROR - Failed to process question 6 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,928 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,928 - ERROR - Failed to process question 8 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,930 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,930 - ERROR - Failed to process question 10 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,931 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,931 - ERROR - Failed to process question 12 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,932 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,932 - ERROR - Failed to process question 14 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,933 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,933 - ERROR - Failed to process question 16 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,935 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,935 - ERROR - Failed to process question 18 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,935 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,936 - ERROR - Failed to process question 20 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,937 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,937 - ERROR - Failed to process question 22 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,938 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,938 - ERROR - Failed to process question 24 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,940 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,940 - ERROR - Failed to process question 26 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,941 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,941 - ERROR - Failed to process question 28 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,942 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,942 - ERROR - Failed to process question 30 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,943 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,943 - ERROR - Failed to process question 32 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,944 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,944 - ERROR - Failed to process question 34 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,945 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,945 - ERROR - Failed to process question 36 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,947 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,947 - ERROR - Failed to process question 38 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,948 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,948 - ERROR - Failed to process question 40 for story All_Summer_in_a_Day_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,948 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:10,949 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-02-02 20:37:10,952 - INFO - Processing story: Back_To_The_Wall
2026-02-02 20:37:10,954 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,954 - ERROR - Failed to process question 2 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,955 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,956 - ERROR - Failed to process question 4 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,956 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,956 - ERROR - Failed to process question 6 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,958 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,958 - ERROR - Failed to process question 8 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,959 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,959 - ERROR - Failed to process question 10 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,960 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,960 - ERROR - Failed to process question 12 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,962 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,962 - ERROR - Failed to process question 14 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,962 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,963 - ERROR - Failed to process question 16 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,964 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,964 - ERROR - Failed to process question 18 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,965 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,965 - ERROR - Failed to process question 20 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,966 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,966 - ERROR - Failed to process question 22 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,967 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,967 - ERROR - Failed to process question 24 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,968 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,969 - ERROR - Failed to process question 26 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,970 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,970 - ERROR - Failed to process question 28 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,972 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,972 - ERROR - Failed to process question 30 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,973 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,973 - ERROR - Failed to process question 32 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,975 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,975 - ERROR - Failed to process question 34 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,976 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,976 - ERROR - Failed to process question 36 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,977 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,977 - ERROR - Failed to process question 38 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,978 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,978 - ERROR - Failed to process question 40 for story Back_To_The_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,979 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:10,980 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-02-02 20:37:10,983 - INFO - Processing story: Community_Time
2026-02-02 20:37:10,985 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,985 - ERROR - Failed to process question 2 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,986 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,986 - ERROR - Failed to process question 4 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,987 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,987 - ERROR - Failed to process question 6 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,988 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,988 - ERROR - Failed to process question 8 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,990 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,990 - ERROR - Failed to process question 10 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,991 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,991 - ERROR - Failed to process question 12 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,992 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,992 - ERROR - Failed to process question 14 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,994 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,994 - ERROR - Failed to process question 16 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,995 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,995 - ERROR - Failed to process question 18 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,996 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,996 - ERROR - Failed to process question 20 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,997 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,997 - ERROR - Failed to process question 22 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,998 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,998 - ERROR - Failed to process question 24 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,999 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:10,999 - ERROR - Failed to process question 26 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,000 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,000 - ERROR - Failed to process question 28 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,002 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,002 - ERROR - Failed to process question 30 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,003 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,003 - ERROR - Failed to process question 32 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,004 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,004 - ERROR - Failed to process question 34 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,005 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,005 - ERROR - Failed to process question 36 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,006 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,006 - ERROR - Failed to process question 38 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,007 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,008 - ERROR - Failed to process question 40 for story Community_Time: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,008 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,010 - INFO - ✓ Saved: Community_Time.json
2026-02-02 20:37:11,012 - INFO - Processing story: Fleabags
2026-02-02 20:37:11,014 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,014 - ERROR - Failed to process question 2 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,016 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,016 - ERROR - Failed to process question 4 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,017 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,017 - ERROR - Failed to process question 6 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,018 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,018 - ERROR - Failed to process question 8 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,020 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,020 - ERROR - Failed to process question 10 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,021 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,021 - ERROR - Failed to process question 12 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,022 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,022 - ERROR - Failed to process question 14 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,023 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,023 - ERROR - Failed to process question 16 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,025 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,025 - ERROR - Failed to process question 18 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,026 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,026 - ERROR - Failed to process question 20 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,027 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,027 - ERROR - Failed to process question 22 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,028 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,028 - ERROR - Failed to process question 24 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,029 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,029 - ERROR - Failed to process question 26 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,030 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,030 - ERROR - Failed to process question 28 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,032 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,032 - ERROR - Failed to process question 30 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,033 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,033 - ERROR - Failed to process question 32 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,034 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,035 - ERROR - Failed to process question 34 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,036 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,036 - ERROR - Failed to process question 36 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,037 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,037 - ERROR - Failed to process question 38 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,039 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,039 - ERROR - Failed to process question 40 for story Fleabags: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,039 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,041 - INFO - ✓ Saved: Fleabags.json
2026-02-02 20:37:11,043 - INFO - Processing story: Gravity_Reduced
2026-02-02 20:37:11,045 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,045 - ERROR - Failed to process question 2 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,047 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,047 - ERROR - Failed to process question 4 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,048 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,048 - ERROR - Failed to process question 6 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,049 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,049 - ERROR - Failed to process question 8 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,050 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,050 - ERROR - Failed to process question 10 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,051 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,052 - ERROR - Failed to process question 12 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,052 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,053 - ERROR - Failed to process question 14 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,054 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,054 - ERROR - Failed to process question 16 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,055 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,055 - ERROR - Failed to process question 18 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,056 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,056 - ERROR - Failed to process question 20 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,058 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,058 - ERROR - Failed to process question 22 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,058 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,059 - ERROR - Failed to process question 24 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,060 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,060 - ERROR - Failed to process question 26 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,061 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,061 - ERROR - Failed to process question 28 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,063 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,063 - ERROR - Failed to process question 30 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,065 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,065 - ERROR - Failed to process question 32 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,066 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,066 - ERROR - Failed to process question 34 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,067 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,067 - ERROR - Failed to process question 36 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,068 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,069 - ERROR - Failed to process question 38 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,069 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,070 - ERROR - Failed to process question 40 for story Gravity_Reduced: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,070 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,072 - INFO - ✓ Saved: Gravity_Reduced.json
2026-02-02 20:37:11,074 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-02-02 20:37:11,076 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,076 - ERROR - Failed to process question 2 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,077 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,077 - ERROR - Failed to process question 4 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,078 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,079 - ERROR - Failed to process question 6 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,079 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,080 - ERROR - Failed to process question 8 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,081 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,081 - ERROR - Failed to process question 10 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,082 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,082 - ERROR - Failed to process question 12 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,083 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,083 - ERROR - Failed to process question 14 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,085 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,085 - ERROR - Failed to process question 16 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,086 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,086 - ERROR - Failed to process question 18 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,087 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,087 - ERROR - Failed to process question 20 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,088 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,089 - ERROR - Failed to process question 22 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,089 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,090 - ERROR - Failed to process question 24 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,091 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,091 - ERROR - Failed to process question 26 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,092 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,092 - ERROR - Failed to process question 28 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,093 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,093 - ERROR - Failed to process question 30 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,095 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,095 - ERROR - Failed to process question 32 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,096 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,096 - ERROR - Failed to process question 34 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,098 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,098 - ERROR - Failed to process question 36 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,099 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,099 - ERROR - Failed to process question 38 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,100 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,100 - ERROR - Failed to process question 40 for story Harrison_Bergeron_Kurt_Vonnegut: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,101 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,103 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-02-02 20:37:11,106 - INFO - Processing story: Honeybee
2026-02-02 20:37:11,108 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,108 - ERROR - Failed to process question 2 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,109 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,109 - ERROR - Failed to process question 4 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,110 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,111 - ERROR - Failed to process question 6 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,111 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,111 - ERROR - Failed to process question 8 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,113 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,113 - ERROR - Failed to process question 10 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,114 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,114 - ERROR - Failed to process question 12 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,115 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,115 - ERROR - Failed to process question 14 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,116 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,116 - ERROR - Failed to process question 16 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,117 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,117 - ERROR - Failed to process question 18 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,118 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,118 - ERROR - Failed to process question 20 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,119 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,119 - ERROR - Failed to process question 22 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,120 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,120 - ERROR - Failed to process question 24 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,122 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,122 - ERROR - Failed to process question 26 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,122 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,123 - ERROR - Failed to process question 28 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,124 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,124 - ERROR - Failed to process question 30 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,125 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,125 - ERROR - Failed to process question 32 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,126 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,126 - ERROR - Failed to process question 34 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,127 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,127 - ERROR - Failed to process question 36 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,128 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,129 - ERROR - Failed to process question 38 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,129 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,130 - ERROR - Failed to process question 40 for story Honeybee: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,130 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,132 - INFO - ✓ Saved: Honeybee.json
2026-02-02 20:37:11,134 - INFO - Processing story: Last_Long_Night
2026-02-02 20:37:11,137 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,137 - ERROR - Failed to process question 2 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,138 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,138 - ERROR - Failed to process question 4 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,139 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,139 - ERROR - Failed to process question 6 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,140 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,140 - ERROR - Failed to process question 8 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,142 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,142 - ERROR - Failed to process question 10 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,143 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,143 - ERROR - Failed to process question 12 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,144 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,144 - ERROR - Failed to process question 14 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,146 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,146 - ERROR - Failed to process question 16 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,147 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,147 - ERROR - Failed to process question 18 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,148 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,148 - ERROR - Failed to process question 20 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,149 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,150 - ERROR - Failed to process question 22 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,151 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,151 - ERROR - Failed to process question 24 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,153 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,153 - ERROR - Failed to process question 26 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,155 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,155 - ERROR - Failed to process question 28 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,157 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,157 - ERROR - Failed to process question 30 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,159 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,159 - ERROR - Failed to process question 32 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,160 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,161 - ERROR - Failed to process question 34 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,162 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,162 - ERROR - Failed to process question 36 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,163 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,163 - ERROR - Failed to process question 38 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,165 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,165 - ERROR - Failed to process question 40 for story Last_Long_Night: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,165 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,167 - INFO - ✓ Saved: Last_Long_Night.json
2026-02-02 20:37:11,170 - INFO - Processing story: Raindrop_Snowflake
2026-02-02 20:37:11,172 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,172 - ERROR - Failed to process question 2 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,174 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,174 - ERROR - Failed to process question 4 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,175 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,175 - ERROR - Failed to process question 6 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,176 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,176 - ERROR - Failed to process question 8 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,178 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,178 - ERROR - Failed to process question 10 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,179 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,179 - ERROR - Failed to process question 12 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,180 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,180 - ERROR - Failed to process question 14 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,181 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,181 - ERROR - Failed to process question 16 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,183 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,183 - ERROR - Failed to process question 18 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,183 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,184 - ERROR - Failed to process question 20 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,185 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,185 - ERROR - Failed to process question 22 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,186 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,186 - ERROR - Failed to process question 24 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,187 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,187 - ERROR - Failed to process question 26 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,188 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,188 - ERROR - Failed to process question 28 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,189 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,189 - ERROR - Failed to process question 30 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,191 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,191 - ERROR - Failed to process question 32 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,192 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,192 - ERROR - Failed to process question 34 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,193 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,193 - ERROR - Failed to process question 36 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,194 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,194 - ERROR - Failed to process question 38 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,196 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,196 - ERROR - Failed to process question 40 for story Raindrop_Snowflake: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,196 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,198 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-02-02 20:37:11,200 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-02-02 20:37:11,202 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,203 - ERROR - Failed to process question 2 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,204 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,204 - ERROR - Failed to process question 4 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,205 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,205 - ERROR - Failed to process question 6 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,207 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,207 - ERROR - Failed to process question 8 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,208 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,208 - ERROR - Failed to process question 10 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,210 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,210 - ERROR - Failed to process question 12 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,211 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,211 - ERROR - Failed to process question 14 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,212 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,212 - ERROR - Failed to process question 16 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,214 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,214 - ERROR - Failed to process question 18 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,215 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,215 - ERROR - Failed to process question 20 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,216 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,216 - ERROR - Failed to process question 22 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,217 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,218 - ERROR - Failed to process question 24 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,219 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,219 - ERROR - Failed to process question 26 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,220 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,220 - ERROR - Failed to process question 28 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,221 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,221 - ERROR - Failed to process question 30 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,223 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,223 - ERROR - Failed to process question 32 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,224 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,224 - ERROR - Failed to process question 34 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,226 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,226 - ERROR - Failed to process question 36 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,227 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,227 - ERROR - Failed to process question 38 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,229 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,229 - ERROR - Failed to process question 40 for story Redemption_of_the_Cursed_Village: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,229 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,231 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-02-02 20:37:11,234 - INFO - Processing story: Rice
2026-02-02 20:37:11,236 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,236 - ERROR - Failed to process question 2 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,238 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,238 - ERROR - Failed to process question 4 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,239 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,239 - ERROR - Failed to process question 6 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,240 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,240 - ERROR - Failed to process question 8 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,241 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,242 - ERROR - Failed to process question 10 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,243 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,243 - ERROR - Failed to process question 12 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,244 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,244 - ERROR - Failed to process question 14 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,245 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,245 - ERROR - Failed to process question 16 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,246 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,246 - ERROR - Failed to process question 18 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,247 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,247 - ERROR - Failed to process question 20 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,249 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,249 - ERROR - Failed to process question 22 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,250 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,250 - ERROR - Failed to process question 24 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,251 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,251 - ERROR - Failed to process question 26 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,253 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,253 - ERROR - Failed to process question 28 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,254 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,254 - ERROR - Failed to process question 30 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,256 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,256 - ERROR - Failed to process question 32 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,257 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,257 - ERROR - Failed to process question 34 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,258 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,258 - ERROR - Failed to process question 36 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,259 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,259 - ERROR - Failed to process question 38 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,260 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,260 - ERROR - Failed to process question 40 for story Rice: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,261 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,262 - INFO - ✓ Saved: Rice.json
2026-02-02 20:37:11,265 - INFO - Processing story: Swallowed
2026-02-02 20:37:11,267 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,267 - ERROR - Failed to process question 2 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,269 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,269 - ERROR - Failed to process question 4 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,269 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,270 - ERROR - Failed to process question 6 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,271 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,271 - ERROR - Failed to process question 8 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,272 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,272 - ERROR - Failed to process question 10 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,273 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,273 - ERROR - Failed to process question 12 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,274 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,274 - ERROR - Failed to process question 14 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,276 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,276 - ERROR - Failed to process question 16 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,276 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,277 - ERROR - Failed to process question 18 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,278 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,278 - ERROR - Failed to process question 20 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,279 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,279 - ERROR - Failed to process question 22 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,280 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,280 - ERROR - Failed to process question 24 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,281 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,281 - ERROR - Failed to process question 26 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,282 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,282 - ERROR - Failed to process question 28 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,283 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,283 - ERROR - Failed to process question 30 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,285 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,285 - ERROR - Failed to process question 32 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,286 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,286 - ERROR - Failed to process question 34 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,287 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,287 - ERROR - Failed to process question 36 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,288 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,288 - ERROR - Failed to process question 38 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,289 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,290 - ERROR - Failed to process question 40 for story Swallowed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,290 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,292 - INFO - ✓ Saved: Swallowed.json
2026-02-02 20:37:11,294 - INFO - Processing story: The_Ants_and_The_Locusts
2026-02-02 20:37:11,296 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,296 - ERROR - Failed to process question 2 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,298 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,298 - ERROR - Failed to process question 4 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,299 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,299 - ERROR - Failed to process question 6 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,300 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,300 - ERROR - Failed to process question 8 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,302 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,302 - ERROR - Failed to process question 10 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,303 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,303 - ERROR - Failed to process question 12 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,304 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,304 - ERROR - Failed to process question 14 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,306 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,306 - ERROR - Failed to process question 16 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,307 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,307 - ERROR - Failed to process question 18 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,308 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,308 - ERROR - Failed to process question 20 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,309 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,309 - ERROR - Failed to process question 22 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,310 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,310 - ERROR - Failed to process question 24 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,312 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,312 - ERROR - Failed to process question 26 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,312 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,313 - ERROR - Failed to process question 28 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,314 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,314 - ERROR - Failed to process question 30 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,315 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,315 - ERROR - Failed to process question 32 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,316 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,316 - ERROR - Failed to process question 34 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,317 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,317 - ERROR - Failed to process question 36 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,319 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,319 - ERROR - Failed to process question 38 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,320 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,320 - ERROR - Failed to process question 40 for story The_Ants_and_The_Locusts: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,320 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,322 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-02-02 20:37:11,324 - INFO - Processing story: The_Christmas_Monks
2026-02-02 20:37:11,327 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,327 - ERROR - Failed to process question 2 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,328 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,328 - ERROR - Failed to process question 4 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,329 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,329 - ERROR - Failed to process question 6 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,330 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,330 - ERROR - Failed to process question 8 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,332 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,332 - ERROR - Failed to process question 10 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,333 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,333 - ERROR - Failed to process question 12 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,334 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,334 - ERROR - Failed to process question 14 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,335 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,335 - ERROR - Failed to process question 16 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,337 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,337 - ERROR - Failed to process question 18 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,337 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,338 - ERROR - Failed to process question 20 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,339 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,339 - ERROR - Failed to process question 22 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,340 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,340 - ERROR - Failed to process question 24 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,342 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,342 - ERROR - Failed to process question 26 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,343 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,343 - ERROR - Failed to process question 28 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,345 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,345 - ERROR - Failed to process question 30 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,346 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,346 - ERROR - Failed to process question 32 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,348 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,348 - ERROR - Failed to process question 34 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,349 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,349 - ERROR - Failed to process question 36 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,350 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,350 - ERROR - Failed to process question 38 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,351 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,351 - ERROR - Failed to process question 40 for story The_Christmas_Monks: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,351 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,354 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-02-02 20:37:11,356 - INFO - Processing story: The_Circuit
2026-02-02 20:37:11,358 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,358 - ERROR - Failed to process question 2 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,359 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,359 - ERROR - Failed to process question 4 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,360 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,360 - ERROR - Failed to process question 6 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,362 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,362 - ERROR - Failed to process question 8 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,363 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,363 - ERROR - Failed to process question 10 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,364 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,364 - ERROR - Failed to process question 12 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,366 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,366 - ERROR - Failed to process question 14 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,367 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,367 - ERROR - Failed to process question 16 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,368 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,368 - ERROR - Failed to process question 18 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,369 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,369 - ERROR - Failed to process question 20 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,370 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,370 - ERROR - Failed to process question 22 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,371 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,372 - ERROR - Failed to process question 24 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,373 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,373 - ERROR - Failed to process question 26 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,374 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,374 - ERROR - Failed to process question 28 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,375 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,375 - ERROR - Failed to process question 30 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,376 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,376 - ERROR - Failed to process question 32 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,378 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,378 - ERROR - Failed to process question 34 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,379 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,379 - ERROR - Failed to process question 36 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,380 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,380 - ERROR - Failed to process question 38 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,382 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,382 - ERROR - Failed to process question 40 for story The_Circuit: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,382 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,384 - INFO - ✓ Saved: The_Circuit.json
2026-02-02 20:37:11,386 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-02-02 20:37:11,388 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,389 - ERROR - Failed to process question 2 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,390 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,390 - ERROR - Failed to process question 4 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,391 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,391 - ERROR - Failed to process question 6 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,392 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,392 - ERROR - Failed to process question 8 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,393 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,393 - ERROR - Failed to process question 10 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,394 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,394 - ERROR - Failed to process question 12 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,395 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,395 - ERROR - Failed to process question 14 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,396 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,396 - ERROR - Failed to process question 16 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,397 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,397 - ERROR - Failed to process question 18 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,398 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,398 - ERROR - Failed to process question 20 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,399 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,400 - ERROR - Failed to process question 22 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,401 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,401 - ERROR - Failed to process question 24 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,402 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,402 - ERROR - Failed to process question 26 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,403 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,403 - ERROR - Failed to process question 28 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,405 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,405 - ERROR - Failed to process question 30 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,406 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,406 - ERROR - Failed to process question 32 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,408 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,408 - ERROR - Failed to process question 34 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,409 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,409 - ERROR - Failed to process question 36 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,410 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,410 - ERROR - Failed to process question 38 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,412 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,412 - ERROR - Failed to process question 40 for story The_Fire_That_Fed_the_People: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,412 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,414 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-02-02 20:37:11,416 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-02-02 20:37:11,419 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,419 - ERROR - Failed to process question 2 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,420 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,420 - ERROR - Failed to process question 4 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,421 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,421 - ERROR - Failed to process question 6 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,422 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,422 - ERROR - Failed to process question 8 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,424 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,424 - ERROR - Failed to process question 10 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,425 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,426 - ERROR - Failed to process question 12 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,427 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,427 - ERROR - Failed to process question 14 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,428 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,429 - ERROR - Failed to process question 16 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,430 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,430 - ERROR - Failed to process question 18 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,431 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,431 - ERROR - Failed to process question 20 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,432 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,432 - ERROR - Failed to process question 22 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,433 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,433 - ERROR - Failed to process question 24 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,434 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,435 - ERROR - Failed to process question 26 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,435 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,435 - ERROR - Failed to process question 28 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,437 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,437 - ERROR - Failed to process question 30 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,439 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,439 - ERROR - Failed to process question 32 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,440 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,441 - ERROR - Failed to process question 34 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,441 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,441 - ERROR - Failed to process question 36 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,443 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,443 - ERROR - Failed to process question 38 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,444 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,444 - ERROR - Failed to process question 40 for story The_Gentleman_of_the_Jungle: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,445 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,446 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-02-02 20:37:11,449 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-02-02 20:37:11,451 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,451 - ERROR - Failed to process question 2 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,453 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,453 - ERROR - Failed to process question 4 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,453 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,454 - ERROR - Failed to process question 6 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,455 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,455 - ERROR - Failed to process question 8 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,456 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,456 - ERROR - Failed to process question 10 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,457 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,457 - ERROR - Failed to process question 12 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,459 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,459 - ERROR - Failed to process question 14 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,460 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,460 - ERROR - Failed to process question 16 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,461 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,461 - ERROR - Failed to process question 18 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,462 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,463 - ERROR - Failed to process question 20 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,463 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,463 - ERROR - Failed to process question 22 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,465 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,465 - ERROR - Failed to process question 24 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,466 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,466 - ERROR - Failed to process question 26 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,467 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,467 - ERROR - Failed to process question 28 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,468 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,468 - ERROR - Failed to process question 30 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,469 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,469 - ERROR - Failed to process question 32 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,471 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,471 - ERROR - Failed to process question 34 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,472 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,472 - ERROR - Failed to process question 36 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,474 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,474 - ERROR - Failed to process question 38 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,474 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,475 - ERROR - Failed to process question 40 for story The_Pedestrian_Ray_Bradbury: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,475 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,477 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-02-02 20:37:11,479 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-02-02 20:37:11,482 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,482 - ERROR - Failed to process question 2 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,483 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,483 - ERROR - Failed to process question 4 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,484 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,484 - ERROR - Failed to process question 6 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,485 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,486 - ERROR - Failed to process question 8 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,487 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,487 - ERROR - Failed to process question 10 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,488 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,488 - ERROR - Failed to process question 12 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,489 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,489 - ERROR - Failed to process question 14 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,491 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,491 - ERROR - Failed to process question 16 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,491 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,492 - ERROR - Failed to process question 18 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,493 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,493 - ERROR - Failed to process question 20 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,494 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,494 - ERROR - Failed to process question 22 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,495 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,495 - ERROR - Failed to process question 24 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,496 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,496 - ERROR - Failed to process question 26 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,497 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,497 - ERROR - Failed to process question 28 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,498 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,498 - ERROR - Failed to process question 30 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,499 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,500 - ERROR - Failed to process question 32 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,501 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,501 - ERROR - Failed to process question 34 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,502 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,502 - ERROR - Failed to process question 36 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,503 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,503 - ERROR - Failed to process question 38 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,504 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,505 - ERROR - Failed to process question 40 for story The_People_who_Dug_for_Rain: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,505 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,507 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-02-02 20:37:11,509 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-02-02 20:37:11,511 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,511 - ERROR - Failed to process question 2 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,513 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,513 - ERROR - Failed to process question 4 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,514 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,514 - ERROR - Failed to process question 6 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,515 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,515 - ERROR - Failed to process question 8 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,517 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,517 - ERROR - Failed to process question 10 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,518 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,518 - ERROR - Failed to process question 12 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,519 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,519 - ERROR - Failed to process question 14 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,520 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,520 - ERROR - Failed to process question 16 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,522 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,522 - ERROR - Failed to process question 18 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,523 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,523 - ERROR - Failed to process question 20 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,524 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,524 - ERROR - Failed to process question 22 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,526 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,526 - ERROR - Failed to process question 24 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,527 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,527 - ERROR - Failed to process question 26 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,529 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,529 - ERROR - Failed to process question 28 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,530 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,530 - ERROR - Failed to process question 30 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,531 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,531 - ERROR - Failed to process question 32 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,532 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,532 - ERROR - Failed to process question 34 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,533 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,533 - ERROR - Failed to process question 36 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,535 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,535 - ERROR - Failed to process question 38 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,536 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,536 - ERROR - Failed to process question 40 for story The_Strangers_That_Came_to_Town_Ambrose_Flack: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,537 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,538 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-02-02 20:37:11,541 - INFO - Processing story: The_Stretcher
2026-02-02 20:37:11,543 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,543 - ERROR - Failed to process question 2 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,544 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,545 - ERROR - Failed to process question 4 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,545 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,546 - ERROR - Failed to process question 6 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,547 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,547 - ERROR - Failed to process question 8 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,548 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,548 - ERROR - Failed to process question 10 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,549 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,549 - ERROR - Failed to process question 12 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,550 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,550 - ERROR - Failed to process question 14 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,552 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,552 - ERROR - Failed to process question 16 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,553 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,553 - ERROR - Failed to process question 18 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,554 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,554 - ERROR - Failed to process question 20 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,555 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,555 - ERROR - Failed to process question 22 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,556 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,556 - ERROR - Failed to process question 24 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,557 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,557 - ERROR - Failed to process question 26 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,559 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,559 - ERROR - Failed to process question 28 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,559 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,560 - ERROR - Failed to process question 30 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,561 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,561 - ERROR - Failed to process question 32 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,562 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,562 - ERROR - Failed to process question 34 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,563 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,563 - ERROR - Failed to process question 36 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,565 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,565 - ERROR - Failed to process question 38 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,566 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,566 - ERROR - Failed to process question 40 for story The_Stretcher: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,566 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,568 - INFO - ✓ Saved: The_Stretcher.json
2026-02-02 20:37:11,571 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-02-02 20:37:11,573 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,573 - ERROR - Failed to process question 2 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,575 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,575 - ERROR - Failed to process question 4 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,576 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,576 - ERROR - Failed to process question 6 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,577 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,577 - ERROR - Failed to process question 8 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,578 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,578 - ERROR - Failed to process question 10 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,580 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,580 - ERROR - Failed to process question 12 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,581 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,581 - ERROR - Failed to process question 14 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,582 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,583 - ERROR - Failed to process question 16 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,583 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,584 - ERROR - Failed to process question 18 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,584 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,584 - ERROR - Failed to process question 20 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,586 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,586 - ERROR - Failed to process question 22 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,587 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,587 - ERROR - Failed to process question 24 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,588 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,588 - ERROR - Failed to process question 26 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,589 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,589 - ERROR - Failed to process question 28 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,590 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,590 - ERROR - Failed to process question 30 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,591 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,591 - ERROR - Failed to process question 32 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,592 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,593 - ERROR - Failed to process question 34 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,593 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,594 - ERROR - Failed to process question 36 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,595 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,595 - ERROR - Failed to process question 38 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,596 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,596 - ERROR - Failed to process question 40 for story The_village_that_Shared_the_Moonlight: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,596 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,598 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-02-02 20:37:11,600 - INFO - Processing story: War_of_the_Wall
2026-02-02 20:37:11,603 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,603 - ERROR - Failed to process question 2 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,604 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,604 - ERROR - Failed to process question 4 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,605 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,605 - ERROR - Failed to process question 6 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,606 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,606 - ERROR - Failed to process question 8 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,607 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,607 - ERROR - Failed to process question 10 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,609 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,609 - ERROR - Failed to process question 12 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,610 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,610 - ERROR - Failed to process question 14 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,611 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,611 - ERROR - Failed to process question 16 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,613 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,613 - ERROR - Failed to process question 18 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,614 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,614 - ERROR - Failed to process question 20 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,615 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,615 - ERROR - Failed to process question 22 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,616 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,617 - ERROR - Failed to process question 24 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,618 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,618 - ERROR - Failed to process question 26 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,619 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,619 - ERROR - Failed to process question 28 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,621 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,621 - ERROR - Failed to process question 30 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,622 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,622 - ERROR - Failed to process question 32 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,624 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,624 - ERROR - Failed to process question 34 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,625 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,625 - ERROR - Failed to process question 36 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,626 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,626 - ERROR - Failed to process question 38 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,628 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,628 - ERROR - Failed to process question 40 for story War_of_the_Wall: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,628 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,630 - INFO - ✓ Saved: War_of_the_Wall.json
2026-02-02 20:37:11,633 - INFO - Processing story: Warrior_Women_Nicaragua
2026-02-02 20:37:11,635 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,635 - ERROR - Failed to process question 2 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,637 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,637 - ERROR - Failed to process question 4 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,637 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,638 - ERROR - Failed to process question 6 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,639 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,639 - ERROR - Failed to process question 8 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,640 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,640 - ERROR - Failed to process question 10 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,641 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,641 - ERROR - Failed to process question 12 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,642 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,642 - ERROR - Failed to process question 14 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,644 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,644 - ERROR - Failed to process question 16 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,645 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,645 - ERROR - Failed to process question 18 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,646 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,646 - ERROR - Failed to process question 20 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,647 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,647 - ERROR - Failed to process question 22 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,648 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,648 - ERROR - Failed to process question 24 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,649 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,649 - ERROR - Failed to process question 26 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,651 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,651 - ERROR - Failed to process question 28 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,652 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,652 - ERROR - Failed to process question 30 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,653 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,653 - ERROR - Failed to process question 32 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,654 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,654 - ERROR - Failed to process question 34 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,655 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,655 - ERROR - Failed to process question 36 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,657 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,657 - ERROR - Failed to process question 38 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,658 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,658 - ERROR - Failed to process question 40 for story Warrior_Women_Nicaragua: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,658 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,660 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-02-02 20:37:11,663 - INFO - Processing story: We_Stand_Up
2026-02-02 20:37:11,665 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,665 - ERROR - Failed to process question 2 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,666 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,667 - ERROR - Failed to process question 4 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,667 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,667 - ERROR - Failed to process question 6 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,669 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,669 - ERROR - Failed to process question 8 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,670 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,670 - ERROR - Failed to process question 10 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,671 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,671 - ERROR - Failed to process question 12 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,672 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,672 - ERROR - Failed to process question 14 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,673 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,673 - ERROR - Failed to process question 16 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,674 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,674 - ERROR - Failed to process question 18 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,675 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,675 - ERROR - Failed to process question 20 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,676 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,676 - ERROR - Failed to process question 22 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,678 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,678 - ERROR - Failed to process question 24 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,679 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,679 - ERROR - Failed to process question 26 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,680 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,680 - ERROR - Failed to process question 28 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,681 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,681 - ERROR - Failed to process question 30 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,682 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,682 - ERROR - Failed to process question 32 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,684 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,684 - ERROR - Failed to process question 34 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,685 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,685 - ERROR - Failed to process question 36 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,686 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,686 - ERROR - Failed to process question 38 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,687 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,687 - ERROR - Failed to process question 40 for story We_Stand_Up: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,687 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,689 - INFO - ✓ Saved: We_Stand_Up.json
2026-02-02 20:37:11,691 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-02-02 20:37:11,693 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,693 - ERROR - Failed to process question 2 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,695 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,695 - ERROR - Failed to process question 4 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,696 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,696 - ERROR - Failed to process question 6 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,697 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,697 - ERROR - Failed to process question 8 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,699 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,699 - ERROR - Failed to process question 10 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,700 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,700 - ERROR - Failed to process question 12 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,701 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,702 - ERROR - Failed to process question 14 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,702 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,702 - ERROR - Failed to process question 16 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,704 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,704 - ERROR - Failed to process question 18 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,705 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,705 - ERROR - Failed to process question 20 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,706 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,706 - ERROR - Failed to process question 22 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,707 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,707 - ERROR - Failed to process question 24 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,708 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,709 - ERROR - Failed to process question 26 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,709 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,709 - ERROR - Failed to process question 28 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,711 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,711 - ERROR - Failed to process question 30 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,712 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,712 - ERROR - Failed to process question 32 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,713 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,713 - ERROR - Failed to process question 34 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,714 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,714 - ERROR - Failed to process question 36 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,716 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,716 - ERROR - Failed to process question 38 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,717 - ERROR - Unexpected error calling LLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,717 - ERROR - Failed to process question 40 for story Whose_Voice_We_Wanted_to_Hear: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=meta-llama/Llama-3.1-8B-Instruct
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-02 20:37:11,717 - WARNING - No pricing found for model meta-llama/Llama-3.1-8B-Instruct, using default
2026-02-02 20:37:11,719 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-02-02 20:37:11,724 - INFO - 
============================================================
2026-02-02 20:37:11,724 - INFO - Survey complete!
2026-02-02 20:37:11,725 - INFO - Processed: 28/28 stories
2026-02-02 20:37:11,725 - INFO - Failed: 0 stories
2026-02-02 20:37:11,725 - INFO - Total cost: $0.0000
2026-02-02 20:37:11,725 - INFO - Total tokens: 0
2026-02-02 20:37:11,725 - INFO - ============================================================

2026-02-02 20:37:11,725 - INFO - 
============================================================
2026-02-02 20:37:11,725 - INFO - Step 4: Learning PyReason Rules
2026-02-02 20:37:11,725 - INFO - ============================================================
2026-02-02 20:37:11,726 - INFO - ============================================================
2026-02-02 20:37:11,726 - INFO - RULE LEARNING
2026-02-02 20:37:11,726 - INFO - ============================================================
2026-02-02 20:37:11,726 - INFO - Loading survey results from: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/survey_results
2026-02-02 20:37:11,728 - INFO - Found 28 survey result files
2026-02-02 20:37:11,750 - INFO - Successfully loaded 28 survey results
2026-02-02 20:37:11,750 - INFO - Extracting feature scores...
2026-02-02 20:37:11,751 - WARNING - No rating found for Protagonist‑Centered Focus in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Internal Goals in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Decision‑Driven Plot in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Self‑Reliance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Individual Accolades in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Meritocracy Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for “Man vs. Self/World” Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Solo Confrontations in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Inner Journey in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Self‑Actualization Climax in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Personal Ethics over Group Norms in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Uniqueness & Self‑Expression in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Self‑Construal in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,752 - WARNING - No rating found for Behavioral Guidance in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Relationship Orientation in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Primary Conflict in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Resolution Style in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Moral Emphasis in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Relationship Framing in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Vertical Individualism in story A_Piece_of_Yellow_Soap, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Protagonist‑Centered Focus in story About_a_Hum, skipping
2026-02-02 20:37:11,753 - WARNING - No rating found for Internal Goals in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Decision‑Driven Plot in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Self‑Reliance in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Individual Accolades in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Meritocracy Emphasis in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for “Man vs. Self/World” Conflict in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Solo Confrontations in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Inner Journey in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Self‑Actualization Climax in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Personal Ethics over Group Norms in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Uniqueness & Self‑Expression in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Self‑Construal in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Behavioral Guidance in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Relationship Orientation in story About_a_Hum, skipping
2026-02-02 20:37:11,754 - WARNING - No rating found for Primary Conflict in story About_a_Hum, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Resolution Style in story About_a_Hum, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Moral Emphasis in story About_a_Hum, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Relationship Framing in story About_a_Hum, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Vertical Individualism in story About_a_Hum, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Protagonist‑Centered Focus in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Internal Goals in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Decision‑Driven Plot in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Self‑Reliance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Individual Accolades in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Meritocracy Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for “Man vs. Self/World” Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,755 - WARNING - No rating found for Solo Confrontations in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Inner Journey in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Self‑Actualization Climax in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Personal Ethics over Group Norms in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Uniqueness & Self‑Expression in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Self‑Construal in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Behavioral Guidance in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Relationship Orientation in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,756 - WARNING - No rating found for Primary Conflict in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Resolution Style in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Moral Emphasis in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Relationship Framing in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Vertical Individualism in story All_Summer_in_a_Day_Ray_Bradbury, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Protagonist‑Centered Focus in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Internal Goals in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Decision‑Driven Plot in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Self‑Reliance in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Individual Accolades in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Meritocracy Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Solo Confrontations in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Inner Journey in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,757 - WARNING - No rating found for Self‑Actualization Climax in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Personal Ethics over Group Norms in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Uniqueness & Self‑Expression in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Self‑Construal in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Behavioral Guidance in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Relationship Orientation in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Primary Conflict in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Resolution Style in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,758 - WARNING - No rating found for Moral Emphasis in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Relationship Framing in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Vertical Individualism in story Back_To_The_Wall, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Protagonist‑Centered Focus in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Internal Goals in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Decision‑Driven Plot in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Self‑Reliance in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Individual Accolades in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Meritocracy Emphasis in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Solo Confrontations in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Inner Journey in story Community_Time, skipping
2026-02-02 20:37:11,759 - WARNING - No rating found for Self‑Actualization Climax in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Personal Ethics over Group Norms in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Uniqueness & Self‑Expression in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Self‑Construal in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Behavioral Guidance in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Relationship Orientation in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Primary Conflict in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Resolution Style in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Moral Emphasis in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Relationship Framing in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Vertical Individualism in story Community_Time, skipping
2026-02-02 20:37:11,760 - WARNING - No rating found for Protagonist‑Centered Focus in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Internal Goals in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Decision‑Driven Plot in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Self‑Reliance in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Individual Accolades in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Meritocracy Emphasis in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Solo Confrontations in story Fleabags, skipping
2026-02-02 20:37:11,761 - WARNING - No rating found for Inner Journey in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Self‑Actualization Climax in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Personal Ethics over Group Norms in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Uniqueness & Self‑Expression in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Self‑Construal in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Behavioral Guidance in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Relationship Orientation in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Primary Conflict in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Resolution Style in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Moral Emphasis in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Relationship Framing in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Vertical Individualism in story Fleabags, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Protagonist‑Centered Focus in story Gravity_Reduced, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Internal Goals in story Gravity_Reduced, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Decision‑Driven Plot in story Gravity_Reduced, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Self‑Reliance in story Gravity_Reduced, skipping
2026-02-02 20:37:11,762 - WARNING - No rating found for Individual Accolades in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Meritocracy Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Solo Confrontations in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Inner Journey in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Self‑Actualization Climax in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Personal Ethics over Group Norms in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Uniqueness & Self‑Expression in story Gravity_Reduced, skipping
2026-02-02 20:37:11,763 - WARNING - No rating found for Self‑Construal in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Behavioral Guidance in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Relationship Orientation in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Primary Conflict in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Resolution Style in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Moral Emphasis in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Relationship Framing in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Vertical Individualism in story Gravity_Reduced, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Protagonist‑Centered Focus in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Internal Goals in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Decision‑Driven Plot in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,764 - WARNING - No rating found for Self‑Reliance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Individual Accolades in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Meritocracy Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Solo Confrontations in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Inner Journey in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Self‑Actualization Climax in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Personal Ethics over Group Norms in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Uniqueness & Self‑Expression in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Self‑Construal in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Behavioral Guidance in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Relationship Orientation in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,765 - WARNING - No rating found for Primary Conflict in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Resolution Style in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Moral Emphasis in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Relationship Framing in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Vertical Individualism in story Harrison_Bergeron_Kurt_Vonnegut, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Protagonist‑Centered Focus in story Honeybee, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Internal Goals in story Honeybee, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Decision‑Driven Plot in story Honeybee, skipping
2026-02-02 20:37:11,766 - WARNING - No rating found for Self‑Reliance in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Individual Accolades in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Meritocracy Emphasis in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Solo Confrontations in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Inner Journey in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Self‑Actualization Climax in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Personal Ethics over Group Norms in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Uniqueness & Self‑Expression in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Self‑Construal in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Behavioral Guidance in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Relationship Orientation in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Primary Conflict in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Resolution Style in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Moral Emphasis in story Honeybee, skipping
2026-02-02 20:37:11,767 - WARNING - No rating found for Relationship Framing in story Honeybee, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Vertical Individualism in story Honeybee, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Protagonist‑Centered Focus in story Last_Long_Night, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Internal Goals in story Last_Long_Night, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Decision‑Driven Plot in story Last_Long_Night, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Self‑Reliance in story Last_Long_Night, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Individual Accolades in story Last_Long_Night, skipping
2026-02-02 20:37:11,768 - WARNING - No rating found for Meritocracy Emphasis in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Solo Confrontations in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Inner Journey in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Self‑Actualization Climax in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Personal Ethics over Group Norms in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Uniqueness & Self‑Expression in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Self‑Construal in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Behavioral Guidance in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Relationship Orientation in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Primary Conflict in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Resolution Style in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Moral Emphasis in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Relationship Framing in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Vertical Individualism in story Last_Long_Night, skipping
2026-02-02 20:37:11,769 - WARNING - No rating found for Protagonist‑Centered Focus in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Internal Goals in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Decision‑Driven Plot in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Self‑Reliance in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Individual Accolades in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Meritocracy Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Solo Confrontations in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Inner Journey in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Self‑Actualization Climax in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Personal Ethics over Group Norms in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Uniqueness & Self‑Expression in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,770 - WARNING - No rating found for Self‑Construal in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Behavioral Guidance in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Relationship Orientation in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Primary Conflict in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Resolution Style in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Moral Emphasis in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Relationship Framing in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Vertical Individualism in story Raindrop_Snowflake, skipping
2026-02-02 20:37:11,771 - WARNING - No rating found for Protagonist‑Centered Focus in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Internal Goals in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Decision‑Driven Plot in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Self‑Reliance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Individual Accolades in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Meritocracy Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Solo Confrontations in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Inner Journey in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Self‑Actualization Climax in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Personal Ethics over Group Norms in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Uniqueness & Self‑Expression in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Self‑Construal in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Behavioral Guidance in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,772 - WARNING - No rating found for Relationship Orientation in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Primary Conflict in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Resolution Style in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Moral Emphasis in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Relationship Framing in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Vertical Individualism in story Redemption_of_the_Cursed_Village, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Protagonist‑Centered Focus in story Rice, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Internal Goals in story Rice, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Decision‑Driven Plot in story Rice, skipping
2026-02-02 20:37:11,773 - WARNING - No rating found for Self‑Reliance in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Individual Accolades in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Meritocracy Emphasis in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Solo Confrontations in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Inner Journey in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Self‑Actualization Climax in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Personal Ethics over Group Norms in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Uniqueness & Self‑Expression in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Self‑Construal in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Behavioral Guidance in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Relationship Orientation in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Primary Conflict in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Resolution Style in story Rice, skipping
2026-02-02 20:37:11,774 - WARNING - No rating found for Moral Emphasis in story Rice, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Relationship Framing in story Rice, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Vertical Individualism in story Rice, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Protagonist‑Centered Focus in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Internal Goals in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Decision‑Driven Plot in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Self‑Reliance in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Individual Accolades in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Meritocracy Emphasis in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Solo Confrontations in story Swallowed, skipping
2026-02-02 20:37:11,775 - WARNING - No rating found for Inner Journey in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Self‑Actualization Climax in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Personal Ethics over Group Norms in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Uniqueness & Self‑Expression in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Self‑Construal in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Behavioral Guidance in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Relationship Orientation in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Primary Conflict in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Resolution Style in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Moral Emphasis in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Relationship Framing in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Vertical Individualism in story Swallowed, skipping
2026-02-02 20:37:11,776 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Internal Goals in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Decision‑Driven Plot in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Self‑Reliance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Individual Accolades in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Meritocracy Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Solo Confrontations in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Inner Journey in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Self‑Actualization Climax in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,777 - WARNING - No rating found for Self‑Construal in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Behavioral Guidance in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Relationship Orientation in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Primary Conflict in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Resolution Style in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Moral Emphasis in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Relationship Framing in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Vertical Individualism in story The_Ants_and_The_Locusts, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Internal Goals in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Decision‑Driven Plot in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Self‑Reliance in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Individual Accolades in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,778 - WARNING - No rating found for Meritocracy Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Solo Confrontations in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Inner Journey in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Self‑Actualization Climax in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Self‑Construal in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Behavioral Guidance in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Relationship Orientation in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Primary Conflict in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Resolution Style in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Moral Emphasis in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Relationship Framing in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Vertical Individualism in story The_Christmas_Monks, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Circuit, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Internal Goals in story The_Circuit, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Decision‑Driven Plot in story The_Circuit, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Self‑Reliance in story The_Circuit, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Individual Accolades in story The_Circuit, skipping
2026-02-02 20:37:11,779 - WARNING - No rating found for Meritocracy Emphasis in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Solo Confrontations in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Inner Journey in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Self‑Actualization Climax in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Circuit, skipping
2026-02-02 20:37:11,780 - WARNING - No rating found for Self‑Construal in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Behavioral Guidance in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Relationship Orientation in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Primary Conflict in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Resolution Style in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Moral Emphasis in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Relationship Framing in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Vertical Individualism in story The_Circuit, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Internal Goals in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Decision‑Driven Plot in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Self‑Reliance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Individual Accolades in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for Meritocracy Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,781 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Solo Confrontations in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Inner Journey in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Self‑Actualization Climax in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Self‑Construal in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Behavioral Guidance in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Relationship Orientation in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Primary Conflict in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Resolution Style in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,782 - WARNING - No rating found for Moral Emphasis in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Relationship Framing in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Vertical Individualism in story The_Fire_That_Fed_the_People, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Internal Goals in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Decision‑Driven Plot in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Self‑Reliance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Individual Accolades in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Meritocracy Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Solo Confrontations in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,783 - WARNING - No rating found for Inner Journey in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Self‑Actualization Climax in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Self‑Construal in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Behavioral Guidance in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Relationship Orientation in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Primary Conflict in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Resolution Style in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Moral Emphasis in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Relationship Framing in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,784 - WARNING - No rating found for Vertical Individualism in story The_Gentleman_of_the_Jungle, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Internal Goals in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Decision‑Driven Plot in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Self‑Reliance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Individual Accolades in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Meritocracy Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Solo Confrontations in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Inner Journey in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Self‑Actualization Climax in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Self‑Construal in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,785 - WARNING - No rating found for Behavioral Guidance in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Relationship Orientation in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Primary Conflict in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Resolution Style in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Moral Emphasis in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Relationship Framing in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Vertical Individualism in story The_Pedestrian_Ray_Bradbury, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Protagonist‑Centered Focus in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Internal Goals in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,786 - WARNING - No rating found for Decision‑Driven Plot in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Self‑Reliance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Individual Accolades in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Meritocracy Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Solo Confrontations in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Inner Journey in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Self‑Actualization Climax in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Personal Ethics over Group Norms in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,787 - WARNING - No rating found for Self‑Construal in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Behavioral Guidance in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Relationship Orientation in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Primary Conflict in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Resolution Style in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Moral Emphasis in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Relationship Framing in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Vertical Individualism in story The_People_who_Dug_for_Rain, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Internal Goals in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Decision‑Driven Plot in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Self‑Reliance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Individual Accolades in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Meritocracy Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,788 - WARNING - No rating found for Solo Confrontations in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Inner Journey in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Self‑Actualization Climax in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Self‑Construal in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Behavioral Guidance in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Relationship Orientation in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,789 - WARNING - No rating found for Primary Conflict in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Resolution Style in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Moral Emphasis in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Relationship Framing in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Vertical Individualism in story The_Strangers_That_Came_to_Town_Ambrose_Flack, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Protagonist‑Centered Focus in story The_Stretcher, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Internal Goals in story The_Stretcher, skipping
2026-02-02 20:37:11,790 - WARNING - No rating found for Decision‑Driven Plot in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Self‑Reliance in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Individual Accolades in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Meritocracy Emphasis in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Solo Confrontations in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Inner Journey in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Self‑Actualization Climax in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Personal Ethics over Group Norms in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Self‑Construal in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Behavioral Guidance in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Relationship Orientation in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Primary Conflict in story The_Stretcher, skipping
2026-02-02 20:37:11,791 - WARNING - No rating found for Resolution Style in story The_Stretcher, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Moral Emphasis in story The_Stretcher, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Relationship Framing in story The_Stretcher, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Vertical Individualism in story The_Stretcher, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Protagonist‑Centered Focus in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Internal Goals in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Decision‑Driven Plot in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,792 - WARNING - No rating found for Self‑Reliance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Individual Accolades in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Meritocracy Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for “Man vs. Self/World” Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Solo Confrontations in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Inner Journey in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Self‑Actualization Climax in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Personal Ethics over Group Norms in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Uniqueness & Self‑Expression in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Self‑Construal in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Behavioral Guidance in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Relationship Orientation in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Primary Conflict in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Resolution Style in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,793 - WARNING - No rating found for Moral Emphasis in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Relationship Framing in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Vertical Individualism in story The_village_that_Shared_the_Moonlight, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Protagonist‑Centered Focus in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Internal Goals in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Decision‑Driven Plot in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Self‑Reliance in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Individual Accolades in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for Meritocracy Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:37:11,794 - WARNING - No rating found for “Man vs. Self/World” Conflict in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Solo Confrontations in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Inner Journey in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Self‑Actualization Climax in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Personal Ethics over Group Norms in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Uniqueness & Self‑Expression in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Self‑Construal in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Behavioral Guidance in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Relationship Orientation in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Primary Conflict in story War_of_the_Wall, skipping
2026-02-02 20:37:11,795 - WARNING - No rating found for Resolution Style in story War_of_the_Wall, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Moral Emphasis in story War_of_the_Wall, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Relationship Framing in story War_of_the_Wall, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Vertical Individualism in story War_of_the_Wall, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Protagonist‑Centered Focus in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Internal Goals in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Decision‑Driven Plot in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Self‑Reliance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Individual Accolades in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Meritocracy Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Solo Confrontations in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Inner Journey in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,796 - WARNING - No rating found for Self‑Actualization Climax in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Personal Ethics over Group Norms in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Uniqueness & Self‑Expression in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Self‑Construal in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Behavioral Guidance in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Relationship Orientation in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Primary Conflict in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Resolution Style in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Moral Emphasis in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,797 - WARNING - No rating found for Relationship Framing in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Vertical Individualism in story Warrior_Women_Nicaragua, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Protagonist‑Centered Focus in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Internal Goals in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Decision‑Driven Plot in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Self‑Reliance in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Individual Accolades in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Meritocracy Emphasis in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for “Man vs. Self/World” Conflict in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Solo Confrontations in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Inner Journey in story We_Stand_Up, skipping
2026-02-02 20:37:11,798 - WARNING - No rating found for Self‑Actualization Climax in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Personal Ethics over Group Norms in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Uniqueness & Self‑Expression in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Self‑Construal in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Behavioral Guidance in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Relationship Orientation in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Primary Conflict in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Resolution Style in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Moral Emphasis in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Relationship Framing in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Vertical Individualism in story We_Stand_Up, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Protagonist‑Centered Focus in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,799 - WARNING - No rating found for Internal Goals in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Decision‑Driven Plot in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Self‑Reliance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Individual Accolades in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Meritocracy Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for “Man vs. Self/World” Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Solo Confrontations in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,800 - WARNING - No rating found for Inner Journey in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Self‑Actualization Climax in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Personal Ethics over Group Norms in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Uniqueness & Self‑Expression in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Self‑Construal in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Behavioral Guidance in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Relationship Orientation in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Primary Conflict in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Resolution Style in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Moral Emphasis in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,801 - WARNING - No rating found for Relationship Framing in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,802 - WARNING - No rating found for Vertical Individualism in story Whose_Voice_We_Wanted_to_Hear, skipping
2026-02-02 20:37:11,802 - INFO - Extracted scores for 28 stories and 0 features
2026-02-02 20:37:11,802 - INFO - Learning PyReason rules...
2026-02-02 20:37:11,802 - INFO - Configuration:
2026-02-02 20:37:11,802 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-02-02 20:37:11,802 - INFO -   - Min confidence: 0.0
2026-02-02 20:37:11,802 - INFO -   - Min support: 0
2026-02-02 20:37:11,802 - INFO - Learning rules for 0 features...
2026-02-02 20:37:11,802 - INFO - Learned 0 rules
2026-02-02 20:37:11,804 - INFO - Saved 0 rules to output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:37:11,804 - INFO - ============================================================
2026-02-02 20:37:11,805 - INFO - RULE LEARNING COMPLETE
2026-02-02 20:37:11,805 - INFO - ============================================================
2026-02-02 20:37:11,805 - INFO - Stories processed: 28
2026-02-02 20:37:11,805 - INFO - Features: 0
2026-02-02 20:37:11,805 - INFO - Rules learned: 0
2026-02-02 20:37:11,805 - INFO - Rules saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:37:11,805 - INFO - ============================================================
2026-02-02 20:37:11,805 - INFO - 
✓ Rules learned and saved to: output/phase1/meta-llama-Llama-3.1-8B-Instruct/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:37:11,805 - INFO - 
Phase 1 completed successfully!
2026-02-02 20:37:11,806 - INFO - Output directory: output/phase1
2026-02-02 20:37:11,806 - INFO - ============================================================
2026-02-02 20:37:11,806 - INFO - Execution completed successfully!
2026-02-02 20:37:11,806 - INFO - ============================================================
2026-02-02 20:38:57,184 - INFO - ============================================================
2026-02-02 20:38:57,184 - INFO - CONNECT Project - Phase 1
2026-02-02 20:38:57,184 - INFO - Problem: inverse
2026-02-02 20:38:57,184 - INFO - ============================================================
2026-02-02 20:38:57,184 - INFO - 
============================================================
2026-02-02 20:38:57,184 - INFO - PHASE 1: TRAINING
2026-02-02 20:38:57,184 - INFO - ============================================================
2026-02-02 20:38:57,184 - INFO - Loading collectivistic stories for inverse problem
2026-02-02 20:38:57,185 - INFO - Found 28 story files in data/collectivistic-stories-all
2026-02-02 20:38:57,205 - INFO - Successfully loaded 28 stories
2026-02-02 20:38:57,206 - INFO - Loaded 28 training stories
2026-02-02 20:38:57,209 - INFO - Survey results will be saved to: output/phase1/bedrock-meta.llama3-1-8b-instruct-v1-0/inverse/survey_results
2026-02-02 20:38:57,213 - INFO - Processing story: A_Piece_of_Yellow_Soap
2026-02-02 20:38:57,239 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:38:58,213 - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2026-02-02 20:38:59,142 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:38:59,147 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:38:59,817 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:38:59,819 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:00,591 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:00,594 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:01,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:01,468 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:02,284 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:02,286 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:03,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:03,032 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:03,829 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:03,831 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:04,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:04,513 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:05,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:05,231 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:06,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:06,031 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:06,706 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:06,708 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:07,463 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:07,465 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:07,992 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:07,994 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:08,741 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:08,743 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:09,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:09,321 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:10,132 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:10,135 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:10,869 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:10,871 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:11,568 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:11,570 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:12,150 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:12,152 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:12,755 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:12,756 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:39:12,760 - INFO - ✓ Saved: A_Piece_of_Yellow_Soap.json
2026-02-02 20:39:12,762 - INFO - Processing story: About_a_Hum
2026-02-02 20:39:12,765 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:13,925 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:13,927 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:14,896 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:14,898 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:15,744 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:15,746 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:16,361 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:16,363 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:17,440 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:17,442 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:18,293 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:18,295 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:18,936 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:18,938 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:19,663 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:19,665 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:20,388 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:20,391 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:21,169 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:21,171 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:21,930 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:21,932 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:22,433 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:22,435 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:23,164 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:23,166 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:23,921 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:23,923 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:24,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:24,528 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:25,186 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:25,188 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:25,644 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:25,646 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:26,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:26,467 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:27,199 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:27,201 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:27,854 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:27,855 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:39:27,858 - INFO - ✓ Saved: About_a_Hum.json
2026-02-02 20:39:27,861 - INFO - Processing story: All_Summer_in_a_Day_Ray_Bradbury
2026-02-02 20:39:27,864 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:29,784 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:29,786 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:31,401 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:31,403 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:32,733 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:32,735 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:35,026 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:35,028 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:36,675 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:36,678 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:38,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:38,043 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:42,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:42,681 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:43,594 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:43,596 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:44,737 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:44,739 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:46,365 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:46,367 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:47,618 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:47,620 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:49,313 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:49,316 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:51,174 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:51,177 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:52,991 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:52,994 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:54,008 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:54,010 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:55,174 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:55,177 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:56,152 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:56,155 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:57,445 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:57,447 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:58,861 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:58,864 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:39:59,874 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:39:59,875 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:39:59,879 - INFO - ✓ Saved: All_Summer_in_a_Day_Ray_Bradbury.json
2026-02-02 20:39:59,881 - INFO - Processing story: Back_To_The_Wall
2026-02-02 20:39:59,884 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:00,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:00,500 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:01,031 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:01,033 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:01,614 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:01,616 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:02,245 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:02,247 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:02,825 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:02,828 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:03,458 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:03,460 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:04,077 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:04,079 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:04,780 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:04,782 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:05,515 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:05,517 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:06,195 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:06,197 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:06,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:06,866 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:07,357 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:07,359 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:08,013 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:08,015 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:08,621 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:08,623 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:09,276 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:09,278 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:09,891 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:09,893 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:10,442 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:10,444 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:10,984 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:10,986 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:11,482 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:11,484 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:12,142 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:12,143 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:40:12,146 - INFO - ✓ Saved: Back_To_The_Wall.json
2026-02-02 20:40:12,149 - INFO - Processing story: Community_Time
2026-02-02 20:40:12,151 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:12,994 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:12,996 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:13,753 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:13,755 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:14,333 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:14,335 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:15,041 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:15,043 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:15,565 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:15,567 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:16,388 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:16,390 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:17,382 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:17,384 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:18,220 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:18,222 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:18,802 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:18,805 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:19,510 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:19,512 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:20,376 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:20,378 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:21,343 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:21,345 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:22,087 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:22,089 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:22,967 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:22,969 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:23,864 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:23,867 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:24,806 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:24,808 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:25,423 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:25,425 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:26,581 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:26,583 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:27,536 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:27,538 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:28,365 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:28,366 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:40:28,370 - INFO - ✓ Saved: Community_Time.json
2026-02-02 20:40:28,373 - INFO - Processing story: Fleabags
2026-02-02 20:40:28,375 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:29,026 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:29,028 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:29,627 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:29,629 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:30,266 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:30,269 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:30,764 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:30,766 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:31,462 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:31,464 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:32,247 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:32,249 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:32,909 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:32,911 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:33,552 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:33,554 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:34,183 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:34,185 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:34,689 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:34,691 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:35,300 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:35,302 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:36,411 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:36,413 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:37,057 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:37,059 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:37,684 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:37,686 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:38,194 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:38,196 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:38,775 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:38,777 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:39,612 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:39,614 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:40,460 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:40,462 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:41,141 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:41,143 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:41,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:41,930 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:40:41,934 - INFO - ✓ Saved: Fleabags.json
2026-02-02 20:40:41,937 - INFO - Processing story: Gravity_Reduced
2026-02-02 20:40:41,939 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:42,746 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:42,748 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:43,570 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:43,572 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:44,431 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:44,433 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:45,284 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:45,286 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:46,179 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:46,181 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:47,288 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:47,290 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:47,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:47,963 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:48,825 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:48,827 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:49,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:49,724 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:50,582 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:50,584 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:51,376 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:51,378 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:52,244 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:52,246 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:53,095 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:53,097 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:53,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:53,927 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:54,711 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:54,713 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:55,467 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:55,469 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:56,077 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:56,079 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:56,790 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:56,792 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:58,186 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:58,188 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:40:58,989 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:40:58,990 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:40:58,994 - INFO - ✓ Saved: Gravity_Reduced.json
2026-02-02 20:40:58,996 - INFO - Processing story: Harrison_Bergeron_Kurt_Vonnegut
2026-02-02 20:40:58,999 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:00,252 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:00,254 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:01,204 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:01,206 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:02,360 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:02,362 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:04,407 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:04,409 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:05,743 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:05,745 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:06,617 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:06,619 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:07,557 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:07,559 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:08,715 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:08,717 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:09,917 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:09,919 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:10,753 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:10,755 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:12,049 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:12,051 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:18,745 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:18,747 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:20,758 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:20,760 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:22,214 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:22,216 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:23,770 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:23,772 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:24,923 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:24,925 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:26,233 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:26,235 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:27,281 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:27,284 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:28,504 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:28,506 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:29,542 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:29,543 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:41:29,548 - INFO - ✓ Saved: Harrison_Bergeron_Kurt_Vonnegut.json
2026-02-02 20:41:29,580 - INFO - Processing story: Honeybee
2026-02-02 20:41:29,584 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:30,258 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:30,260 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:31,444 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:31,446 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:32,036 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:32,038 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:32,875 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:32,877 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:33,578 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:33,580 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:34,466 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:34,468 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:35,438 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:35,440 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:36,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:36,132 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:37,099 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:37,101 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:38,199 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:38,201 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:39,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:39,087 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:39,681 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:39,684 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:40,529 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:40,531 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:41,053 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:41,055 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:41,770 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:41,772 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:42,921 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:42,923 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:43,908 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:43,910 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:44,931 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:44,933 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:45,522 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:45,524 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:46,170 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:46,171 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:41:46,175 - INFO - ✓ Saved: Honeybee.json
2026-02-02 20:41:46,178 - INFO - Processing story: Last_Long_Night
2026-02-02 20:41:46,180 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:47,030 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:47,032 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:47,821 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:47,823 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:48,531 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:48,534 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:49,396 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:49,398 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:50,224 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:50,226 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:51,183 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:51,185 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:51,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:51,963 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:52,656 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:52,658 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:53,534 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:53,536 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:54,226 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:54,228 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:54,905 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:54,907 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:55,781 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:55,783 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:56,620 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:56,622 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:57,417 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:57,419 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:58,254 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:58,256 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:59,124 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:59,126 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:41:59,941 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:41:59,943 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:00,785 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:00,787 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:01,862 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:01,864 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:03,045 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:03,046 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:42:03,049 - INFO - ✓ Saved: Last_Long_Night.json
2026-02-02 20:42:03,052 - INFO - Processing story: Raindrop_Snowflake
2026-02-02 20:42:03,055 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:03,645 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:03,647 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:04,170 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:04,172 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:05,024 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:05,026 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:05,612 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:05,615 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:06,089 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:06,091 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:06,726 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:06,728 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:07,253 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:07,255 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:07,871 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:07,874 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:08,451 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:08,454 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:09,133 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:09,135 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:09,643 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:09,645 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:10,268 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:10,270 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:10,982 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:10,984 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:11,530 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:11,532 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:12,093 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:12,095 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:12,663 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:12,665 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:13,250 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:13,252 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:13,797 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:13,798 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:14,307 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:14,309 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:14,787 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:14,788 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:42:14,792 - INFO - ✓ Saved: Raindrop_Snowflake.json
2026-02-02 20:42:14,794 - INFO - Processing story: Redemption_of_the_Cursed_Village
2026-02-02 20:42:14,797 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:15,484 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:15,486 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:16,038 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:16,040 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:16,535 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:16,537 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:17,097 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:17,100 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:17,726 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:17,728 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:18,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:18,320 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:19,067 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:19,069 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:19,746 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:19,748 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:20,312 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:20,314 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:20,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:20,964 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:21,483 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:21,485 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:22,098 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:22,100 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:22,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:22,680 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:23,312 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:23,314 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:24,077 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:24,079 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:24,649 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:24,651 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:25,121 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:25,123 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:25,735 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:25,737 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:26,412 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:26,414 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:27,111 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:27,112 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:42:27,116 - INFO - ✓ Saved: Redemption_of_the_Cursed_Village.json
2026-02-02 20:42:27,118 - INFO - Processing story: Rice
2026-02-02 20:42:27,121 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:28,476 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:28,478 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:29,507 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:29,510 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:30,878 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:30,880 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:33,156 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:33,158 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:34,203 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:34,205 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:35,574 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:35,576 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:37,326 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:37,328 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:38,460 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:38,462 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:39,723 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:39,725 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:41,517 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:41,519 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:43,344 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:43,346 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:45,361 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:45,363 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:47,815 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:47,817 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:49,071 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:49,073 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:50,875 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:50,877 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:51,855 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:51,858 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:53,303 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:53,305 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:54,407 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:54,409 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:55,318 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:55,320 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:56,965 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:56,966 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:42:56,970 - INFO - ✓ Saved: Rice.json
2026-02-02 20:42:58,095 - INFO - Processing story: Swallowed
2026-02-02 20:42:58,098 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:58,621 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:58,623 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:59,192 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:59,194 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:42:59,847 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:42:59,849 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:00,465 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:00,468 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:01,057 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:01,059 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:01,692 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:01,694 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:02,289 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:02,291 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:03,072 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:03,075 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:03,756 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:03,758 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:04,456 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:04,458 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:05,160 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:05,163 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:05,771 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:05,774 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:06,315 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:06,317 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:06,778 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:06,780 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:07,347 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:07,349 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:07,948 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:07,951 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:08,458 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:08,460 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:09,005 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:09,007 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:09,702 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:09,704 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:10,426 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:10,427 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:43:10,431 - INFO - ✓ Saved: Swallowed.json
2026-02-02 20:43:10,434 - INFO - Processing story: The_Ants_and_The_Locusts
2026-02-02 20:43:10,436 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:11,079 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:11,081 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:11,635 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:11,637 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:12,228 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:12,230 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:12,834 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:12,836 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:13,485 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:13,487 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:14,005 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:14,007 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:14,497 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:14,500 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:15,116 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:15,118 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:15,661 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:15,663 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:16,137 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:16,139 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:16,647 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:16,649 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:17,215 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:17,218 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:17,847 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:17,849 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:18,448 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:18,450 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:19,010 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:19,012 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:19,928 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:19,931 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:20,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:20,610 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:21,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:21,087 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:21,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:21,529 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:22,167 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:22,167 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:43:22,171 - INFO - ✓ Saved: The_Ants_and_The_Locusts.json
2026-02-02 20:43:22,174 - INFO - Processing story: The_Christmas_Monks
2026-02-02 20:43:22,177 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:24,327 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:24,329 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:25,469 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:25,471 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:26,834 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:26,836 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:28,527 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:28,529 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:29,678 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:29,680 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:30,924 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:30,926 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:32,358 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:32,360 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:34,109 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:34,111 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:35,521 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:35,523 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:37,127 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:37,130 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:39,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:39,031 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:40,485 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:40,487 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:42,440 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:42,442 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:44,044 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:44,046 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:45,153 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:45,156 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:46,610 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:46,612 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:48,548 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:48,550 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:50,704 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:50,706 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:52,592 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:52,594 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:54,022 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:54,023 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:43:54,027 - INFO - ✓ Saved: The_Christmas_Monks.json
2026-02-02 20:43:54,031 - INFO - Processing story: The_Circuit
2026-02-02 20:43:54,033 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:55,429 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:55,431 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:57,145 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:57,147 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:58,591 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:58,593 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:43:59,838 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:43:59,840 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:01,255 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:01,257 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:02,748 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:02,750 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:04,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:04,087 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:05,271 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:05,273 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:06,831 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:06,834 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:08,569 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:08,572 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:10,628 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:10,630 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:12,153 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:12,155 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:13,719 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:13,721 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:15,615 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:15,617 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:17,018 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:17,020 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:18,522 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:18,524 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:19,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:19,963 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:21,132 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:21,134 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:22,809 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:22,811 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:24,356 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:24,357 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:44:24,360 - INFO - ✓ Saved: The_Circuit.json
2026-02-02 20:44:24,363 - INFO - Processing story: The_Fire_That_Fed_the_People
2026-02-02 20:44:24,366 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:25,209 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:25,211 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:25,769 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:25,771 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:26,739 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:26,741 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:27,413 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:27,415 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:27,984 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:27,986 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:28,755 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:28,757 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:29,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:29,528 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:30,358 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:30,361 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:31,172 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:31,174 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:31,772 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:31,774 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:32,490 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:32,492 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:33,581 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:33,583 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:34,292 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:34,294 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:34,785 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:34,787 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:35,423 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:35,425 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:36,030 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:36,032 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:36,448 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:36,450 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:37,244 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:37,246 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:37,771 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:37,773 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:38,502 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:38,503 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:44:38,507 - INFO - ✓ Saved: The_Fire_That_Fed_the_People.json
2026-02-02 20:44:38,522 - INFO - Processing story: The_Gentleman_of_the_Jungle
2026-02-02 20:44:38,524 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:39,364 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:39,366 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:40,146 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:40,148 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:40,878 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:40,880 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:41,719 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:41,721 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:42,585 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:42,587 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:43,682 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:43,685 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:44,470 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:44,472 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:45,172 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:45,174 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:45,858 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:45,860 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:46,785 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:46,788 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:47,445 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:47,447 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:48,189 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:48,191 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:48,983 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:48,986 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:49,614 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:49,617 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:50,262 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:50,264 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:51,207 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:51,209 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:52,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:52,131 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:52,703 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:52,705 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:53,337 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:53,339 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:54,093 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:54,094 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:44:54,098 - INFO - ✓ Saved: The_Gentleman_of_the_Jungle.json
2026-02-02 20:44:54,101 - INFO - Processing story: The_Pedestrian_Ray_Bradbury
2026-02-02 20:44:54,103 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:55,250 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:55,252 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:56,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:56,231 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:57,198 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:57,200 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:58,195 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:58,197 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:59,078 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:59,080 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:44:59,922 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:44:59,926 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:00,867 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:00,869 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:02,276 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:02,278 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:03,110 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:03,112 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:04,153 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:04,155 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:05,074 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:05,077 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:06,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:06,332 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:07,734 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:07,736 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:08,946 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:08,948 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:09,950 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:09,953 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:11,035 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:11,037 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:12,219 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:12,221 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:13,524 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:13,526 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:14,319 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:14,322 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:15,308 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:15,309 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:45:15,313 - INFO - ✓ Saved: The_Pedestrian_Ray_Bradbury.json
2026-02-02 20:45:15,317 - INFO - Processing story: The_People_who_Dug_for_Rain
2026-02-02 20:45:15,319 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:16,010 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:16,012 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:16,557 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:16,559 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:17,132 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:17,135 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:17,867 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:17,869 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:18,302 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:18,304 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:18,774 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:18,776 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:19,605 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:19,607 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:20,173 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:20,175 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:20,863 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:20,865 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:21,480 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:21,482 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:22,108 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:22,110 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:22,788 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:22,790 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:23,276 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:23,278 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:23,963 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:23,965 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:24,526 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:24,529 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:25,210 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:25,212 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:25,888 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:25,890 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:26,620 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:26,622 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:27,762 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:27,764 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:28,324 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:28,325 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:45:28,329 - INFO - ✓ Saved: The_People_who_Dug_for_Rain.json
2026-02-02 20:45:28,332 - INFO - Processing story: The_Strangers_That_Came_to_Town_Ambrose_Flack
2026-02-02 20:45:28,335 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:29,769 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:29,771 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:31,682 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:31,685 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:32,896 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:32,898 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:34,667 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:34,669 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:35,675 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:35,677 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:36,853 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:36,855 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:38,581 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:38,583 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:39,988 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:39,991 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:41,887 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:41,889 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:43,076 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:43,078 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:44,750 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:44,753 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:46,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:46,087 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:47,755 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:47,757 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:49,547 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:49,549 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:51,219 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:51,221 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:53,178 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:53,180 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:54,996 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:54,998 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:57,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:57,833 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:45:59,502 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:45:59,504 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:01,549 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:01,550 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:46:01,554 - INFO - ✓ Saved: The_Strangers_That_Came_to_Town_Ambrose_Flack.json
2026-02-02 20:46:01,558 - INFO - Processing story: The_Stretcher
2026-02-02 20:46:01,560 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:02,186 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:02,188 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:02,939 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:02,941 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:03,534 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:03,536 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:04,181 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:04,183 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:05,048 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:05,050 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:05,830 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:05,833 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:06,425 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:06,427 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:06,961 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:06,963 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:07,511 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:07,513 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:08,088 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:08,090 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:08,710 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:08,712 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:09,242 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:09,244 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:09,850 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:09,852 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:10,295 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:10,297 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:10,984 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:10,986 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:11,536 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:11,538 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:12,209 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:12,211 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:12,897 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:12,899 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:13,548 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:13,550 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:14,212 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:14,213 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:46:14,217 - INFO - ✓ Saved: The_Stretcher.json
2026-02-02 20:46:14,220 - INFO - Processing story: The_village_that_Shared_the_Moonlight
2026-02-02 20:46:14,223 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:14,718 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:14,720 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:15,235 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:15,237 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:15,887 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:15,889 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:16,530 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:16,532 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:17,076 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:17,078 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:17,610 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:17,612 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:18,098 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:18,100 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:18,645 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:18,647 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:19,196 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:19,198 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:19,716 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:19,718 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:20,334 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:20,336 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:20,858 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:20,861 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:21,322 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:21,324 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:21,899 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:21,901 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:22,421 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:22,423 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:22,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:22,931 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:23,311 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:23,314 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:23,821 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:23,823 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:24,348 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:24,350 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:24,908 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:24,909 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:46:24,912 - INFO - ✓ Saved: The_village_that_Shared_the_Moonlight.json
2026-02-02 20:46:24,915 - INFO - Processing story: War_of_the_Wall
2026-02-02 20:46:24,918 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:26,345 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:26,347 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:27,428 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:27,431 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:28,988 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:28,990 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:29,790 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:29,793 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:31,119 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:31,121 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:34,029 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:34,031 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:35,270 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:35,272 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:36,712 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:36,714 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:37,733 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:37,735 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:39,085 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:39,088 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:40,700 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:40,702 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:42,904 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:42,907 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:45,400 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:45,402 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:47,330 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:47,332 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:49,359 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:49,361 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:51,286 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:51,289 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:52,700 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:52,702 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:54,221 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:54,223 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:55,933 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:55,936 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:57,569 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:57,570 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:46:57,574 - INFO - ✓ Saved: War_of_the_Wall.json
2026-02-02 20:46:57,577 - INFO - Processing story: Warrior_Women_Nicaragua
2026-02-02 20:46:57,580 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:58,215 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:58,217 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:58,722 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:58,724 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:46:59,299 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:46:59,301 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:00,007 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:00,009 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:00,611 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:00,614 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:01,210 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:01,213 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:01,820 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:01,822 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:02,352 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:02,354 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:02,916 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:02,918 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:03,516 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:03,518 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:04,151 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:04,153 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:04,704 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:04,707 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:05,279 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:05,282 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:05,929 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:05,932 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:06,571 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:06,574 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:07,154 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:07,156 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:07,639 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:07,642 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:08,223 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:08,225 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:08,823 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:08,825 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:09,382 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:09,383 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:47:09,387 - INFO - ✓ Saved: Warrior_Women_Nicaragua.json
2026-02-02 20:47:09,390 - INFO - Processing story: We_Stand_Up
2026-02-02 20:47:09,392 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:10,032 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:10,034 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:10,767 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:10,770 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:11,390 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:11,393 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:12,048 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:12,050 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:12,727 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:12,729 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:13,461 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:13,464 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:13,994 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:13,997 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:14,735 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:14,737 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:15,188 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:15,190 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:15,597 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:15,599 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:16,229 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:16,232 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:16,721 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:16,723 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:17,366 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:17,368 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:17,973 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:17,975 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:18,611 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:18,613 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:19,363 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:19,365 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:20,036 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:20,038 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:20,778 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:20,780 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:21,607 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:21,610 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:22,264 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:22,265 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:47:22,269 - INFO - ✓ Saved: We_Stand_Up.json
2026-02-02 20:47:22,272 - INFO - Processing story: Whose_Voice_We_Wanted_to_Hear
2026-02-02 20:47:22,274 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:22,986 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:22,989 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:23,669 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:23,671 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:24,566 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:24,568 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:25,289 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:25,291 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:26,006 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:26,009 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:26,872 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:26,874 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:27,522 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:27,524 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:28,366 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:28,368 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:29,048 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:29,050 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:29,784 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:29,786 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:30,397 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:30,399 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:31,129 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:31,131 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:32,100 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:32,102 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:32,814 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:32,816 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:33,603 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:33,605 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:34,380 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:34,382 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:35,347 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:35,349 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:36,126 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:36,128 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:36,921 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:36,923 - INFO - 
LiteLLM completion() model= meta.llama3-1-8b-instruct-v1:0; provider = bedrock
2026-02-02 20:47:37,706 - INFO - Wrapper: Completed Call, calling success_handler
2026-02-02 20:47:37,707 - WARNING - No pricing found for model bedrock/meta.llama3-1-8b-instruct-v1:0, using default
2026-02-02 20:47:37,711 - INFO - ✓ Saved: Whose_Voice_We_Wanted_to_Hear.json
2026-02-02 20:47:37,717 - INFO - 
============================================================
2026-02-02 20:47:37,717 - INFO - Survey complete!
2026-02-02 20:47:37,717 - INFO - Processed: 28/28 stories
2026-02-02 20:47:37,717 - INFO - Failed: 0 stories
2026-02-02 20:47:37,717 - INFO - Total cost: $3.7909
2026-02-02 20:47:37,717 - INFO - Total tokens: 1,178,659
2026-02-02 20:47:37,717 - INFO - ============================================================

2026-02-02 20:47:37,718 - INFO - 
============================================================
2026-02-02 20:47:37,718 - INFO - Step 4: Learning PyReason Rules
2026-02-02 20:47:37,718 - INFO - ============================================================
2026-02-02 20:47:37,718 - INFO - ============================================================
2026-02-02 20:47:37,718 - INFO - RULE LEARNING
2026-02-02 20:47:37,718 - INFO - ============================================================
2026-02-02 20:47:37,718 - INFO - Loading survey results from: output/phase1/bedrock-meta.llama3-1-8b-instruct-v1-0/inverse/survey_results
2026-02-02 20:47:37,720 - INFO - Found 28 survey result files
2026-02-02 20:47:37,750 - INFO - Successfully loaded 28 survey results
2026-02-02 20:47:37,750 - INFO - Extracting feature scores...
2026-02-02 20:47:37,753 - INFO - Extracted scores for 28 stories and 20 features
2026-02-02 20:47:37,753 - INFO - Learning PyReason rules...
2026-02-02 20:47:37,753 - INFO - Configuration:
2026-02-02 20:47:37,753 - INFO -   - Body ranges: [[0.0, 0.0], [0.25, 0.25], [0.5, 0.5], [0.75, 0.75], [1.0, 1.0]]
2026-02-02 20:47:37,753 - INFO -   - Min confidence: 0.0
2026-02-02 20:47:37,753 - INFO -   - Min support: 0
2026-02-02 20:47:37,754 - INFO - Learning rules for 20 features...
2026-02-02 20:47:37,755 - INFO - Learned 100 rules
2026-02-02 20:47:37,757 - INFO - Saved 100 rules to output/phase1/bedrock-meta.llama3-1-8b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:47:37,757 - INFO - ============================================================
2026-02-02 20:47:37,757 - INFO - RULE LEARNING COMPLETE
2026-02-02 20:47:37,757 - INFO - ============================================================
2026-02-02 20:47:37,757 - INFO - Stories processed: 28
2026-02-02 20:47:37,757 - INFO - Features: 20
2026-02-02 20:47:37,757 - INFO - Rules learned: 100
2026-02-02 20:47:37,757 - INFO - Rules saved to: output/phase1/bedrock-meta.llama3-1-8b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:47:37,757 - INFO - ============================================================
2026-02-02 20:47:37,757 - INFO - 
Sample rules:
2026-02-02 20:47:37,758 - INFO -   1. corpus(X, behavioral_guidance):[0.14,0.14] <-1 individualistic_feature(X, behavioral_guidance):[0.0,0.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-02-02 20:47:37,758 - INFO -   2. corpus(X, behavioral_guidance):[0.82,0.82] <-1 individualistic_feature(X, behavioral_guidance):[0.25,0.25], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-02-02 20:47:37,758 - INFO -   3. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[0.5,0.5], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-02-02 20:47:37,758 - INFO -   4. corpus(X, behavioral_guidance):[0.00,0.00] <-1 individualistic_feature(X, behavioral_guidance):[0.75,0.75], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-02-02 20:47:37,758 - INFO -   5. corpus(X, behavioral_guidance):[0.04,0.04] <-1 individualistic_feature(X, behavioral_guidance):[1.0,1.0], story_name(X):[1,1], behavioral_guidance(behavioral_guidance):[1,1]
2026-02-02 20:47:37,758 - INFO -   ... and 95 more
2026-02-02 20:47:37,759 - INFO - 
✓ Rules learned and saved to: output/phase1/bedrock-meta.llama3-1-8b-instruct-v1-0/inverse/learned_rules/pyreason_rules.txt
2026-02-02 20:47:37,759 - INFO - 
Phase 1 completed successfully!
2026-02-02 20:47:37,759 - INFO - Output directory: output/phase1
2026-02-02 20:47:37,760 - INFO - ============================================================
2026-02-02 20:47:37,760 - INFO - Execution completed successfully!
2026-02-02 20:47:37,761 - INFO - ============================================================
